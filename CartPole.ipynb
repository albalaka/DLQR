{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import control as ct\n",
    "import tensorflow as tf\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVNFull():\n",
    "    def __init__(self, loc,covariance_matrix):\n",
    "        self.loc = tf.expand_dims(loc,-1)\n",
    "        self.cov = covariance_matrix\n",
    "        self.shape = tf.cast(self.cov.shape[-1],dtype=tf.float64)\n",
    "        assert(self.loc.shape[-2]==self.cov.shape[-1]), \"mean and covariance must have same n\"\n",
    "        assert(self.cov.shape[-1]==self.cov.shape[-2]),'covariance must have shape [...,n,n]'\n",
    "        \n",
    "    def prob(self, value):\n",
    "        value = tf.expand_dims(value,-1)\n",
    "#         print('Inside prob function')\n",
    "#         print('value',value.shape)\n",
    "        assert(value.shape[-1]==self.loc.shape[-1] and value.shape[-2]==self.loc.shape[-2]),'value must have same last 2 dimensions as loc'\n",
    "#         print('cov',self.cov.shape)\n",
    "        cov_inv = tf.linalg.inv(self.cov)\n",
    "#         print('cov_inv',cov_inv.shape)\n",
    "#         print(cov_inv.eval())\n",
    "        cov_det = tf.linalg.det(self.cov)\n",
    "#         print('cov_det', cov_det.shape)\n",
    "#         print(cov_det.eval())\n",
    "        denomenator = tf.math.sqrt(tf.math.pow((tf.cast(2*np.pi,dtype = tf.float64)),self.shape)*cov_det)\n",
    "#         print('denomenator', denomenator.shape)\n",
    "        diff = value-self.loc\n",
    "#         print('diff', diff.shape)\n",
    "        numerator = tf.squeeze(tf.math.exp((-0.5)*tf.matmul(tf.matmul(diff,cov_inv, transpose_a=True),diff)))\n",
    "#         print('numerator', numerator.shape)\n",
    "#         print('final value', tf.math.divide(numerator,denomenator).shape)\n",
    "#         print('leaving prob function')\n",
    "        return tf.math.divide(numerator,denomenator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    mu = tf.constant(0,shape=[10,4], dtype=tf.float64)\n",
    "    temp = tf.eye(4,batch_shape=[10],dtype = tf.float64)+tf.random.uniform([10,4,1],dtype = tf.float64)\n",
    "    cov = tf.matmul(temp,temp,transpose_b=True)\n",
    "    print(mu.shape,cov.shape)\n",
    "    test_sample = tf.zeros([10,4], dtype = tf.float64)\n",
    "    _ = tf.Variable(np.array([[np.power(.1,x) for x in range(4)] for _ in range(10)]), dtype = tf.float64)\n",
    "    rand = tf.Variable(tf.random.normal([10,4], dtype = tf.float64))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    mine = MVNFull(mu,cov)\n",
    "    theirs = tfd.MultivariateNormalFullCovariance(loc=mu, covariance_matrix=cov)\n",
    "    print(rand.shape)\n",
    "    my_sample = mine.prob(rand)\n",
    "    their_sample = theirs.prob(rand)\n",
    "    print(my_sample.eval())\n",
    "    print(their_sample.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(10):\n",
    "        diffs = 0\n",
    "        squared_diffs = 0\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for _ in range(100):\n",
    "            mu = tf.convert_to_tensor(np.expand_dims(np.array([1,2,3,4]).astype(np.float64),-1))\n",
    "            cov = tf.convert_to_tensor(np.eye(4)*10+np.random.normal(size=[4,4]))\n",
    "            mine = MVNFull(mu,cov)\n",
    "            theirs = tfd.MultivariateNormalFullCovariance(loc=tf.squeeze(mu),covariance_matrix=cov)\n",
    "            random_test = tf.convert_to_tensor(np.expand_dims(np.array([1,2,3,4]).astype(np.float64),-1))\n",
    "\n",
    "            my_sample = mine.prob(random_test)\n",
    "            their_sample = theirs.prob(tf.squeeze(random_test))\n",
    "    #         print(my_sample.eval()[0][0])\n",
    "    #         print(their_sample.eval())\n",
    "            if my_sample.eval()[0][0]-their_sample.eval()>0:\n",
    "                pos+=1\n",
    "            else:\n",
    "                neg+=1\n",
    "            diffs+=my_sample.eval()[0][0]-their_sample.eval()\n",
    "            squared_diffs+= np.square(my_sample.eval()[0][0]-their_sample.eval())\n",
    "        squared_diffs = np.sqrt(squared_diffs)\n",
    "        print(diffs/100, squared_diffs/100)\n",
    "        print(pos,neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_filter_fn(A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z):\n",
    "    '''Calculates prior distribution based on the previous posterior distribution\n",
    "        and the current residual updates posterior distribution based on the new\n",
    "        prior distribution\n",
    "    '''\n",
    "#     print('z',z.shape)\n",
    "#     print('A', A.shape)\n",
    "#     print('B',B.shape)\n",
    "#     print('u',u.shape)\n",
    "#     print('g',g.shape)\n",
    "#     print('sigma',sigma.shape)\n",
    "#     print('C', C.shape)\n",
    "#     print('l_a_posteriori', l_a_posteriori.shape)\n",
    "#     print('P_a_posteriori', P_a_posteriori.shape)\n",
    "    _I = tf.eye(int(A.shape[0]), dtype = tf.float64)\n",
    "    \n",
    "    z = tf.expand_dims(z,-1)\n",
    "    l_a_priori = tf.matmul(A,l_a_posteriori) + tf.matmul(B,u)\n",
    "#     print('l_a_priori',l_a_priori.shape)\n",
    "    P_a_priori = tf.matmul(tf.matmul(A,P_a_posteriori), A, transpose_b = True) + tf.matmul(g,g, transpose_b=True)\n",
    "#     print('P_a_priori',P_a_priori.shape)\n",
    "    y_pre = z - tf.matmul(C,l_a_priori)\n",
    "#     print('y_pre', y_pre.shape)\n",
    "    S = tf.matmul(sigma, sigma, transpose_b=True) + \\\n",
    "        tf.matmul(tf.matmul(C, P_a_priori), C, transpose_b=True)\n",
    "#     print('S', S.shape)\n",
    "    \n",
    "    S_inv = tf.linalg.inv(S)\n",
    "    K = tf.matmul(tf.matmul(P_a_priori, C, transpose_b=True), S_inv)\n",
    "#     print('K', K.shape)\n",
    "    l_a_posteriori = l_a_priori + tf.matmul(K,y_pre)\n",
    "#     print('l_a_posteriori', l_a_posteriori.shape)\n",
    "    I_KC = _I-tf.matmul(K,C)\n",
    "#     print('I-KC', I_KC.shape)\n",
    "    P_a_posteriori = tf.matmul(tf.matmul(I_KC, P_a_priori), I_KC, transpose_b=True) + \\\n",
    "                        tf.matmul(tf.matmul(K,tf.matmul(sigma, sigma, transpose_b = True)),\n",
    "                                K, transpose_b=True)\n",
    "#     print('P_a_posteriori',P_a_posteriori.shape)\n",
    "    y_post = z-tf.matmul(C,l_a_posteriori)\n",
    "#     print('y_post', y_post.shape)\n",
    "    pred = tf.matmul(C, l_a_posteriori)\n",
    "#     print('pred', pred.shape)\n",
    "        \n",
    "    return A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z\n",
    "\n",
    "def dict_append(d,new_items,vals):\n",
    "            for idx,item in enumerate(vals):\n",
    "                d[item].append(new_items[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_SSM_model(object):\n",
    "    def __init__(self, sess, name, m = 4, n=4, r=1,\n",
    "                 learning_rate = 0.0001, lr_decay = 0.95, sigma_upper_bound = 1,\n",
    "                 sigma_lower_bound = 0, g_upper_bound = 1,\n",
    "                 g_lower_bound = 0.1, mu_0_upper_bound = 1,mu_0_lower_bound = 0,\n",
    "                 Sigma_0_upper_bound = 1, Sigma_0_lower_bound = 0, beta = 0.00001,\n",
    "                 b_upper_bound = 0.25, b_lower_bound = -0.25,thetaacc_error=0,initial_state=1.0\n",
    "                ):\n",
    "        \n",
    "        '''thetaacc_error gives the amount of random angular acceleration that can be put on the pendulum,\n",
    "        initial_state gives the amount of variation in the initial state\n",
    "        '''\n",
    "        if name == '':\n",
    "            raise NameError(\"A model has no name\")\n",
    "\n",
    "        '''This functions assumes the state space model:\n",
    "            l_(t+1) = A_(t)l_(t)+B(t)u_(t)\n",
    "            z_(t+1) = C_(t)l_(t)\n",
    "            where:\n",
    "            l has dim m\n",
    "            u has dim r\n",
    "            z has dim m\n",
    "            A has dim mxn\n",
    "            B has dim mxr\n",
    "            C has dim mxm\n",
    "            '''\n",
    "            \n",
    "        self.sess = sess\n",
    "        \n",
    "        '''nn model hyperparameters'''\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_sample_len = tf.Variable(200, name = 'sample_len', trainable=False)\n",
    "        self.global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "        self.increment_global_step = tf.assign_add(self.global_step,1, name = 'increment_global_step')\n",
    "        self.lr_decay = lr_decay\n",
    "        self.lstm_sizes = [128,64]\n",
    "        last_lstm = self.lstm_sizes[-1]\n",
    "\n",
    "        '''dims'''\n",
    "        self.m = m # size of the state space\n",
    "        self.dim_z = m\n",
    "        self.n = n\n",
    "        self.r = r\n",
    "        self.lstm_input_dim = m+4 # previous states plus physical parameters\n",
    "        \n",
    "        \n",
    "        self.initial_variance = 1\n",
    "        \n",
    "        '''error bounds'''\n",
    "        self.sigma_upper_bound = sigma_upper_bound\n",
    "        self.g_lower_bound = g_lower_bound\n",
    "        self.g_upper_bound = g_upper_bound\n",
    "        self.mu_0_upper_bound = mu_0_upper_bound\n",
    "        self.mu_0_lower_bound = mu_0_lower_bound\n",
    "        self.Sigma_0_upper_bound = Sigma_0_upper_bound\n",
    "        self.Sigma_0_lower_bound= Sigma_0_lower_bound\n",
    "        self.b_upper_bound = b_upper_bound\n",
    "        self.b_lower_bound = b_lower_bound\n",
    "        self.beta = beta\n",
    "        \n",
    "        '''LQR parameters'''\n",
    "        self.initial_state = tf.Variable(1.0, name = 'initial_state',trainable=False)\n",
    "#         self.\n",
    "        self.sess.run(self.initial_state.initializer)\n",
    "        self.env = gym.make('Custom_CartPole-v0', thetaacc_error=thetaacc_error, initial_state=self.initial_state.eval())\n",
    "        self.gravity = self.env.gravity\n",
    "        self.cart_mass = self.env.masscart\n",
    "        self.pole_mass = self.env.masspole\n",
    "        self.pole_length = self.env.length\n",
    "        self.env_params = tf.expand_dims(np.array([self.gravity, self.cart_mass,\n",
    "                                                   self.pole_mass,self.pole_length], dtype=np.float64),0)\n",
    "        self.Q = np.eye(4)*[1,1,1,1]\n",
    "        self.R = 1\n",
    "        \n",
    "        self.vals = ['A','B','u','C','l_a_posteriori','P_a_posteriori','g','sigma','z']\n",
    "        self.KF_states = dict.fromkeys(self.vals)\n",
    "        \n",
    "        self.y_0 = tf.Variable(tf.zeros([self.dim_z], dtype = tf.float64), dtype = tf.float64, name = 'y_0', trainable = False)\n",
    "        \n",
    "        '''Saving model stuff, don\"t need for now'''\n",
    "        self.model_folder = 'development_trials/{}'.format(name)\n",
    "        if not os.path.isdir(self.model_folder):\n",
    "            print('This model has no folder')\n",
    "            os.makedirs(self.model_folder)\n",
    "        self.saved_model_location = '{}/model.ckpt'.format(self.model_folder)\n",
    "\n",
    "        self.losses = []\n",
    "        \n",
    "        with tf.variable_scope('KF', reuse = tf.AUTO_REUSE):\n",
    "            self.C = tf.get_variable(initializer = tf.eye(self.dim_z, dtype = tf.float64),dtype = tf.float64,\n",
    "                                     name = 'C', trainable = False)\n",
    "            self.W_A = tf.get_variable(initializer = tf.random.normal([last_lstm, m*n], dtype=tf.float64),\n",
    "                                       dtype = tf.float64, name = 'W_A')\n",
    "            self.bias_A = tf.get_variable(initializer = tf.zeros([1, m*n], dtype=tf.float64),\n",
    "                                          dtype = tf.float64, name = 'bias_A')\n",
    "            \n",
    "            self.W_B = tf.get_variable(initializer = tf.random.normal([last_lstm, m*r], dtype=tf.float64),\n",
    "                                       dtype = tf.float64, name = 'W_B')\n",
    "            self.bias_B = tf.get_variable(initializer = tf.zeros([1, m*r], dtype=tf.float64),\n",
    "                                         dtype = tf.float64, name = 'bias_B')\n",
    "\n",
    "            self.W_g = tf.get_variable(initializer = tf.random.normal([last_lstm, m], dtype=tf.float64),\n",
    "                                       dtype = tf.float64, name = 'W_g')\n",
    "            self.bias_g = tf.get_variable(initializer = tf.zeros([1, m], dtype=tf.float64),\n",
    "                                          dtype = tf.float64, name = 'bias_g')\n",
    "\n",
    "            self.W_sigma = tf.get_variable(initializer = tf.random.normal([last_lstm, self.dim_z], dtype=tf.float64),\n",
    "                                           dtype = tf.float64, name = 'W_sigma')\n",
    "            self.bias_sigma = tf.get_variable(initializer = tf.zeros([1, self.dim_z], dtype=tf.float64),\n",
    "                                              dtype = tf.float64, name = 'bias_sigma')\n",
    "\n",
    "            self.W_mu_0 = tf.get_variable(initializer = tf.random.normal([last_lstm, self.m], dtype=tf.float64),\n",
    "                                          dtype = tf.float64, name = 'W_mu_0')\n",
    "            self.bias_mu_0 = tf.get_variable(initializer = tf.zeros([1, self.m], dtype=tf.float64),\n",
    "                                             dtype = tf.float64, name = 'bias_mu_0')\n",
    "            \n",
    "            self.W_Sigma_0 = tf.get_variable(initializer = tf.random.normal([last_lstm, self.m], dtype=tf.float64),\n",
    "                                             dtype = tf.float64, name = 'W_Sigma_0')\n",
    "            self.bias_Sigma_0 = tf.get_variable(initializer = tf.zeros([1, self.m], dtype=tf.float64),\n",
    "                                                dtype = tf.float64, name = 'bias_Sigma_0')\n",
    "            \n",
    "            self.P_0 = tf.Variable(self.initial_variance*tf.eye(self.m,dtype = tf.float64),\n",
    "                                   name = 'P_0', trainable = False)\n",
    "\n",
    "            self.y_0 = tf.Variable(tf.zeros([self.dim_z], dtype=tf.float64), dtype = tf.float64, name = 'y_0', trainable = False)\n",
    "            self.z_0 = tf.Variable(tf.zeros([self.dim_z, self.dim_z], dtype=tf.float64), dtype = tf.float64, name = 'z_0', trainable = False)\n",
    "            self.pred_0 = tf.Variable(tf.zeros([self.dim_z], dtype=tf.float64), dtype = tf.float64, name = 'pred_0', trainable = False)\n",
    "            \n",
    "            \n",
    "            '''Variables for test range in LQE only'''\n",
    "#             self.A_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, m, n], name = 'A_test')\n",
    "#             self.B_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, m, r], name = 'B_test')\n",
    "#             self.g_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, self.m, 1], name = 'g_test')\n",
    "#             self.sigma_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, self.dim_z, 1], name = 'sigma_test')\n",
    "#             self.l_0_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.m, 1], name = 'l_0_test')\n",
    "#             self.final_z = tf.placeholder(tf.float32, shape = [self.batch_size, 1, self.dim_z], name = 'final_z')\n",
    "\n",
    "#         self.z = tf.placeholder(tf.float32, shape = [self.dim_z],name = 'z')\n",
    "        self.reward = tf.placeholder(tf.float64,shape = [])\n",
    "#         self.A = tf.placeholder(tf.float32, shape = [None, m,n])\n",
    "#         self.B = tf.placeholder(tf.float32, shape = [None, m,r])\n",
    "#         self.u = tf.placeholder(tf.float32, shape = [None, r,1])\n",
    "#         self.C = tf.placeholder(tf.float32, shape = [None, self.dim_z,m])\n",
    "#         self.g = tf.placeholder(tf.float32, shape = [None, m,1])\n",
    "#         self.sigma = tf.placeholder(tf.float32, shape = [None, dim_z,dim_z])\n",
    "#         with tf.variable_scope('LSTM', reuse = tf.AUTO_REUSE):\n",
    "#             self.lstm_input = tf.placeholder(tf.float32, shape = [None, self.lstm_input_dim],\n",
    "#                                             name = 'lstm_input')\n",
    "\n",
    "    def initialize_variables(self):\n",
    "        self.saver = tf.train.Saver()\n",
    "        try:\n",
    "            self.saver.restore(self.sess, tf.train.latest_checkpoint(self.model_folder))\n",
    "            print(\"Restoring model from {}\".format(self.saved_model_location))\n",
    "        except:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            print(\"Initializing new model at {}\".format(self.saved_model_location))\n",
    "        return self\n",
    "\n",
    "    def build_new_LSTM(self):\n",
    "        with tf.name_scope('LSTM'):\n",
    "            with tf.variable_scope('LSTM', reuse=tf.AUTO_REUSE):\n",
    "\n",
    "                lstms = [tf.contrib.rnn.LSTMCell(size, reuse=tf.get_variable_scope().reuse) for size in self.lstm_sizes]\n",
    "                dropouts = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = 0.5) for lstm in lstms]\n",
    "\n",
    "                self.cell = tf.contrib.rnn.MultiRNNCell(dropouts)\n",
    "#                 if prev_state:\n",
    "#                     initial_state = prev_state\n",
    "#                 else:\n",
    "#                     initial_state = cell.zero_state(self.batch_size, tf.float32)\n",
    "#                 self.lstm_output, self.final_state = tf.nn.dynamic_rnn(cell, self.lstm_input, initial_state = initial_state)\n",
    "        return self\n",
    "\n",
    "    def new_affine(self,lstm_output,first=False):\n",
    "        with tf.variable_scope('affine_transformations'):\n",
    "            if first:\n",
    "                mu_0 = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_mu_0), self.bias_mu_0))\n",
    "                self.mu_0 = ((self.mu_0_upper_bound-self.mu_0_lower_bound)/(1+tf.exp(-mu_0)))+self.mu_0_lower_bound\n",
    "\n",
    "                Sigma_0 = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_Sigma_0), self.bias_Sigma_0))\n",
    "                Sigma_0 = ((self.Sigma_0_upper_bound-self.Sigma_0_lower_bound)/(1+tf.exp(-Sigma_0)))+self.Sigma_0_lower_bound\n",
    "                self.Sigma_0 = tf.matmul(Sigma_0,Sigma_0,transpose_b=True)+tf.eye(4, dtype=tf.float64)*0.001\n",
    "\n",
    "                l_0_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(self.mu_0),\n",
    "                                                                        covariance_matrix= self.Sigma_0,\n",
    "                                                                       validate_args=True)\n",
    "                self.l_0 = tf.expand_dims(l_0_distribution.sample(),1)\n",
    "                return self\n",
    "\n",
    "            A = tf.reshape(tf.add(tf.matmul(lstm_output, self.W_A), self.bias_A),shape=(self.m,self.n))\n",
    "            B = tf.reshape(tf.add(tf.matmul(lstm_output, self.W_B), self.bias_B),shape=(self.m,self.r))\n",
    "            \n",
    "            g = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_g), self.bias_g))\n",
    "            g = ((self.g_upper_bound-self.g_lower_bound)/(1+tf.exp(-g)))+self.g_lower_bound\n",
    "\n",
    "            sigma = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_sigma), self.bias_sigma))\n",
    "            sigma = (self.sigma_upper_bound)/(1+tf.exp(-sigma))\n",
    "            \n",
    "        return A,B,g,sigma\n",
    "\n",
    "    def likelihood_fn(self, params, inputs):\n",
    "        '''Compute likelihood over a batch\n",
    "        params contains: mu, Sigma - the parameters of the likelihood distribution\n",
    "        inputs contains: calculations of mu: F, a, l_filtered==l_a_posteriori\n",
    "                        calculations of Sigma: a, F, P_a_posteriori, g, sigma\n",
    "        '''\n",
    "        A, B, u, C, g, sigma, l_filtered, P_filtered = inputs\n",
    "        mu, Sigma = params\n",
    "        '''\n",
    "        a (bs, m, 1)\n",
    "        b (bs, 1)\n",
    "        F (bs, m, m)\n",
    "        g (bs, m, 1)\n",
    "        sigma (bs, 1, 1)\n",
    "        f (bs, m, 1)\n",
    "        S (bs, m, m)\n",
    "        mu (bs, 1, 1)\n",
    "        Sigma (bs, 1, 1)\n",
    "        '''\n",
    "#         print('A',A.shape)\n",
    "#         print('B',B.shape)\n",
    "#         print('u',u.shape)\n",
    "#         print('C',C.shape)\n",
    "#         print('g',g.shape)\n",
    "#         print('sigma',sigma.shape)\n",
    "#         print('l_filtered',l_filtered.shape)\n",
    "#         print('p_filtered',P_filtered.shape)\n",
    "#         print('mu',mu.shape)\n",
    "#         print('Sigma',Sigma.shape)\n",
    "        mu = tf.matmul(C, tf.add(tf.matmul(A,l_filtered), tf.matmul(B,u)))\n",
    "#         mu = tf.add(tf.matmul(tf.matmul(a, F, transpose_a=True), f), b)\n",
    "\n",
    "        temp = tf.matmul(tf.matmul(A, P_filtered), A, transpose_b=True) + tf.matmul(g, g, transpose_b=True)\n",
    "        Sigma = tf.matmul(tf.matmul(C, temp), C, transpose_b=True) + tf.matmul(sigma,sigma,transpose_b=True)\n",
    "\n",
    "#         temp = tf.matmul(tf.matmul(F, S), F, transpose_b=True) + tf.matmul(g, g, transpose_b=True)\n",
    "#         Sigma = tf.matmul(tf.matmul(a, temp, transpose_a=True), a) + tf.square(sigma)\n",
    "        \n",
    "        return mu, Sigma\n",
    "    \n",
    "    def calculate_new_loss(self,reward):\n",
    "        with tf.variable_scope('loss', reuse = tf.AUTO_REUSE):\n",
    "#             for key,value in self.KF_states.items():\n",
    "#                 print(key,value[0].shape)\n",
    "#             print('mu_0',self.mu_0.shape)\n",
    "#             print('Sigma_0',self.Sigma_0.shape)\n",
    "#             print(self.Sigma_0.eval())\n",
    "\n",
    "            mu_1 = tf.matmul(self.KF_states['A'][0], self.mu_0)+\\\n",
    "                    tf.matmul(self.KF_states['B'][0],self.KF_states['u'][0])\n",
    "#             print(self.KF_states['sigma'][0])\n",
    "            Sigma_1 = tf.matmul(tf.matmul(self.KF_states['C'][0],self.Sigma_0,transpose_a=True),\n",
    "                                self.KF_states['C'][0])+tf.matmul(self.KF_states['sigma'][0],\n",
    "                                                                  self.KF_states['sigma'][0],transpose_b=True)\n",
    "#             print('mu_1',mu_1.shape)\n",
    "#             print('Sigma_1', Sigma_1.shape)\n",
    "#             print(Sigma_1.eval())\n",
    "            \n",
    "            def make_tensor(l):\n",
    "                return tf.convert_to_tensor(l,dtype=tf.float64)\n",
    "            if reward>1:\n",
    "                mu, Sigma = tf.scan(self.likelihood_fn,\n",
    "                                    elems = (make_tensor(self.KF_states['A'][1:]),\n",
    "                                             make_tensor(self.KF_states['B'][1:]),\n",
    "                                             make_tensor(self.KF_states['u'][1:]),\n",
    "                                             make_tensor(self.KF_states['C'][1:]),\n",
    "                                             make_tensor(self.KF_states['g'][1:]),\n",
    "                                             make_tensor(self.KF_states['sigma'][1:]),\n",
    "                                             make_tensor(self.KF_states['l_a_posteriori'][:-1]),\n",
    "                                             make_tensor(self.KF_states['P_a_posteriori'][1:])),\n",
    "                                    initializer = (mu_1, Sigma_1))\n",
    "\n",
    "                self.mu = tf.concat([tf.expand_dims(mu_1,0), mu], 0)\n",
    "                self.Sigma = tf.concat([tf.expand_dims(Sigma_1,0),Sigma], 0)\n",
    "\n",
    "            else:\n",
    "                self.mu = tf.expand_dims(mu_1,0)\n",
    "                self.Sigma=tf.expand_dims(Sigma_1,0)\n",
    "#             print(self.mu.shape)\n",
    "#             print(\"Sigma\",self.Sigma.shape)\n",
    "#             print(self.Sigma.eval())\n",
    "#             print('cov determinant',tf.linalg.det(tf.eye(self.m,batch_shape=[self.Sigma.shape[0]], dtype=tf.float64)+self.Sigma).eval())\n",
    "#             print('cov eigs',tf.linalg.eigvalsh(tf.eye(self.m,batch_shape=[self.Sigma.shape[0]], dtype=tf.float64)+self.Sigma).eval())\n",
    "#             print(tf.linalg.inv(self.Sigma).eval())\n",
    "#             print(tf.linalg.cholesky(tf.matmul(self.Sigma,self.Sigma,transpose_b=True)).eval())\n",
    "        \n",
    "            '''TODO:\n",
    "                Failing on cholesky decomposition? Only when evaluating\n",
    "            '''\n",
    "#             z_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(self.mu,-1), \\\n",
    "#                 covariance_matrix = tf.eye(self.m,batch_shape=[self.Sigma.shape[0]],dtype = tf.float64)+self.Sigma)\n",
    "            z_distribution = MVNFull(loc = tf.squeeze(self.mu,-1),covariance_matrix = 0.001*tf.eye(self.m,batch_shape=[self.Sigma.shape[0]],dtype = tf.float64)+self.Sigma)\n",
    "            self.z_probability = z_distribution.prob(tf.squeeze(self.KF_states['z'],-1))\n",
    "            regularizers = tf.nn.l2_loss(self.W_g) + tf.nn.l2_loss(self.W_mu_0) + \\\n",
    "                        tf.nn.l2_loss(self.W_sigma) + tf.nn.l2_loss(self.W_Sigma_0) + \\\n",
    "                        tf.nn.l2_loss(self.W_A) + tf.nn.l2_loss(self.W_B)\n",
    "#             print('likelihood',self.z_probability.eval())\n",
    "#             self.loss = tf.reduce_mean(self.beta*regularizers)- \\\n",
    "#                             (tf.math.square(tf.reciprocal(self.reward))* \\\n",
    "#                              tf.reduce_sum(tf.log(self.z_probability+1e-8)))\n",
    "            self.loss = tf.reduce_mean(self.beta*regularizers)-tf.math.square(self.reward)* \\\n",
    "                                tf.reduce_sum(tf.log(self.z_probability+1e-8))\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "#             self.optimizer = tf.train.AdamOptimizer(decayed_learning_rate)\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "#             for grad,var in grads_and_vars:\n",
    "#                 print(grad,var)\n",
    "#             capped_grads_and_vars = [(tf.clip_by_norm(grad, 1.), var) for grad, var in grads_and_vars]\n",
    "            capped_grads_and_vars = [gv if gv[0] is None else [tf.clip_by_value(gv[0], -10., 10.), gv[1]] for gv in grads_and_vars]\n",
    "            self.train_op = self.optimizer.apply_gradients(capped_grads_and_vars)\n",
    "        return self\n",
    "            \n",
    "    def LQR_DP_solve(Q, R, A, B):\n",
    "        return\n",
    "    \n",
    "    def new_train(self, epochs):\n",
    "        '''In this method, we require each epoch as 1 training sample\n",
    "            We will generate single steps at a time for input to the LSTM,\n",
    "            and then single step calculations of the optimal control\n",
    "        '''\n",
    "        \n",
    "        #Delete this section\n",
    "        Q = np.eye(4)*[10,1,1,1]\n",
    "        R = 1\n",
    "        \n",
    "        \n",
    "\n",
    "        self.rewards = [0 for _ in range(epochs)]\n",
    "#         self.environment_states = [[] for _ in range(epochs)]\n",
    "#         self.KF_states = [[] for _ in range(epochs)]\n",
    "            # required for likelihood/loss: A,B,u,C,l_a_posteriori,P_a_posteriorig,sigma\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for i in range(epochs):\n",
    "            start = time.time()\n",
    "            self.environment_states=[]\n",
    "            self.KF_states = {'A':[],'B':[],'u':[],'C':[],'l_a_posteriori':[],'P_a_posteriori':[],\n",
    "                             'g':[],'sigma':[],'z':[]}\n",
    "            \n",
    "            done = False\n",
    "            observation = self.env.reset()\n",
    "            self.environment_states.append(tf.convert_to_tensor(observation,dtype=tf.float64))\n",
    "            preds = []\n",
    "            epoch_loss = []\n",
    "            initial_state = self.cell.zero_state(batch_size=1,dtype=tf.float64)\n",
    "            initial_input = tf.concat((self.env_params,np.zeros(shape=[1,4])),axis=1)\n",
    "#             print(initial_input.shape)\n",
    "#             for item in initial_state:\n",
    "#                 print(type(item))\n",
    "#                 print(item)\n",
    "            with tf.variable_scope('LSTM', reuse=tf.AUTO_REUSE):\n",
    "                output_single,state_single = self.cell(inputs = initial_input, state = initial_state)\n",
    "                self.new_affine(output_single, first=True)\n",
    "            \n",
    "            u = tf.zeros(shape = [1,self.r], dtype=tf.float64)\n",
    "            l_a_posteriori = self.l_0\n",
    "            P_a_posteriori = self.P_0\n",
    "            \n",
    "            uninitialized_vars= []\n",
    "            for var in tf.global_variables():\n",
    "                try:\n",
    "                    sess.run(var)\n",
    "                except tf.errors.FailedPreconditionError:\n",
    "                    uninitialized_vars.append(var)\n",
    "                    \n",
    "#             print(uninitialized_vars)\n",
    "            init_new_vars_op = self.sess.run(tf.variables_initializer(uninitialized_vars))\n",
    "#             self.sess.run(tf.global_variables_initializer())\n",
    "            while not done:\n",
    "                #Try parameterizing u by NN, include it in new_affine\n",
    "                \n",
    "                \n",
    "                '''Get these values from a sess.run with placeholder???'''\n",
    "                A, B, g, sigma = self.new_affine(output_single)\n",
    "#                 A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z = \\\n",
    "#                         forward_filter_fn(A,B,u,self.C,l_a_posteriori,\n",
    "#                                           P_a_posteriori,g,sigma,self.environment_states[-1])\n",
    "                dict_append(self.KF_states, forward_filter_fn(A,B,u,self.C,l_a_posteriori,\n",
    "                                                         P_a_posteriori,g,sigma,\n",
    "                                                         self.environment_states[-1]),\n",
    "                           self.vals)\n",
    "#                 self.KF_states.append((A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z))\n",
    "                \n",
    "                \n",
    "                #Delete this section\n",
    "                K,S,E = ct.lqr(self.KF_states['A'][-1].eval(),self.KF_states['B'][-1].eval(),Q,R)\n",
    "                u = -tf.matmul(K.astype(np.float64),tf.expand_dims(self.environment_states[-1],-1))\n",
    "                #u needs to be chosen in a better fashion\n",
    "                \n",
    "                observation,reward,done,info = self.env.step(np.squeeze(u.eval()))\n",
    "                self.environment_states.append(tf.convert_to_tensor(observation,dtype=tf.float64))\n",
    "                self.rewards[i] += 1\n",
    "                \n",
    "                '''Calculate filtered distributions with KF\n",
    "                    Approximate the control\n",
    "                    Call the next step with calculated control\n",
    "                    update lstm input with output of the observation\n",
    "                '''\n",
    "                next_input = tf.concat((self.env_params,tf.expand_dims(self.environment_states[-1],0)),axis=1)\n",
    "                output_single,state_single = self.cell(inputs=next_input,state=state_single)\n",
    "                \n",
    "#             for key,value in self.KF_states.items():\n",
    "#                 print(key)\n",
    "#                 for item in value:\n",
    "#                     print(item.shape)\n",
    "            self.calculate_new_loss(self.rewards[i])\n",
    "#             self.calculate_new_loss(self.rewards[i])\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            feed_dict={self.reward:self.rewards[i]}\n",
    "#             loss_, _,_ = self.sess.run([self.loss, self.train_op, self.increment_global_step], feed_dict=feed_dict)\n",
    "            loss_, _ = self.sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "\n",
    "            \n",
    "#             print(self.sess.run(self.global_step))\n",
    "            \n",
    "            \n",
    "            print('Loss: {:.3f}'.format(loss_))\n",
    "            print(\"Epoch {} ended after {:.3f} minutes, with {} rewards\\nTime per reward: {:.3f}\".\n",
    "                  format(i,(time.time()-start)/60,self.rewards[i],(time.time()-start)/(60*self.rewards[i])))\n",
    "        self.saver.save(self.sess, self.saved_model_location)#, global_step=self.global_step)\n",
    "#             print(\"Model Saved at {}\".format(self.saved_model_location))\n",
    "        print(\"Total time: {:.3f}\".format((time.time()-start)/60))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "This model has no folder\n",
      "WARNING:tensorflow:From <ipython-input-4-7bce6e022462>:164: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-7bce6e022462>:167: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "Initializing new model at development_trials/deleteme/model.ckpt\n",
      "WARNING:tensorflow:From /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loss: 2842063.110\n",
      "Epoch 0 ended after 1.293 minutes, with 54 rewards\n",
      "Time per reward: 0.024\n",
      "Loss: 3978.879\n",
      "Epoch 1 ended after 0.489 minutes, with 6 rewards\n",
      "Time per reward: 0.082\n",
      "Loss: 9431.400\n",
      "Epoch 2 ended after 0.509 minutes, with 8 rewards\n",
      "Time per reward: 0.064\n",
      "Loss: 126345.740\n",
      "Epoch 3 ended after 1.340 minutes, with 19 rewards\n",
      "Time per reward: 0.071\n",
      "Loss: 323761.897\n",
      "Epoch 4 ended after 2.365 minutes, with 26 rewards\n",
      "Time per reward: 0.091\n",
      "Total time: 2.455\n",
      "[[54, 6, 8, 19, 26]]\n",
      "WARNING:tensorflow:From /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 18.432\n",
      "Epoch 0 ended after 0.029 minutes, with 1 rewards\n",
      "Time per reward: 0.029\n",
      "Loss: 859435.292\n",
      "Epoch 1 ended after 0.953 minutes, with 36 rewards\n",
      "Time per reward: 0.026\n",
      "Loss: 661983.215\n",
      "Epoch 2 ended after 1.771 minutes, with 33 rewards\n",
      "Time per reward: 0.054\n",
      "Loss: 90500.816\n",
      "Epoch 3 ended after 1.221 minutes, with 17 rewards\n",
      "Time per reward: 0.072\n",
      "Loss: 107429.422\n",
      "Epoch 4 ended after 1.623 minutes, with 18 rewards\n",
      "Time per reward: 0.090\n",
      "Total time: 1.705\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 18.432\n",
      "Epoch 0 ended after 0.028 minutes, with 1 rewards\n",
      "Time per reward: 0.028\n",
      "Loss: 5677.879\n",
      "Epoch 1 ended after 0.176 minutes, with 7 rewards\n",
      "Time per reward: 0.025\n",
      "Loss: 9431.400\n",
      "Epoch 2 ended after 0.216 minutes, with 8 rewards\n",
      "Time per reward: 0.027\n",
      "Loss: 3978.878\n",
      "Epoch 3 ended after 0.210 minutes, with 6 rewards\n",
      "Time per reward: 0.035\n",
      "Loss: 449261.994\n",
      "Epoch 4 ended after 1.225 minutes, with 29 rewards\n",
      "Time per reward: 0.042\n",
      "Total time: 1.269\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 18.433\n",
      "Epoch 0 ended after 0.042 minutes, with 1 rewards\n",
      "Time per reward: 0.042\n",
      "Loss: 497.370\n",
      "Epoch 1 ended after 0.072 minutes, with 3 rewards\n",
      "Time per reward: 0.024\n",
      "Loss: 497.369\n",
      "Epoch 2 ended after 0.074 minutes, with 3 rewards\n",
      "Time per reward: 0.025\n",
      "Loss: 254647.501\n",
      "Epoch 3 ended after 0.620 minutes, with 24 rewards\n",
      "Time per reward: 0.026\n",
      "Loss: 90500.816\n",
      "Epoch 4 ended after 0.730 minutes, with 17 rewards\n",
      "Time per reward: 0.043\n",
      "Total time: 0.770\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 497.370\n",
      "Epoch 0 ended after 0.074 minutes, with 3 rewards\n",
      "Time per reward: 0.025\n",
      "Loss: 24517.938\n",
      "Epoch 1 ended after 0.220 minutes, with 11 rewards\n",
      "Time per reward: 0.020\n",
      "Loss: 1178.935\n",
      "Epoch 2 ended after 0.125 minutes, with 4 rewards\n",
      "Time per reward: 0.031\n",
      "Loss: 18.431\n",
      "Epoch 3 ended after 0.057 minutes, with 1 rewards\n",
      "Time per reward: 0.057\n",
      "Loss: 90500.807\n",
      "Epoch 4 ended after 0.579 minutes, with 17 rewards\n",
      "Time per reward: 0.034\n",
      "Total time: 0.615\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 147365.458\n",
      "Epoch 0 ended after 0.354 minutes, with 20 rewards\n",
      "Time per reward: 0.018\n",
      "Loss: 62169.808\n",
      "Epoch 1 ended after 0.525 minutes, with 15 rewards\n",
      "Time per reward: 0.035\n",
      "Loss: 1178.935\n",
      "Epoch 2 ended after 0.192 minutes, with 4 rewards\n",
      "Time per reward: 0.048\n",
      "Loss: 13428.688\n",
      "Epoch 3 ended after 0.434 minutes, with 9 rewards\n",
      "Time per reward: 0.048\n",
      "Loss: 24517.937\n",
      "Epoch 4 ended after 0.638 minutes, with 11 rewards\n",
      "Time per reward: 0.058\n",
      "Total time: 0.688\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 18.433\n",
      "Epoch 0 ended after 0.027 minutes, with 1 rewards\n",
      "Time per reward: 0.027\n",
      "Loss: 23388.667\n",
      "Epoch 1 ended after 0.222 minutes, with 11 rewards\n",
      "Time per reward: 0.020\n",
      "Loss: 2043.971\n",
      "Epoch 2 ended after 0.141 minutes, with 5 rewards\n",
      "Time per reward: 0.028\n",
      "Loss: 6318.304\n",
      "Epoch 3 ended after 0.230 minutes, with 7 rewards\n",
      "Time per reward: 0.033\n",
      "Loss: 50546.360\n",
      "Epoch 4 ended after 0.533 minutes, with 14 rewards\n",
      "Time per reward: 0.038\n",
      "Total time: 0.567\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 1178.934\n",
      "Epoch 0 ended after 0.072 minutes, with 4 rewards\n",
      "Time per reward: 0.018\n",
      "Loss: 323761.896\n",
      "Epoch 1 ended after 0.625 minutes, with 26 rewards\n",
      "Time per reward: 0.024\n",
      "Loss: 3548.533\n",
      "Epoch 2 ended after 0.245 minutes, with 6 rewards\n",
      "Time per reward: 0.041\n",
      "Loss: 126347.461\n",
      "Epoch 3 ended after 0.859 minutes, with 19 rewards\n",
      "Time per reward: 0.045\n",
      "Loss: 3977.342\n",
      "Epoch 4 ended after 0.388 minutes, with 6 rewards\n",
      "Time per reward: 0.065\n",
      "Total time: 0.444\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 3978.878\n",
      "Epoch 0 ended after 0.101 minutes, with 6 rewards\n",
      "Time per reward: 0.017\n",
      "Loss: 1178.935\n",
      "Epoch 1 ended after 0.141 minutes, with 4 rewards\n",
      "Time per reward: 0.035\n",
      "Loss: 90500.815\n",
      "Epoch 2 ended after 0.500 minutes, with 17 rewards\n",
      "Time per reward: 0.029\n",
      "Loss: 3978.878\n",
      "Epoch 3 ended after 0.277 minutes, with 6 rewards\n",
      "Time per reward: 0.046\n",
      "Loss: 75451.119\n",
      "Epoch 4 ended after 0.782 minutes, with 16 rewards\n",
      "Time per reward: 0.049\n",
      "Total time: 0.826\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 75451.120\n",
      "Epoch 0 ended after 0.288 minutes, with 16 rewards\n",
      "Time per reward: 0.018\n",
      "Loss: 1092696.373\n",
      "Epoch 1 ended after 1.422 minutes, with 39 rewards\n",
      "Time per reward: 0.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40470.248\n",
      "Epoch 2 ended after 0.730 minutes, with 13 rewards\n",
      "Time per reward: 0.056\n",
      "Loss: 1178.935\n",
      "Epoch 3 ended after 0.325 minutes, with 4 rewards\n",
      "Time per reward: 0.081\n",
      "Loss: 18.432\n",
      "Epoch 4 ended after 0.154 minutes, with 1 rewards\n",
      "Time per reward: 0.154\n",
      "Total time: 0.219\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 18.433\n",
      "Epoch 0 ended after 0.026 minutes, with 1 rewards\n",
      "Time per reward: 0.026\n",
      "Loss: 18.432\n",
      "Epoch 1 ended after 0.039 minutes, with 1 rewards\n",
      "Time per reward: 0.039\n",
      "Loss: 18420.692\n",
      "Epoch 2 ended after 0.200 minutes, with 10 rewards\n",
      "Time per reward: 0.020\n",
      "Loss: 323750.673\n",
      "Epoch 3 ended after 0.888 minutes, with 26 rewards\n",
      "Time per reward: 0.034\n",
      "Loss: 362574.271\n",
      "Epoch 4 ended after 1.350 minutes, with 27 rewards\n",
      "Time per reward: 0.050\n",
      "Total time: 1.401\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 1178.935\n",
      "Epoch 0 ended after 0.077 minutes, with 4 rewards\n",
      "Time per reward: 0.019\n",
      "Loss: 1178.935\n",
      "Epoch 1 ended after 0.151 minutes, with 4 rewards\n",
      "Time per reward: 0.038\n",
      "Loss: 1092696.373\n",
      "Epoch 2 ended after 1.238 minutes, with 39 rewards\n",
      "Time per reward: 0.032\n",
      "Loss: 31830.924\n",
      "Epoch 3 ended after 0.633 minutes, with 12 rewards\n",
      "Time per reward: 0.053\n",
      "Loss: 859435.292\n",
      "Epoch 4 ended after 2.485 minutes, with 36 rewards\n",
      "Time per reward: 0.069\n",
      "Total time: 2.558\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 3978.878\n",
      "Epoch 0 ended after 0.129 minutes, with 6 rewards\n",
      "Time per reward: 0.021\n",
      "Loss: 3978.879\n",
      "Epoch 1 ended after 0.174 minutes, with 6 rewards\n",
      "Time per reward: 0.029\n",
      "Loss: 18.432\n",
      "Epoch 2 ended after 0.047 minutes, with 1 rewards\n",
      "Time per reward: 0.047\n",
      "Loss: 126347.460\n",
      "Epoch 3 ended after 0.567 minutes, with 19 rewards\n",
      "Time per reward: 0.030\n",
      "Loss: 6213669.483\n",
      "Epoch 4 ended after 4.211 minutes, with 70 rewards\n",
      "Time per reward: 0.060\n",
      "Total time: 4.288\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 18.432\n",
      "Epoch 0 ended after 0.027 minutes, with 1 rewards\n",
      "Time per reward: 0.027\n",
      "Loss: 18.432\n",
      "Epoch 1 ended after 0.041 minutes, with 1 rewards\n",
      "Time per reward: 0.041\n",
      "Loss: 1178.935\n",
      "Epoch 2 ended after 0.117 minutes, with 4 rewards\n",
      "Time per reward: 0.029\n",
      "Loss: 2302.597\n",
      "Epoch 3 ended after 0.137 minutes, with 5 rewards\n",
      "Time per reward: 0.027\n",
      "Loss: 497.370\n",
      "Epoch 4 ended after 0.114 minutes, with 3 rewards\n",
      "Time per reward: 0.038\n",
      "Total time: 0.132\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70], [1, 1, 4, 5, 3]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 62169.809\n",
      "Epoch 0 ended after 0.244 minutes, with 15 rewards\n",
      "Time per reward: 0.016\n",
      "Loss: 661984.016\n",
      "Epoch 1 ended after 1.042 minutes, with 33 rewards\n",
      "Time per reward: 0.032\n",
      "Loss: 497358.391\n",
      "Epoch 2 ended after 1.622 minutes, with 30 rewards\n",
      "Time per reward: 0.054\n",
      "Loss: 18420.692\n",
      "Epoch 3 ended after 0.773 minutes, with 10 rewards\n",
      "Time per reward: 0.077\n",
      "Loss: 18.432\n",
      "Epoch 4 ended after 0.184 minutes, with 1 rewards\n",
      "Time per reward: 0.184\n",
      "Total time: 0.255\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70], [1, 1, 4, 5, 3], [15, 33, 30, 10, 1]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 3978.879\n",
      "Epoch 0 ended after 0.125 minutes, with 6 rewards\n",
      "Time per reward: 0.021\n",
      "Loss: 497.370\n",
      "Epoch 1 ended after 0.109 minutes, with 3 rewards\n",
      "Time per reward: 0.036\n",
      "Loss: 74045.739\n",
      "Epoch 2 ended after 0.401 minutes, with 16 rewards\n",
      "Time per reward: 0.025\n",
      "Loss: 147365.457\n",
      "Epoch 3 ended after 0.758 minutes, with 20 rewards\n",
      "Time per reward: 0.038\n",
      "Loss: 40470.241\n",
      "Epoch 4 ended after 0.704 minutes, with 13 rewards\n",
      "Time per reward: 0.054\n",
      "Total time: 0.753\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70], [1, 1, 4, 5, 3], [15, 33, 30, 10, 1], [6, 3, 16, 20, 13]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 1010779.605\n",
      "Epoch 0 ended after 0.858 minutes, with 38 rewards\n",
      "Time per reward: 0.023\n",
      "Loss: 24517.938\n",
      "Epoch 1 ended after 0.595 minutes, with 11 rewards\n",
      "Time per reward: 0.054\n",
      "Loss: 24517.938\n",
      "Epoch 2 ended after 0.594 minutes, with 11 rewards\n",
      "Time per reward: 0.054\n",
      "Loss: 18.432\n",
      "Epoch 3 ended after 0.129 minutes, with 1 rewards\n",
      "Time per reward: 0.129\n",
      "Loss: 497.370\n",
      "Epoch 4 ended after 0.255 minutes, with 3 rewards\n",
      "Time per reward: 0.085\n",
      "Total time: 0.307\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70], [1, 1, 4, 5, 3], [15, 33, 30, 10, 1], [6, 3, 16, 20, 13], [38, 11, 11, 1, 3]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 18.432\n",
      "Epoch 0 ended after 0.043 minutes, with 1 rewards\n",
      "Time per reward: 0.043\n",
      "Loss: 126347.461\n",
      "Epoch 1 ended after 0.336 minutes, with 19 rewards\n",
      "Time per reward: 0.018\n",
      "Loss: 9431.400\n",
      "Epoch 2 ended after 0.251 minutes, with 8 rewards\n",
      "Time per reward: 0.031\n",
      "Loss: 147.377\n",
      "Epoch 3 ended after 0.115 minutes, with 2 rewards\n",
      "Time per reward: 0.057\n",
      "Loss: 40470.248\n",
      "Epoch 4 ended after 0.538 minutes, with 13 rewards\n",
      "Time per reward: 0.041\n",
      "Total time: 0.575\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70], [1, 1, 4, 5, 3], [15, 33, 30, 10, 1], [6, 3, 16, 20, 13], [38, 11, 11, 1, 3], [1, 19, 8, 2, 13]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n",
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 107429.422\n",
      "Epoch 0 ended after 0.312 minutes, with 18 rewards\n",
      "Time per reward: 0.017\n",
      "Loss: 90500.816\n",
      "Epoch 1 ended after 0.550 minutes, with 17 rewards\n",
      "Time per reward: 0.032\n",
      "Loss: 18.432\n",
      "Epoch 2 ended after 0.078 minutes, with 1 rewards\n",
      "Time per reward: 0.078\n",
      "Loss: 18.432\n",
      "Epoch 3 ended after 0.083 minutes, with 1 rewards\n",
      "Time per reward: 0.083\n",
      "Loss: 6318.305\n",
      "Epoch 4 ended after 0.332 minutes, with 7 rewards\n",
      "Time per reward: 0.047\n",
      "Total time: 0.369\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70], [1, 1, 4, 5, 3], [15, 33, 30, 10, 1], [6, 3, 16, 20, 13], [38, 11, 11, 1, 3], [1, 19, 8, 2, 13], [18, 17, 1, 1, 7]]\n",
      "INFO:tensorflow:Restoring parameters from development_trials/deleteme/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model from development_trials/deleteme/model.ckpt\n",
      "Loss: 24517.937\n",
      "Epoch 0 ended after 0.180 minutes, with 11 rewards\n",
      "Time per reward: 0.016\n",
      "Loss: 497.370\n",
      "Epoch 1 ended after 0.121 minutes, with 3 rewards\n",
      "Time per reward: 0.040\n",
      "Loss: 170593.935\n",
      "Epoch 2 ended after 0.590 minutes, with 21 rewards\n",
      "Time per reward: 0.028\n",
      "Loss: 18.432\n",
      "Epoch 3 ended after 0.081 minutes, with 1 rewards\n",
      "Time per reward: 0.081\n",
      "Loss: 2302.597\n",
      "Epoch 4 ended after 0.253 minutes, with 5 rewards\n",
      "Time per reward: 0.051\n",
      "Total time: 0.288\n",
      "[[54, 6, 8, 19, 26], [1, 36, 33, 17, 18], [1, 7, 8, 6, 29], [1, 3, 3, 24, 17], [3, 11, 4, 1, 17], [20, 15, 4, 9, 11], [1, 11, 5, 7, 14], [4, 26, 6, 19, 6], [6, 4, 17, 6, 16], [16, 39, 13, 4, 1], [1, 1, 10, 26, 27], [4, 4, 39, 12, 36], [6, 6, 1, 19, 70], [1, 1, 4, 5, 3], [15, 33, 30, 10, 1], [6, 3, 16, 20, 13], [38, 11, 11, 1, 3], [1, 19, 8, 2, 13], [18, 17, 1, 1, 7], [11, 3, 21, 1, 5]]\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for _ in range(20):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        testing = LSTM_SSM_model(sess, name = 'deleteme')\n",
    "        testing.build_new_LSTM()\n",
    "        testing.initialize_variables()\n",
    "        testing.new_train(5)\n",
    "        rewards.append(testing.rewards)\n",
    "    print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_0=np.eye(4)\n",
    "Q = np.eye(4)\n",
    "R = np.array([[1]])\n",
    "def testing_FDRE(P,A,B,X,Q,R):\n",
    "    T = np.eye(4)-(2/np.matmul(X.T,X))*np.matmul(X,X.T)\n",
    "    A_hat = -np.matmul(np.matmul(T,A),np.linalg.inv(T))\n",
    "    B_hat = np.matmul(T,B)\n",
    "    P_prime = -np.matmul(A_hat.T,P)-np.matmul(P,A_hat)+Q- \\\n",
    "                np.matmul(np.matmul(np.matmul(np.matmul(P,B_hat),np.linalg.inv(R)),B_hat.T),P)\n",
    "    return P_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_FDRE(P_0,A[0],B[0],X[0],Q,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(A.shape[0]):\n",
    "    for j in range(A.shape[1]):\n",
    "        if np.linalg.matrix_rank(ct.ctrb(A[i][j],B[i][j])) != 4:\n",
    "            print(np.linalg.matrix_rank(ct.ctrb(A[i][j],B[i][j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [example.z[0,x,0] for x in range(example.z.shape[0])]\n",
    "second = [example.z[0,x,1] for x in range(example.z.shape[0])]\n",
    "third = [example.z[0,x,2] for x in range(example.z.shape[0])]\n",
    "fourth = [example.z[0,x,3] for x in range(example.z.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(first)\n",
    "plt.plot(second)\n",
    "plt.plot(third)\n",
    "plt.plot(fourth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_magnitude = np.array([0.01,0.1,0.01,0.1])\n",
    "av_time = []\n",
    "\n",
    "env = gym.make('Custom_CartPole-v0', thetaacc_error=2, initial_state=1)\n",
    "g = env.gravity\n",
    "M = env.masscart\n",
    "m = env.masspole\n",
    "l = env.length\n",
    "Q = np.eye(4)*[10,1,1,1]\n",
    "R = 1\n",
    "\n",
    "'''System of equations'''\n",
    "A = np.array([[0,1,0,0],[0,0,-m*g/M,0],[0,0,0,1],[0,0,(M+m)*g/(l*M),0]])\n",
    "B = np.array([[0,1/M,0,-1/(l*M)]]).T\n",
    "\n",
    "\n",
    "'''LQR'''\n",
    "import time\n",
    "K,S,E = ct.lqr(A,B,Q,R)\n",
    "'''Pole Placement'''\n",
    "#K = ct.place(A,B,np.array([-1.1,-1.2,-1.3,-1.4]))\n",
    "\n",
    "\n",
    "#env.x_threshold = 5.0\n",
    "#env.theta_threshold_radians = 10.0\n",
    "\n",
    "\n",
    "states = [[] for _ in range(5)]\n",
    "rewards = np.array([0]*5)\n",
    "for i_episode in range(5):\n",
    "    observation = env.reset()\n",
    "    states[i_episode].append(observation)\n",
    "    for t in range(500):\n",
    "#         env.render()\n",
    "        u = -np.dot(K,observation)\n",
    "        observation, reward, done, info = env.step(u[0])\n",
    "        states[i_episode].append(observation)\n",
    "        if done:\n",
    "            print(\"Episode finished at time step {}\".format(t+1))\n",
    "            break\n",
    "        rewards[i_episode]+=1\n",
    "    print(\"Episode complete\")\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
