{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import control as ct\n",
    "import tensorflow as tf\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_filter_fn(A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z):\n",
    "    '''Calculates prior distribution based on the previous posterior distribution\n",
    "        and the current residual updates posterior distribution based on the new\n",
    "        prior distribution\n",
    "    '''\n",
    "#     print('z',z.shape)\n",
    "#     print('A', A.shape)\n",
    "#     print('B',B.shape)\n",
    "#     print('u',u.shape)\n",
    "#     print('g',g.shape)\n",
    "#     print('sigma',sigma.shape)\n",
    "#     print('C', C.shape)\n",
    "#     print('l_a_posteriori', l_a_posteriori.shape)\n",
    "#     print('P_a_posteriori', P_a_posteriori.shape)\n",
    "    _I = tf.eye(int(A.shape[0]), dtype = tf.float64)\n",
    "    \n",
    "    z = tf.expand_dims(z,-1)\n",
    "    l_a_priori = tf.matmul(A,l_a_posteriori) + tf.matmul(B,u)\n",
    "#     print('l_a_priori',l_a_priori.shape)\n",
    "    P_a_priori = tf.matmul(tf.matmul(A,P_a_posteriori), A, transpose_b = True) + tf.matmul(g,g, transpose_b=True)\n",
    "#     print('P_a_priori',P_a_priori.shape)\n",
    "    y_pre = z - tf.matmul(C,l_a_priori)\n",
    "#     print('y_pre', y_pre.shape)\n",
    "    S = tf.matmul(sigma, sigma, transpose_b=True) + \\\n",
    "        tf.matmul(tf.matmul(C, P_a_priori), C, transpose_b=True)\n",
    "#     print('S', S.shape)\n",
    "    \n",
    "    S_inv = tf.linalg.inv(S)\n",
    "    K = tf.matmul(tf.matmul(P_a_priori, C, transpose_b=True), S_inv)\n",
    "#     print('K', K.shape)\n",
    "    l_a_posteriori = l_a_priori + tf.matmul(K,y_pre)\n",
    "#     print('l_a_posteriori', l_a_posteriori.shape)\n",
    "    I_KC = _I-tf.matmul(K,C)\n",
    "#     print('I-KC', I_KC.shape)\n",
    "    P_a_posteriori = tf.matmul(tf.matmul(I_KC, P_a_priori), I_KC, transpose_b=True) + \\\n",
    "                        tf.matmul(tf.matmul(K,tf.matmul(sigma, sigma, transpose_b = True)),\n",
    "                                K, transpose_b=True)\n",
    "#     print('P_a_posteriori',P_a_posteriori.shape)\n",
    "    y_post = z-tf.matmul(C,l_a_posteriori)\n",
    "#     print('y_post', y_post.shape)\n",
    "    pred = tf.matmul(C, l_a_posteriori)\n",
    "#     print('pred', pred.shape)\n",
    "        \n",
    "    return A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z\n",
    "\n",
    "def dict_append(d,new_items,vals):\n",
    "            for idx,item in enumerate(vals):\n",
    "                d[item].append(new_items[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_SSM_model(object):\n",
    "    def __init__(self, sess, name, m = 4, n=4, r=1,\n",
    "                 learning_rate = 0.0001, lr_decay = 0.95, sigma_upper_bound = 1,\n",
    "                 sigma_lower_bound = 0, g_upper_bound = 1,\n",
    "                 g_lower_bound = 0.1, mu_0_upper_bound = 1,mu_0_lower_bound = 0,\n",
    "                 Sigma_0_upper_bound = 1, Sigma_0_lower_bound = 0, beta = 0.00001,\n",
    "                 b_upper_bound = 0.25, b_lower_bound = -0.25,thetaacc_error=0,initial_state=1.0\n",
    "                ):\n",
    "        \n",
    "        '''thetaacc_error gives the amount of random angular acceleration that can be put on the pendulum,\n",
    "        initial_state gives the amount of variation in the initial state\n",
    "        '''\n",
    "        if name == '':\n",
    "            raise NameError(\"A model has no name\")\n",
    "\n",
    "        '''This functions assumes the state space model:\n",
    "            l_(t+1) = A_(t)l_(t)+B(t)u_(t)\n",
    "            z_(t+1) = C_(t)l_(t)\n",
    "            where:\n",
    "            l has dim m\n",
    "            u has dim r\n",
    "            z has dim m\n",
    "            A has dim mxn\n",
    "            B has dim mxr\n",
    "            C has dim mxm\n",
    "            '''\n",
    "            \n",
    "        self.sess = sess\n",
    "        \n",
    "        '''nn model hyperparameters'''\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_sample_len = tf.Variable(200, name = 'sample_len', trainable=False)\n",
    "        self.global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "        self.increment_global_step = tf.assign_add(self.global_step,1, name = 'increment_global_step')\n",
    "        self.lr_decay = lr_decay\n",
    "        self.lstm_sizes = [128,64]\n",
    "        last_lstm = self.lstm_sizes[-1]\n",
    "\n",
    "        '''dims'''\n",
    "        self.m = m # size of the state space\n",
    "        self.dim_z = m\n",
    "        self.n = n\n",
    "        self.r = r\n",
    "        self.lstm_input_dim = m+4 # previous states plus physical parameters\n",
    "        \n",
    "        \n",
    "        self.initial_variance = 1\n",
    "        \n",
    "        '''error bounds'''\n",
    "        self.sigma_upper_bound = sigma_upper_bound\n",
    "        self.g_lower_bound = g_lower_bound\n",
    "        self.g_upper_bound = g_upper_bound\n",
    "        self.mu_0_upper_bound = mu_0_upper_bound\n",
    "        self.mu_0_lower_bound = mu_0_lower_bound\n",
    "        self.Sigma_0_upper_bound = Sigma_0_upper_bound\n",
    "        self.Sigma_0_lower_bound= Sigma_0_lower_bound\n",
    "        self.b_upper_bound = b_upper_bound\n",
    "        self.b_lower_bound = b_lower_bound\n",
    "        self.beta = beta\n",
    "        \n",
    "        '''LQR parameters'''\n",
    "        self.initial_state = tf.Variable(1.0, name = 'initial_state',trainable=False)\n",
    "#         self.\n",
    "        self.sess.run(self.initial_state.initializer)\n",
    "        self.env = gym.make('Custom_CartPole-v0', thetaacc_error=thetaacc_error, initial_state=self.initial_state.eval())\n",
    "        self.gravity = self.env.gravity\n",
    "        self.cart_mass = self.env.masscart\n",
    "        self.pole_mass = self.env.masspole\n",
    "        self.pole_length = self.env.length\n",
    "        self.env_params = tf.expand_dims(np.array([self.gravity, self.cart_mass,\n",
    "                                                   self.pole_mass,self.pole_length], dtype=np.float64),0)\n",
    "        self.Q = np.eye(4)*[1,1,1,1]\n",
    "        self.R = 1\n",
    "        \n",
    "        self.vals = ['A','B','u','C','l_a_posteriori','P_a_posteriori','g','sigma','z']\n",
    "        self.KF_states = dict.fromkeys(self.vals)\n",
    "        \n",
    "        self.y_0 = tf.Variable(tf.zeros([self.dim_z], dtype = tf.float64), dtype = tf.float64, name = 'y_0', trainable = False)\n",
    "        \n",
    "        '''Saving model stuff, don\"t need for now'''\n",
    "        self.model_folder = 'development_trials/{}'.format(name)\n",
    "        if not os.path.isdir(self.model_folder):\n",
    "            print('This model has no folder')\n",
    "            os.makedirs(self.model_folder)\n",
    "        self.saved_model_location = '{}/model.ckpt'.format(self.model_folder)\n",
    "\n",
    "        self.losses = []\n",
    "        \n",
    "        with tf.variable_scope('KF', reuse = tf.AUTO_REUSE):\n",
    "            self.C = tf.get_variable(initializer = tf.eye(self.dim_z, dtype = tf.float64),dtype = tf.float64,\n",
    "                                     name = 'C', trainable = False)\n",
    "            self.W_A = tf.get_variable(initializer = tf.random.normal([last_lstm, m*n], dtype=tf.float64),\n",
    "                                       dtype = tf.float64, name = 'W_A')\n",
    "            self.bias_A = tf.get_variable(initializer = tf.zeros([1, m*n], dtype=tf.float64),\n",
    "                                          dtype = tf.float64, name = 'bias_A')\n",
    "            \n",
    "            self.W_B = tf.get_variable(initializer = tf.random.normal([last_lstm, m*r], dtype=tf.float64),\n",
    "                                       dtype = tf.float64, name = 'W_B')\n",
    "            self.bias_B = tf.get_variable(initializer = tf.zeros([1, m*r], dtype=tf.float64),\n",
    "                                         dtype = tf.float64, name = 'bias_B')\n",
    "\n",
    "            self.W_g = tf.get_variable(initializer = tf.random.normal([last_lstm, m], dtype=tf.float64),\n",
    "                                       dtype = tf.float64, name = 'W_g')\n",
    "            self.bias_g = tf.get_variable(initializer = tf.zeros([1, m], dtype=tf.float64),\n",
    "                                          dtype = tf.float64, name = 'bias_g')\n",
    "\n",
    "            self.W_sigma = tf.get_variable(initializer = tf.random.normal([last_lstm, self.dim_z], dtype=tf.float64),\n",
    "                                           dtype = tf.float64, name = 'W_sigma')\n",
    "            self.bias_sigma = tf.get_variable(initializer = tf.zeros([1, self.dim_z], dtype=tf.float64),\n",
    "                                              dtype = tf.float64, name = 'bias_sigma')\n",
    "\n",
    "            self.W_mu_0 = tf.get_variable(initializer = tf.random.normal([last_lstm, self.m], dtype=tf.float64),\n",
    "                                          dtype = tf.float64, name = 'W_mu_0')\n",
    "            self.bias_mu_0 = tf.get_variable(initializer = tf.zeros([1, self.m], dtype=tf.float64),\n",
    "                                             dtype = tf.float64, name = 'bias_mu_0')\n",
    "            \n",
    "            self.W_Sigma_0 = tf.get_variable(initializer = tf.random.normal([last_lstm, self.m], dtype=tf.float64),\n",
    "                                             dtype = tf.float64, name = 'W_Sigma_0')\n",
    "            self.bias_Sigma_0 = tf.get_variable(initializer = tf.zeros([1, self.m], dtype=tf.float64),\n",
    "                                                dtype = tf.float64, name = 'bias_Sigma_0')\n",
    "            \n",
    "            self.P_0 = tf.Variable(self.initial_variance*tf.eye(self.m,dtype = tf.float64),\n",
    "                                   name = 'P_0', trainable = False)\n",
    "\n",
    "            self.y_0 = tf.Variable(tf.zeros([self.dim_z], dtype=tf.float64), dtype = tf.float64, name = 'y_0', trainable = False)\n",
    "            self.z_0 = tf.Variable(tf.zeros([self.dim_z, self.dim_z], dtype=tf.float64), dtype = tf.float64, name = 'z_0', trainable = False)\n",
    "            self.pred_0 = tf.Variable(tf.zeros([self.dim_z], dtype=tf.float64), dtype = tf.float64, name = 'pred_0', trainable = False)\n",
    "            \n",
    "            \n",
    "            '''Variables for test range in LQE only'''\n",
    "#             self.A_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, m, n], name = 'A_test')\n",
    "#             self.B_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, m, r], name = 'B_test')\n",
    "#             self.g_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, self.m, 1], name = 'g_test')\n",
    "#             self.sigma_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.test_range, self.dim_z, 1], name = 'sigma_test')\n",
    "#             self.l_0_test = tf.placeholder(tf.float32, shape = [self.batch_size, self.m, 1], name = 'l_0_test')\n",
    "#             self.final_z = tf.placeholder(tf.float32, shape = [self.batch_size, 1, self.dim_z], name = 'final_z')\n",
    "\n",
    "#         self.z = tf.placeholder(tf.float32, shape = [self.dim_z],name = 'z')\n",
    "        self.reward = tf.placeholder(tf.float64,shape = [])\n",
    "#         self.A = tf.placeholder(tf.float32, shape = [None, m,n])\n",
    "#         self.B = tf.placeholder(tf.float32, shape = [None, m,r])\n",
    "#         self.u = tf.placeholder(tf.float32, shape = [None, r,1])\n",
    "#         self.C = tf.placeholder(tf.float32, shape = [None, self.dim_z,m])\n",
    "#         self.g = tf.placeholder(tf.float32, shape = [None, m,1])\n",
    "#         self.sigma = tf.placeholder(tf.float32, shape = [None, dim_z,dim_z])\n",
    "#         with tf.variable_scope('LSTM', reuse = tf.AUTO_REUSE):\n",
    "#             self.lstm_input = tf.placeholder(tf.float32, shape = [None, self.lstm_input_dim],\n",
    "#                                             name = 'lstm_input')\n",
    "\n",
    "    def initialize_variables(self):\n",
    "        self.saver = tf.train.Saver()\n",
    "        try:\n",
    "            self.saver.restore(self.sess, tf.train.latest_checkpoint(self.model_folder))\n",
    "            print(\"Restoring model from {}\".format(self.saved_model_location))\n",
    "        except:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            print(\"Initializing new model at {}\".format(self.saved_model_location))\n",
    "        return self\n",
    "\n",
    "    def build_new_LSTM(self):\n",
    "        with tf.name_scope('LSTM'):\n",
    "            with tf.variable_scope('LSTM', reuse=tf.AUTO_REUSE):\n",
    "\n",
    "                lstms = [tf.contrib.rnn.LSTMCell(size, reuse=tf.get_variable_scope().reuse) for size in self.lstm_sizes]\n",
    "                dropouts = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = 0.5) for lstm in lstms]\n",
    "\n",
    "                self.cell = tf.contrib.rnn.MultiRNNCell(dropouts)\n",
    "#                 if prev_state:\n",
    "#                     initial_state = prev_state\n",
    "#                 else:\n",
    "#                     initial_state = cell.zero_state(self.batch_size, tf.float32)\n",
    "#                 self.lstm_output, self.final_state = tf.nn.dynamic_rnn(cell, self.lstm_input, initial_state = initial_state)\n",
    "        return self\n",
    "\n",
    "    def new_affine(self,lstm_output,first=False):\n",
    "        with tf.variable_scope('affine_transformations'):\n",
    "            if first:\n",
    "                mu_0 = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_mu_0), self.bias_mu_0))\n",
    "                self.mu_0 = ((self.mu_0_upper_bound-self.mu_0_lower_bound)/(1+tf.exp(-mu_0)))+self.mu_0_lower_bound\n",
    "\n",
    "                Sigma_0 = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_Sigma_0), self.bias_Sigma_0))\n",
    "                Sigma_0 = ((self.Sigma_0_upper_bound-self.Sigma_0_lower_bound)/(1+tf.exp(-Sigma_0)))+self.Sigma_0_lower_bound\n",
    "                self.Sigma_0 = tf.matmul(Sigma_0,Sigma_0,transpose_b=True)\n",
    "\n",
    "                l_0_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(self.mu_0),\n",
    "                                                                        covariance_matrix= self.Sigma_0,\n",
    "                                                                       validate_args=True)\n",
    "                self.l_0 = tf.expand_dims(l_0_distribution.sample(),1)\n",
    "                return self\n",
    "\n",
    "            A = tf.reshape(tf.add(tf.matmul(lstm_output, self.W_A), self.bias_A),shape=(self.m,self.n))\n",
    "            B = tf.reshape(tf.add(tf.matmul(lstm_output, self.W_B), self.bias_B),shape=(self.m,self.r))\n",
    "            \n",
    "            g = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_g), self.bias_g))\n",
    "            g = ((self.g_upper_bound-self.g_lower_bound)/(1+tf.exp(-g)))+self.g_lower_bound\n",
    "\n",
    "            sigma = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_sigma), self.bias_sigma))\n",
    "            sigma = (self.sigma_upper_bound)/(1+tf.exp(-sigma))\n",
    "            \n",
    "        return A,B,g,sigma\n",
    "\n",
    "    def likelihood_fn(self, params, inputs):\n",
    "        '''Compute likelihood over a batch\n",
    "        params contains: mu, Sigma - the parameters of the likelihood distribution\n",
    "        inputs contains: calculations of mu: F, a, l_filtered==l_a_posteriori\n",
    "                        calculations of Sigma: a, F, P_a_posteriori, g, sigma\n",
    "        '''\n",
    "        A, B, u, C, g, sigma, l_filtered, P_filtered = inputs\n",
    "        mu, Sigma = params\n",
    "        '''\n",
    "        a (bs, m, 1)\n",
    "        b (bs, 1)\n",
    "        F (bs, m, m)\n",
    "        g (bs, m, 1)\n",
    "        sigma (bs, 1, 1)\n",
    "        f (bs, m, 1)\n",
    "        S (bs, m, m)\n",
    "        mu (bs, 1, 1)\n",
    "        Sigma (bs, 1, 1)\n",
    "        '''\n",
    "#         print('A',A.shape)\n",
    "#         print('B',B.shape)\n",
    "#         print('u',u.shape)\n",
    "#         print('C',C.shape)\n",
    "#         print('g',g.shape)\n",
    "#         print('sigma',sigma.shape)\n",
    "#         print('l_filtered',l_filtered.shape)\n",
    "#         print('p_filtered',P_filtered.shape)\n",
    "#         print('mu',mu.shape)\n",
    "#         print('Sigma',Sigma.shape)\n",
    "        mu = tf.matmul(C, tf.add(tf.matmul(A,l_filtered), tf.matmul(B,u)))\n",
    "#         mu = tf.add(tf.matmul(tf.matmul(a, F, transpose_a=True), f), b)\n",
    "\n",
    "        temp = tf.matmul(tf.matmul(A, P_filtered), A, transpose_b=True) + tf.matmul(g, g, transpose_b=True)\n",
    "        Sigma = tf.matmul(tf.matmul(C, temp), C, transpose_b=True) + tf.matmul(sigma,sigma,transpose_b=True)\n",
    "\n",
    "#         temp = tf.matmul(tf.matmul(F, S), F, transpose_b=True) + tf.matmul(g, g, transpose_b=True)\n",
    "#         Sigma = tf.matmul(tf.matmul(a, temp, transpose_a=True), a) + tf.square(sigma)\n",
    "        \n",
    "        return mu, Sigma\n",
    "    \n",
    "    def calculate_new_loss(self,reward):\n",
    "        with tf.variable_scope('loss', reuse = tf.AUTO_REUSE):\n",
    "#             for key,value in self.KF_states.items():\n",
    "#                 print(key,value[0].shape)\n",
    "            print('mu_0',self.mu_0.shape)\n",
    "            print('Sigma_0',self.Sigma_0.shape)\n",
    "            print(self.Sigma_0.eval())\n",
    "            mu_1 = tf.matmul(self.KF_states['A'][0], self.mu_0)+\\\n",
    "                    tf.matmul(self.KF_states['B'][0],self.KF_states['u'][0])\n",
    "#             print(self.KF_states['sigma'][0])\n",
    "            Sigma_1 = tf.matmul(tf.matmul(self.KF_states['C'][0],self.Sigma_0,transpose_a=True),\n",
    "                                self.KF_states['C'][0])+tf.matmul(self.KF_states['sigma'][0],\n",
    "                                                                  self.KF_states['sigma'][0],transpose_b=True)\n",
    "            print('mu_1',mu_1.shape)\n",
    "            print('Sigma_1', Sigma_1.shape)\n",
    "            print(Sigma_1.eval())\n",
    "            \n",
    "            def make_tensor(l):\n",
    "                return tf.convert_to_tensor(l,dtype=tf.float64)\n",
    "            if reward>1:\n",
    "                mu, Sigma = tf.scan(self.likelihood_fn,\n",
    "                                    elems = (make_tensor(self.KF_states['A'][1:]),\n",
    "                                             make_tensor(self.KF_states['B'][1:]),\n",
    "                                             make_tensor(self.KF_states['u'][1:]),\n",
    "                                             make_tensor(self.KF_states['C'][1:]),\n",
    "                                             make_tensor(self.KF_states['g'][1:]),\n",
    "                                             make_tensor(self.KF_states['sigma'][1:]),\n",
    "                                             make_tensor(self.KF_states['l_a_posteriori'][:-1]),\n",
    "                                             make_tensor(self.KF_states['P_a_posteriori'][1:])),\n",
    "                                    initializer = (mu_1, Sigma_1))\n",
    "\n",
    "                self.mu = tf.concat([tf.expand_dims(mu_1,0), mu], 0)\n",
    "                self.Sigma = tf.concat([tf.expand_dims(Sigma_1,0),Sigma], 0)\n",
    "\n",
    "            else:\n",
    "                self.mu = tf.expand_dims(mu_1,0)\n",
    "                self.Sigma=tf.expand_dims(Sigma_1,0)\n",
    "#             print(self.mu.shape)\n",
    "            print(\"Sigma\",self.Sigma.shape)\n",
    "            print(self.Sigma.eval())\n",
    "            print(tf.linalg.det(tf.eye(self.m,batch_shape=[self.Sigma.shape[0]], dtype=tf.float64)+self.Sigma).eval())\n",
    "            print(tf.linalg.eigvalsh(tf.eye(self.m,batch_shape=[self.Sigma.shape[0]], dtype=tf.float64)+self.Sigma).eval())\n",
    "#             print(tf.linalg.inv(self.Sigma).eval())\n",
    "#             print(tf.linalg.cholesky(tf.matmul(self.Sigma,self.Sigma,transpose_b=True)).eval())\n",
    "        \n",
    "            '''TODO:\n",
    "                Find a legitimate way to get a symmetric covariance here. Needs to be decomposable by\n",
    "                cholesky decomposition. Does that mean is must be positive definite?\n",
    "            '''\n",
    "#             z_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(self.mu,-1), \\\n",
    "#                                 covariance_matrix = tf.add(5*tf.eye(self.m, batch_shape=[self.Sigma.shape[0]], dtype=tf.float64), \\\n",
    "#                                                            tf.matmul(self.Sigma,self.Sigma,transpose_a=True)), \\\n",
    "#                                                            validate_args=True)\n",
    "            z_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(self.mu,-1), \\\n",
    "                covariance_matrix = tf.eye(self.m,batch_shape=[self.Sigma.shape[0]],dtype = tf.float64)+self.Sigma)\n",
    "            self.z_probability = z_distribution.prob(tf.squeeze(self.KF_states['z'],-1))\n",
    "            regularizers = tf.nn.l2_loss(self.W_g) + tf.nn.l2_loss(self.W_mu_0) + \\\n",
    "                        tf.nn.l2_loss(self.W_sigma) + tf.nn.l2_loss(self.W_Sigma_0) + \\\n",
    "                        tf.nn.l2_loss(self.W_A) + tf.nn.l2_loss(self.W_B)\n",
    "            print(self.z_probability.eval())\n",
    "#             self.loss = tf.reduce_mean(self.beta*regularizers)- \\\n",
    "#                             (tf.math.square(tf.reciprocal(self.reward))* \\\n",
    "#                              tf.reduce_sum(tf.log(self.z_probability+1e-8)))\n",
    "            self.loss = tf.reduce_mean(self.beta*regularizers)-tf.math.square(self.reward)* \\\n",
    "                                tf.reduce_sum(tf.log(self.z_probability+1e-8))\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "#             self.optimizer = tf.train.AdamOptimizer(decayed_learning_rate)\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "#             for grad,var in grads_and_vars:\n",
    "#                 print(grad,var)\n",
    "#             capped_grads_and_vars = [(tf.clip_by_norm(grad, 1.), var) for grad, var in grads_and_vars]\n",
    "            capped_grads_and_vars = [gv if gv[0] is None else [tf.clip_by_value(gv[0], -10., 10.), gv[1]] for gv in grads_and_vars]\n",
    "            self.train_op = self.optimizer.apply_gradients(capped_grads_and_vars)\n",
    "        return self\n",
    "            \n",
    "    def LQR_DP_solve(Q, R, A, B):\n",
    "        return\n",
    "    \n",
    "    def new_train(self, epochs):\n",
    "        '''In this method, we require each epoch as 1 training sample\n",
    "            We will generate single steps at a time for input to the LSTM,\n",
    "            and then single step calculations of the optimal control\n",
    "        '''\n",
    "        \n",
    "        #Delete this section\n",
    "        Q = np.eye(4)*[10,1,1,1]\n",
    "        R = 1\n",
    "        \n",
    "        \n",
    "\n",
    "        self.rewards = [0 for _ in range(epochs)]\n",
    "#         self.environment_states = [[] for _ in range(epochs)]\n",
    "#         self.KF_states = [[] for _ in range(epochs)]\n",
    "            # required for likelihood/loss: A,B,u,C,l_a_posteriori,P_a_posteriorig,sigma\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for i in range(epochs):\n",
    "            start = time.time()\n",
    "            self.environment_states=[]\n",
    "            self.KF_states = {'A':[],'B':[],'u':[],'C':[],'l_a_posteriori':[],'P_a_posteriori':[],\n",
    "                             'g':[],'sigma':[],'z':[]}\n",
    "            \n",
    "            done = False\n",
    "            observation = self.env.reset()\n",
    "            self.environment_states.append(tf.convert_to_tensor(observation,dtype=tf.float64))\n",
    "            preds = []\n",
    "            epoch_loss = []\n",
    "            initial_state = self.cell.zero_state(batch_size=1,dtype=tf.float64)\n",
    "            initial_input = tf.concat((self.env_params,np.zeros(shape=[1,4])),axis=1)\n",
    "#             print(initial_input.shape)\n",
    "#             for item in initial_state:\n",
    "#                 print(type(item))\n",
    "#                 print(item)\n",
    "            with tf.variable_scope('LSTM', reuse=tf.AUTO_REUSE):\n",
    "                output_single,state_single = self.cell(inputs = initial_input, state = initial_state)\n",
    "                self.new_affine(output_single, first=True)\n",
    "            \n",
    "            u = tf.zeros(shape = [1,self.r], dtype=tf.float64)\n",
    "            l_a_posteriori = self.l_0\n",
    "            P_a_posteriori = self.P_0\n",
    "            \n",
    "            uninitialized_vars= []\n",
    "            for var in tf.global_variables():\n",
    "                try:\n",
    "                    sess.run(var)\n",
    "                except tf.errors.FailedPreconditionError:\n",
    "                    uninitialized_vars.append(var)\n",
    "                    \n",
    "#             print(uninitialized_vars)\n",
    "            init_new_vars_op = self.sess.run(tf.variables_initializer(uninitialized_vars))\n",
    "#             self.sess.run(tf.global_variables_initializer())\n",
    "            while not done:\n",
    "                #Try parameterizing u by NN, include it in new_affine\n",
    "                \n",
    "                \n",
    "                '''Get these values from a sess.run with placeholder???'''\n",
    "                A, B, g, sigma = self.new_affine(output_single)\n",
    "#                 A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z = \\\n",
    "#                         forward_filter_fn(A,B,u,self.C,l_a_posteriori,\n",
    "#                                           P_a_posteriori,g,sigma,self.environment_states[-1])\n",
    "                dict_append(self.KF_states, forward_filter_fn(A,B,u,self.C,l_a_posteriori,\n",
    "                                                         P_a_posteriori,g,sigma,\n",
    "                                                         self.environment_states[-1]),\n",
    "                           self.vals)\n",
    "#                 self.KF_states.append((A,B,u,C,l_a_posteriori,P_a_posteriori,g,sigma,z))\n",
    "                \n",
    "                \n",
    "                #Delete this section\n",
    "                K,S,E = ct.lqr(self.KF_states['A'][-1].eval(),self.KF_states['B'][-1].eval(),Q,R)\n",
    "                u = -tf.matmul(K.astype(np.float64),tf.expand_dims(self.environment_states[-1],-1))\n",
    "                #u needs to be chosen in a better fashion\n",
    "                \n",
    "                observation,reward,done,info = self.env.step(np.squeeze(u.eval()))\n",
    "                self.environment_states.append(tf.convert_to_tensor(observation,dtype=tf.float64))\n",
    "                self.rewards[i] += 1\n",
    "                \n",
    "                '''Calculate filtered distributions with KF\n",
    "                    Approximate the control\n",
    "                    Call the next step with calculated control\n",
    "                    update lstm input with output of the observation\n",
    "                '''\n",
    "                next_input = tf.concat((self.env_params,tf.expand_dims(self.environment_states[-1],0)),axis=1)\n",
    "                output_single,state_single = self.cell(inputs=next_input,state=state_single)\n",
    "                \n",
    "#             for key,value in self.KF_states.items():\n",
    "#                 print(key)\n",
    "#                 for item in value:\n",
    "#                     print(item.shape)\n",
    "            self.calculate_new_loss(self.rewards[i])\n",
    "#             self.calculate_new_loss(self.rewards[i])\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            feed_dict={self.reward:self.rewards[i]}\n",
    "#             loss_, _,_ = self.sess.run([self.loss, self.train_op, self.increment_global_step], feed_dict=feed_dict)\n",
    "            loss_, _ = self.sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "\n",
    "            \n",
    "#             print(self.sess.run(self.global_step))\n",
    "            \n",
    "            \n",
    "            print('Loss: {:.3f}'.format(loss_))\n",
    "            print(\"Epoch {} ended after {:.3f} minutes, with {} rewards\\nTime per reward: {:.3f}\".\n",
    "                  format(i,(time.time()-start)/60,self.rewards[i],(time.time()-start)/(60*self.rewards[i])))\n",
    "        self.saver.save(self.sess, self.saved_model_location)#, global_step=self.global_step)\n",
    "#             print(\"Model Saved at {}\".format(self.saved_model_location))\n",
    "        print(\"Total time: {:.3f}\".format((time.time()-start)/60))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new model at development_trials/deleteme/model.ckpt\n",
      "mu_0 (4, 1)\n",
      "Sigma_0 (4, 4)\n",
      "[[0.24209643 0.23110354 0.28521619 0.18957926]\n",
      " [0.23110354 0.2206098  0.27226535 0.18097102]\n",
      " [0.28521619 0.27226535 0.336016   0.22334519]\n",
      " [0.18957926 0.18097102 0.22334519 0.14845446]]\n",
      "mu_1 (4, 1)\n",
      "Sigma_1 (4, 4)\n",
      "[[0.43805782 0.45201799 0.52606263 0.34615477]\n",
      " [0.45201799 0.46734999 0.54335619 0.36486995]\n",
      " [0.52606263 0.54335619 0.63204911 0.42008007]\n",
      " [0.34615477 0.36486995 0.42008007 0.33722643]]\n",
      "Sigma (41, 4, 4)\n",
      "[[[ 6.38876670e-01  4.79518963e-01  6.40663303e-01  5.41165298e-01]\n",
      "  [ 4.79518963e-01  3.61617467e-01  4.81802374e-01  4.06275118e-01]\n",
      "  [ 6.40663303e-01  4.81802374e-01  6.42975258e-01  5.42731112e-01]\n",
      "  [ 5.41165298e-01  4.06275118e-01  5.42731112e-01  4.58403428e-01]]\n",
      "\n",
      " [[ 6.58043694e-01  3.83976498e-01  5.56191215e-01  4.82786389e-01]\n",
      "  [ 3.83976498e-01  5.00554122e-01  5.20057228e-01  5.47202964e-01]\n",
      "  [ 5.56191215e-01  5.20057228e-01  6.19102676e-01  6.00693632e-01]\n",
      "  [ 4.82786389e-01  5.47202964e-01  6.00693632e-01  6.11363917e-01]]\n",
      "\n",
      " [[ 1.93839602e+00  9.43268297e-01  5.65166819e-01  3.69868701e-01]\n",
      "  [ 9.43268297e-01  5.25674473e-01  4.61884145e-01  4.53339202e-01]\n",
      "  [ 5.65166819e-01  4.61884145e-01  6.92591887e-01  8.72456767e-01]\n",
      "  [ 3.69868701e-01  4.53339202e-01  8.72456767e-01  1.19223327e+00]]\n",
      "\n",
      " [[ 3.50954776e-01  1.69986153e-01  4.02408073e-01  5.86661168e-01]\n",
      "  [ 1.69986153e-01  3.37057550e-01  3.39720638e-01  2.29469623e-01]\n",
      "  [ 4.02408073e-01  3.39720638e-01  1.51040462e+00  1.82100976e+00]\n",
      "  [ 5.86661168e-01  2.29469623e-01  1.82100976e+00  2.43141324e+00]]\n",
      "\n",
      " [[ 3.97000730e+00  1.63441845e+00 -4.97589023e-01 -2.00958728e+00]\n",
      "  [ 1.63441845e+00  8.98920720e-01 -2.05039118e-01 -7.19658043e-01]\n",
      "  [-4.97589023e-01 -2.05039118e-01  2.83523184e-01  8.70472334e-01]\n",
      "  [-2.00958728e+00 -7.19658043e-01  8.70472334e-01  2.79929502e+00]]\n",
      "\n",
      " [[ 9.49737206e-01  5.93331789e-01  4.06300594e-01  8.12793496e-01]\n",
      "  [ 5.93331789e-01  3.17508113e+00  2.85626074e+00 -3.55255375e+00]\n",
      "  [ 4.06300594e-01  2.85626074e+00  2.71540594e+00 -3.61226925e+00]\n",
      "  [ 8.12793496e-01 -3.55255375e+00 -3.61226925e+00  6.86576711e+00]]\n",
      "\n",
      " [[ 3.81480282e+00  4.14232605e+00  5.37233350e+00 -2.50183535e+00]\n",
      "  [ 4.14232605e+00  5.95685300e+00  7.73778895e+00 -4.58330389e+00]\n",
      "  [ 5.37233350e+00  7.73778895e+00  1.08312655e+01 -6.59690316e+00]\n",
      "  [-2.50183535e+00 -4.58330389e+00 -6.59690316e+00  4.54962408e+00]]\n",
      "\n",
      " [[ 1.83671837e+00  2.24306170e+00 -1.98729304e+00  3.03578529e-01]\n",
      "  [ 2.24306170e+00  7.55872571e+00 -1.12445308e+01 -1.87676754e+00]\n",
      "  [-1.98729304e+00 -1.12445308e+01  1.83760525e+01  3.92129693e+00]\n",
      "  [ 3.03578529e-01 -1.87676754e+00  3.92129693e+00  1.30172544e+00]]\n",
      "\n",
      " [[ 1.53213313e+00  1.00485026e+00  1.59913964e+00 -1.49449603e+00]\n",
      "  [ 1.00485026e+00  6.79940613e-01  1.23753978e+00 -1.44664710e+00]\n",
      "  [ 1.59913964e+00  1.23753978e+00  3.37955648e+00 -5.77415570e+00]\n",
      "  [-1.49449603e+00 -1.44664710e+00 -5.77415570e+00  1.18667288e+01]]\n",
      "\n",
      " [[ 3.73817459e+00  8.26403445e-01 -2.62698116e+00  1.10893272e+00]\n",
      "  [ 8.26403445e-01  2.69290805e-01 -5.48995325e-01  4.03435348e-01]\n",
      "  [-2.62698116e+00 -5.48995325e-01  4.05422923e+00 -4.92247689e-02]\n",
      "  [ 1.10893272e+00  4.03435348e-01 -4.92247689e-02  8.23886626e-01]]\n",
      "\n",
      " [[ 9.10531885e-01  5.43441908e-01  1.21337300e+00  4.15849978e-01]\n",
      "  [ 5.43441908e-01  3.66266734e-01  4.68837626e-01  2.91034406e-01]\n",
      "  [ 1.21337300e+00  4.68837626e-01  3.17322848e+00  2.88731687e-01]\n",
      "  [ 4.15849978e-01  2.91034406e-01  2.88731687e-01  2.58973870e-01]]\n",
      "\n",
      " [[ 5.63910073e-01 -1.55995472e-01  4.02566705e-01  7.06352439e-01]\n",
      "  [-1.55995472e-01  2.73517349e+00 -9.02914971e-01 -4.18406123e-01]\n",
      "  [ 4.02566705e-01 -9.02914971e-01  5.52224773e-01  5.96080343e-01]\n",
      "  [ 7.06352439e-01 -4.18406123e-01  5.96080343e-01  9.24726611e-01]]\n",
      "\n",
      " [[ 1.46842607e+00 -1.21741166e-01 -7.78009520e-01  1.56061709e+00]\n",
      "  [-1.21741166e-01  1.52761264e+00  4.77548457e+00 -2.73061619e+00]\n",
      "  [-7.78009520e-01  4.77548457e+00  1.56746651e+01 -9.04681471e+00]\n",
      "  [ 1.56061709e+00 -2.73061619e+00 -9.04681471e+00  6.15029178e+00]]\n",
      "\n",
      " [[ 1.06359194e+01 -5.54708718e+00 -4.00547834e+00 -5.18442455e+00]\n",
      "  [-5.54708718e+00  3.16059149e+00  2.36649201e+00  3.49760214e+00]\n",
      "  [-4.00547834e+00  2.36649201e+00  1.80112083e+00  2.78731380e+00]\n",
      "  [-5.18442455e+00  3.49760214e+00  2.78731380e+00  4.90977764e+00]]\n",
      "\n",
      " [[ 2.25155987e+00 -1.44156237e+00 -3.63164989e+00 -3.96127938e+00]\n",
      "  [-1.44156237e+00  4.63273897e+00  7.51089321e+00  9.31585458e+00]\n",
      "  [-3.63164989e+00  7.51089321e+00  1.31578518e+01  1.60000177e+01]\n",
      "  [-3.96127938e+00  9.31585458e+00  1.60000177e+01  1.97077227e+01]]\n",
      "\n",
      " [[ 6.70139623e+00  7.86689750e+00 -1.26423404e+00  2.49551358e+00]\n",
      "  [ 7.86689750e+00  9.43411470e+00 -1.88539408e+00  2.82646492e+00]\n",
      "  [-1.26423404e+00 -1.88539408e+00  1.65343243e+00  4.45847941e-02]\n",
      "  [ 2.49551358e+00  2.82646492e+00  4.45847941e-02  1.13881110e+00]]\n",
      "\n",
      " [[ 5.52521168e+00 -4.43881688e+00  1.01400793e+00 -6.40184839e-01]\n",
      "  [-4.43881688e+00  4.51177575e+00 -1.75238759e-01  1.59825374e+00]\n",
      "  [ 1.01400793e+00 -1.75238759e-01  6.46215142e-01  6.98412215e-01]\n",
      "  [-6.40184839e-01  1.59825374e+00  6.98412215e-01  1.56436377e+00]]\n",
      "\n",
      " [[ 3.50436918e+00  4.47828133e+00 -1.75578308e+00  1.61271088e+00]\n",
      "  [ 4.47828133e+00  7.28702992e+00 -3.41163234e+00  2.15715265e+00]\n",
      "  [-1.75578308e+00 -3.41163234e+00  3.85074075e+00 -7.93208303e-01]\n",
      "  [ 1.61271088e+00  2.15715265e+00 -7.93208303e-01  7.51670312e-01]]\n",
      "\n",
      " [[ 2.80513537e+01  1.20991227e+01 -3.39311952e+01 -1.72598615e+01]\n",
      "  [ 1.20991227e+01  5.30886658e+00 -1.51576531e+01 -7.89275734e+00]\n",
      "  [-3.39311952e+01 -1.51576531e+01  4.45097058e+01  2.37259817e+01]\n",
      "  [-1.72598615e+01 -7.89275734e+00  2.37259817e+01  1.29915095e+01]]\n",
      "\n",
      " [[ 2.33607928e+00  1.69774810e+00 -2.70066719e+00 -1.07034802e+00]\n",
      "  [ 1.69774810e+00  1.24336517e+00 -2.12748973e+00 -8.51046456e-01]\n",
      "  [-2.70066719e+00 -2.12748973e+00  5.97493085e+00  2.54314917e+00]\n",
      "  [-1.07034802e+00 -8.51046456e-01  2.54314917e+00  1.77550485e+00]]\n",
      "\n",
      " [[ 1.55659245e+00 -1.50298019e+00  2.95101109e+00  1.03757468e+00]\n",
      "  [-1.50298019e+00  4.55120926e+00 -5.22881152e+00 -1.85981857e+00]\n",
      "  [ 2.95101109e+00 -5.22881152e+00  7.61773431e+00  2.70195245e+00]\n",
      "  [ 1.03757468e+00 -1.85981857e+00  2.70195245e+00  9.58696694e-01]]\n",
      "\n",
      " [[ 2.14097445e-01 -9.82790949e-02 -6.71126874e-02  5.24733256e-01]\n",
      "  [-9.82790949e-02  8.97327016e-01  3.08194922e+00 -2.77705590e-01]\n",
      "  [-6.71126874e-02  3.08194922e+00  1.09483395e+01 -3.08380408e-01]\n",
      "  [ 5.24733256e-01 -2.77705590e-01 -3.08380408e-01  1.32981727e+00]]\n",
      "\n",
      " [[ 3.78465275e+00  1.79465582e+00 -4.15664319e-01 -1.40729585e+00]\n",
      "  [ 1.79465582e+00  8.76760450e-01 -2.99517631e-01 -8.74777164e-01]\n",
      "  [-4.15664319e-01 -2.99517631e-01  4.53108288e-01  9.82516682e-01]\n",
      "  [-1.40729585e+00 -8.74777164e-01  9.82516682e-01  2.27452397e+00]]\n",
      "\n",
      " [[ 1.08337034e+00  6.80616141e-01  3.26530603e-01  1.84770248e-01]\n",
      "  [ 6.80616141e-01  3.11301669e+00 -3.55721818e+00 -2.45651479e+00]\n",
      "  [ 3.26530603e-01 -3.55721818e+00  5.68777265e+00  3.72707296e+00]\n",
      "  [ 1.84770248e-01 -2.45651479e+00  3.72707296e+00  2.51016907e+00]]\n",
      "\n",
      " [[ 1.27053493e+01  3.84301464e+00  1.56200557e+00 -6.17472797e+00]\n",
      "  [ 3.84301464e+00  1.19640398e+00  5.76205693e-01 -1.86207089e+00]\n",
      "  [ 1.56200557e+00  5.76205693e-01  1.40785326e+00  3.27374759e-01]\n",
      "  [-6.17472797e+00 -1.86207089e+00  3.27374759e-01  4.27347256e+00]]\n",
      "\n",
      " [[ 2.45172468e-01 -3.72518095e-01  6.02114449e-02  2.43903106e-01]\n",
      "  [-3.72518095e-01  4.49770125e+00  2.29258045e+00  1.40139429e-01]\n",
      "  [ 6.02114449e-02  2.29258045e+00  1.64013613e+00  4.02533795e-01]\n",
      "  [ 2.43903106e-01  1.40139429e-01  4.02533795e-01  3.15022672e-01]]\n",
      "\n",
      " [[ 1.18504127e+00  1.18827962e+00  5.46902355e-01  6.89317912e-01]\n",
      "  [ 1.18827962e+00  1.99060024e+00 -4.31978971e-02  8.80674261e-01]\n",
      "  [ 5.46902355e-01 -4.31978971e-02  7.17656775e-01  2.70554921e-01]\n",
      "  [ 6.89317912e-01  8.80674261e-01  2.70554921e-01  7.61051089e-01]]\n",
      "\n",
      " [[ 2.01838781e+00  1.22842926e+00 -4.65467224e-01  9.15565570e-01]\n",
      "  [ 1.22842926e+00  1.11767092e+00 -9.59295424e-01  5.87006282e-01]\n",
      "  [-4.65467224e-01 -9.59295424e-01  3.39172504e+00 -2.91980727e-01]\n",
      "  [ 9.15565570e-01  5.87006282e-01 -2.91980727e-01  4.18048996e-01]]\n",
      "\n",
      " [[ 6.96158965e-01  1.86690613e+00 -1.25899871e+00  3.16685739e-01]\n",
      "  [ 1.86690613e+00  5.32761713e+00 -3.52098535e+00  7.04757438e-01]\n",
      "  [-1.25899871e+00 -3.52098535e+00  3.10311216e+00 -3.90299570e-01]\n",
      "  [ 3.16685739e-01  7.04757438e-01 -3.90299570e-01  2.27177731e-01]]\n",
      "\n",
      " [[ 8.87010288e-01 -6.40128012e-01 -8.16601597e-01  4.80842113e-01]\n",
      "  [-6.40128012e-01  1.19781676e+00  1.49406151e+00 -2.28626242e-01]\n",
      "  [-8.16601597e-01  1.49406151e+00  1.87416415e+00 -3.02982840e-01]\n",
      "  [ 4.80842113e-01 -2.28626242e-01 -3.02982840e-01  2.83147545e-01]]\n",
      "\n",
      " [[ 5.69081559e+00  1.55757722e+00 -6.71844219e+00  1.64414667e+00]\n",
      "  [ 1.55757722e+00  4.51272751e-01 -2.18692153e+00  3.37217897e-01]\n",
      "  [-6.71844219e+00 -2.18692153e+00  1.28050294e+01 -4.15286828e-01]\n",
      "  [ 1.64414667e+00  3.37217897e-01 -4.15286828e-01  1.09522354e+00]]\n",
      "\n",
      " [[ 4.74644403e-01  3.54541261e-01 -2.61727023e-01  7.57006178e-01]\n",
      "  [ 3.54541261e-01  8.43049064e-01 -1.55216748e+00  2.05074518e+00]\n",
      "  [-2.61727023e-01 -1.55216748e+00  8.53681839e+00 -5.44831202e+00]\n",
      "  [ 7.57006178e-01  2.05074518e+00 -5.44831202e+00  5.48144605e+00]]\n",
      "\n",
      " [[ 5.03067756e-01  5.32949705e-01  6.40910161e-01  8.09499667e-02]\n",
      "  [ 5.32949705e-01  3.08877926e+00  1.18419734e+00 -8.27256047e-01]\n",
      "  [ 6.40910161e-01  1.18419734e+00  9.55509394e-01 -7.21694352e-02]\n",
      "  [ 8.09499667e-02 -8.27256047e-01 -7.21694352e-02  3.44733160e-01]]\n",
      "\n",
      " [[ 7.57948980e+00  7.07985633e+00  7.48623183e-01  1.37030697e+00]\n",
      "  [ 7.07985633e+00  6.70385006e+00  9.52176891e-01  1.25848846e+00]\n",
      "  [ 7.48623183e-01  9.52176891e-01  8.70700948e-01  3.23818624e-01]\n",
      "  [ 1.37030697e+00  1.25848846e+00  3.23818624e-01  9.27029177e-01]]\n",
      "\n",
      " [[ 2.02122137e+00  2.72602461e+00  3.54898951e+00  1.10469747e+00]\n",
      "  [ 2.72602461e+00  6.00632913e+00  6.63639718e+00  2.14469357e+00]\n",
      "  [ 3.54898951e+00  6.63639718e+00  7.70922799e+00  2.45437880e+00]\n",
      "  [ 1.10469747e+00  2.14469357e+00  2.45437880e+00  7.90904583e-01]]\n",
      "\n",
      " [[ 6.68325969e+00  1.02916899e+01  7.00275437e+00 -2.16607366e+00]\n",
      "  [ 1.02916899e+01  1.60340193e+01  1.06468637e+01 -3.59931823e+00]\n",
      "  [ 7.00275437e+00  1.06468637e+01  7.44129176e+00 -2.06471863e+00]\n",
      "  [-2.16607366e+00 -3.59931823e+00 -2.06471863e+00  1.11456630e+00]]\n",
      "\n",
      " [[ 9.05991300e-01 -1.61967745e+00 -1.88072661e+00  2.54190075e-01]\n",
      "  [-1.61967745e+00  9.39782695e+00  1.29251866e+01  2.30592840e+00]\n",
      "  [-1.88072661e+00  1.29251866e+01  1.79774204e+01  3.52408556e+00]\n",
      "  [ 2.54190075e-01  2.30592840e+00  3.52408556e+00  1.25014653e+00]]\n",
      "\n",
      " [[ 1.08070684e+00 -1.72265492e-01  1.44358070e+00  2.06867388e-01]\n",
      "  [-1.72265492e-01  4.59224935e+00 -4.16778329e+00  2.44379237e+00]\n",
      "  [ 1.44358070e+00 -4.16778329e+00  5.82540397e+00 -1.35405689e+00]\n",
      "  [ 2.06867388e-01  2.44379237e+00 -1.35405689e+00  1.89536231e+00]]\n",
      "\n",
      " [[ 2.56045701e+00  4.56737088e+00  3.11411544e+00  1.89342613e+00]\n",
      "  [ 4.56737088e+00  1.10370809e+01  6.09787273e+00  3.07095317e+00]\n",
      "  [ 3.11411544e+00  6.09787273e+00  4.30469154e+00  2.21789881e+00]\n",
      "  [ 1.89342613e+00  3.07095317e+00  2.21789881e+00  1.43448948e+00]]\n",
      "\n",
      " [[ 5.40441687e+00 -5.11153908e+00  2.50666903e+00 -2.08750606e+00]\n",
      "  [-5.11153908e+00  6.93229453e+00 -1.95657806e+00  4.49107220e+00]\n",
      "  [ 2.50666903e+00 -1.95657806e+00  1.70651789e+00 -3.96742063e-01]\n",
      "  [-2.08750606e+00  4.49107220e+00 -3.96742063e-01  3.83761865e+00]]\n",
      "\n",
      " [[ 3.54533940e+00  5.41640750e+00  5.30571690e-01  6.13974791e+00]\n",
      "  [ 5.41640750e+00  9.31242052e+00 -8.94793542e-03  9.89257347e+00]\n",
      "  [ 5.30571690e-01 -8.94793542e-03  7.26769271e-01  5.13947387e-01]\n",
      "  [ 6.13974791e+00  9.89257347e+00  5.13947387e-01  1.09683617e+01]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.00948328   6.546448    10.67232431  17.58633205   8.14945968\n",
      "   6.34517056   8.11819253  98.43306812  75.89290518 186.53167739\n",
      "   8.3805684    9.01245452  34.42790284  69.19800948  43.11513891\n",
      "  75.16248263 103.76624338  27.03883758  39.12773749  25.75219593\n",
      "  73.7906117   11.75720988  43.72108935  21.54176639  43.61920996\n",
      " 170.8252382   39.03080383  94.33367378  20.78479036   7.94262674\n",
      "  22.33557378  60.94499036  15.80546479  18.86540198  64.92234471\n",
      "  33.53207457  29.68460772  82.5631865  452.33442219  33.55311419\n",
      "  74.71390869]\n",
      "[[ 1.          1.          1.0048519   3.2404096 ]\n",
      " [ 1.          1.02042417  1.9539709   3.0073564 ]\n",
      " [ 1.          1.01940834  2.59222333  9.2374002 ]\n",
      " [ 1.          1.02165207  2.91899446  5.84833681]\n",
      " [ 1.          1.06578127  2.13362938  4.29592504]\n",
      " [ 1.          1.00504016  2.30071595  5.19376461]\n",
      " [ 1.          1.01152793  2.10797731  8.72266321]\n",
      " [ 1.          1.01549483  3.32090478  8.53594979]\n",
      " [ 1.          1.09134852  2.32318842  5.47132633]\n",
      " [ 1.          1.15822605  2.48505895 15.39079502]\n",
      " [ 1.          1.03579949  2.82523986 24.3533378 ]\n",
      " [ 1.          1.08376509  1.9525669  11.7005746 ]\n",
      " [ 1.          1.25151068  3.57790802 56.50647807]\n",
      " [ 1.          1.00278061  2.31542407 16.18327755]\n",
      " [ 1.          1.13514169  2.397564   38.44564056]\n",
      " [ 1.          1.00354086  2.03328485 17.98268525]\n",
      " [ 1.          1.04256605  2.89559755 43.34104196]\n",
      " [ 1.          1.01518393  2.6644406  14.33338109]\n",
      " [ 1.          1.20618816  2.07635927  4.61942113]\n",
      " [ 1.          1.19846295  1.85943032 24.82556674]\n",
      " [ 1.          1.00205884  2.11365211 20.99686383]\n",
      " [ 1.          1.44220177  1.93522548 11.00696026]\n",
      " [ 1.          1.00749536  1.64850478  4.68069924]\n",
      " [ 1.          1.21561109  2.93125174  9.22029608]\n",
      " [ 1.          1.02282742  4.24089524  8.49867935]\n",
      " [ 1.          1.33160623  2.64704725 41.41123635]\n",
      " [ 1.          1.15029388  2.48733128 11.8716447 ]\n",
      " [ 1.          1.15404696  2.58349256 30.40012415]\n",
      " [ 1.          1.0206531   2.03620525 34.12475145]\n",
      " [ 1.          1.02632654  2.50859379 12.70455358]\n",
      " [ 1.          1.0369276   4.05950731  8.81201554]\n",
      " [ 1.          1.00812057  2.55757187 27.42665338]\n",
      " [ 1.          1.37923076  4.40424723  6.00981245]\n",
      " [ 1.          1.09188833  2.31813334  8.00664298]\n",
      " [ 1.          1.01553305  3.74444409 45.14963245]\n",
      " [ 1.          1.22712273  3.58829025 25.21971498]\n",
      " [ 1.          1.09603925  3.10000185 28.65902598]\n",
      " [ 1.          1.15396657  3.38517765 11.10975878]\n",
      " [ 1.          1.09022441  2.68280456 30.5230047 ]\n",
      " [ 1.          1.05419087  4.53092798 11.90095939]\n",
      " [ 1.          1.32113377  3.10212749 18.65087531]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cholesky decomposition was not successful. The input might not be valid.\n\t [[node LSTM_1/affine_transformations/MultivariateNormalFullCovariance/init/Cholesky (defined at /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mvn_full_covariance.py:181) ]]\n\nCaused by op 'LSTM_1/affine_transformations/MultivariateNormalFullCovariance/init/Cholesky', defined at:\n  File \"/home/alon/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/alon/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/alon/anaconda3/lib/python3.7/asyncio/base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"/home/alon/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"/home/alon/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-54-c6d52af6914f>\", line 7, in <module>\n    testing.new_train(5)\n  File \"<ipython-input-53-375a6f85987a>\", line 358, in new_train\n    self.new_affine(output_single, first=True)\n  File \"<ipython-input-53-375a6f85987a>\", line 187, in new_affine\n    validate_args=True)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mvn_full_covariance.py\", line 181, in __init__\n    scale_tril = tf.cholesky(covariance_matrix)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 767, in cholesky\n    \"Cholesky\", input=input, name=name)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n\t [[node LSTM_1/affine_transformations/MultivariateNormalFullCovariance/init/Cholesky (defined at /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mvn_full_covariance.py:181) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cholesky decomposition was not successful. The input might not be valid.\n\t [[{{node LSTM_1/affine_transformations/MultivariateNormalFullCovariance/init/Cholesky}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c6d52af6914f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_new_LSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-375a6f85987a>\u001b[0m in \u001b[0;36mnew_train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;31m#                 for item in value:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;31m#                     print(item.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_new_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;31m#             self.calculate_new_loss(self.rewards[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-375a6f85987a>\u001b[0m in \u001b[0;36mcalculate_new_loss\u001b[0;34m(self, reward)\u001b[0m\n\u001b[1;32m    298\u001b[0m                         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_Sigma_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_A\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;31m#             self.loss = tf.reduce_mean(self.beta*regularizers)- \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;31m#                             (tf.math.square(tf.reciprocal(self.reward))* \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cholesky decomposition was not successful. The input might not be valid.\n\t [[node LSTM_1/affine_transformations/MultivariateNormalFullCovariance/init/Cholesky (defined at /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mvn_full_covariance.py:181) ]]\n\nCaused by op 'LSTM_1/affine_transformations/MultivariateNormalFullCovariance/init/Cholesky', defined at:\n  File \"/home/alon/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/alon/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/alon/anaconda3/lib/python3.7/asyncio/base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"/home/alon/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"/home/alon/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-54-c6d52af6914f>\", line 7, in <module>\n    testing.new_train(5)\n  File \"<ipython-input-53-375a6f85987a>\", line 358, in new_train\n    self.new_affine(output_single, first=True)\n  File \"<ipython-input-53-375a6f85987a>\", line 187, in new_affine\n    validate_args=True)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mvn_full_covariance.py\", line 181, in __init__\n    scale_tril = tf.cholesky(covariance_matrix)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 767, in cholesky\n    \"Cholesky\", input=input, name=name)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n\t [[node LSTM_1/affine_transformations/MultivariateNormalFullCovariance/init/Cholesky (defined at /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mvn_full_covariance.py:181) ]]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        testing = LSTM_SSM_model(sess, name = 'deleteme')\n",
    "        testing.build_new_LSTM()\n",
    "        testing.initialize_variables()\n",
    "        testing.new_train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_0=np.eye(4)\n",
    "Q = np.eye(4)\n",
    "R = np.array([[1]])\n",
    "def testing_FDRE(P,A,B,X,Q,R):\n",
    "    T = np.eye(4)-(2/np.matmul(X.T,X))*np.matmul(X,X.T)\n",
    "    A_hat = -np.matmul(np.matmul(T,A),np.linalg.inv(T))\n",
    "    B_hat = np.matmul(T,B)\n",
    "    P_prime = -np.matmul(A_hat.T,P)-np.matmul(P,A_hat)+Q- \\\n",
    "                np.matmul(np.matmul(np.matmul(np.matmul(P,B_hat),np.linalg.inv(R)),B_hat.T),P)\n",
    "    return P_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_FDRE(P_0,A[0],B[0],X[0],Q,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(A.shape[0]):\n",
    "    for j in range(A.shape[1]):\n",
    "        if np.linalg.matrix_rank(ct.ctrb(A[i][j],B[i][j])) != 4:\n",
    "            print(np.linalg.matrix_rank(ct.ctrb(A[i][j],B[i][j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [example.z[0,x,0] for x in range(example.z.shape[0])]\n",
    "second = [example.z[0,x,1] for x in range(example.z.shape[0])]\n",
    "third = [example.z[0,x,2] for x in range(example.z.shape[0])]\n",
    "fourth = [example.z[0,x,3] for x in range(example.z.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(first)\n",
    "plt.plot(second)\n",
    "plt.plot(third)\n",
    "plt.plot(fourth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_magnitude = np.array([0.01,0.1,0.01,0.1])\n",
    "av_time = []\n",
    "\n",
    "env = gym.make('Custom_CartPole-v0', thetaacc_error=2, initial_state=1)\n",
    "g = env.gravity\n",
    "M = env.masscart\n",
    "m = env.masspole\n",
    "l = env.length\n",
    "Q = np.eye(4)*[10,1,1,1]\n",
    "R = 1\n",
    "\n",
    "'''System of equations'''\n",
    "A = np.array([[0,1,0,0],[0,0,-m*g/M,0],[0,0,0,1],[0,0,(M+m)*g/(l*M),0]])\n",
    "B = np.array([[0,1/M,0,-1/(l*M)]]).T\n",
    "\n",
    "\n",
    "'''LQR'''\n",
    "import time\n",
    "K,S,E = ct.lqr(A,B,Q,R)\n",
    "'''Pole Placement'''\n",
    "#K = ct.place(A,B,np.array([-1.1,-1.2,-1.3,-1.4]))\n",
    "\n",
    "\n",
    "#env.x_threshold = 5.0\n",
    "#env.theta_threshold_radians = 10.0\n",
    "\n",
    "\n",
    "states = [[] for _ in range(5)]\n",
    "rewards = np.array([0]*5)\n",
    "for i_episode in range(5):\n",
    "    observation = env.reset()\n",
    "    states[i_episode].append(observation)\n",
    "    for t in range(500):\n",
    "#         env.render()\n",
    "        u = -np.dot(K,observation)\n",
    "        observation, reward, done, info = env.step(u[0])\n",
    "        states[i_episode].append(observation)\n",
    "        if done:\n",
    "            print(\"Episode finished at time step {}\".format(t+1))\n",
    "            break\n",
    "        rewards[i_episode]+=1\n",
    "    print(\"Episode complete\")\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
