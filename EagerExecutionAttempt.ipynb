{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import control as ct\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVNFull():\n",
    "    def __init__(self, loc,covariance_matrix):\n",
    "        self.loc = loc\n",
    "        self.cov = covariance_matrix\n",
    "        self.shape = tf.cast(self.cov.shape[-1],dtype=tf.float64)\n",
    "#         print(self.loc.shape)\n",
    "#         print(self.cov.shape)\n",
    "        assert(self.loc.shape[-2]==self.cov.shape[-1]), \"mean and covariance must have same n\"\n",
    "        assert(self.cov.shape[-1]==self.cov.shape[-2]),'covariance must have shape [...,n,n]'\n",
    "        \n",
    "    def prob(self, value):\n",
    "#         value = value\n",
    "#         print('Inside prob function')\n",
    "#         print('value',value.shape)\n",
    "        assert(value.shape[-1]==self.loc.shape[-1] and value.shape[-2]==self.loc.shape[-2]),'value must have same last 2 dimensions as loc'\n",
    "#         print('cov',self.cov.shape)\n",
    "        cov_inv = tf.linalg.inv(self.cov)\n",
    "#         print('cov_inv',cov_inv.shape)\n",
    "#         print(cov_inv.eval())\n",
    "        cov_det = tf.linalg.det(self.cov)\n",
    "#         print('cov_det', cov_det.shape)\n",
    "#         print(cov_det.eval())\n",
    "        denomenator = tf.math.sqrt(tf.math.pow((tf.cast(2*np.pi,dtype = tf.float64)),self.shape)*cov_det)\n",
    "#         print('denomenator', denomenator.shape)\n",
    "        diff = value-self.loc\n",
    "#         print('diff', diff.shape)\n",
    "        numerator = tf.squeeze(tf.math.exp((-0.5)*tf.matmul(tf.matmul(diff,cov_inv, transpose_a=True),diff)))\n",
    "#         print('numerator', numerator.shape)\n",
    "#         print('final value', tf.math.divide(numerator,denomenator).shape)\n",
    "#         print('leaving prob function')\n",
    "        return tf.math.divide(numerator,denomenator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_filter_fn(A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,z):\n",
    "    '''Calculates prior distribution based on the previous posterior distribution\n",
    "        and the current residual updates posterior distribution based on the new\n",
    "        prior distribution\n",
    "    '''\n",
    "#     print('z',z.shape)\n",
    "#     print('A', A.shape)\n",
    "#     print('B',B.shape)\n",
    "#     print('u',u.shape)\n",
    "#     print('g',g.shape)\n",
    "#     print('sigma',sigma.shape)\n",
    "#     print('C', C.shape)\n",
    "#     print('l_a_posteriori', l_a_posteriori.shape)\n",
    "#     print('P_a_posteriori', P_a_posteriori.shape)\n",
    "    _I = tf.eye(int(A.shape[0]), dtype = tf.float64)\n",
    "    \n",
    "    z = tf.expand_dims(z,-1)\n",
    "    l_a_priori = tf.matmul(A,l_a_posteriori) + tf.matmul(B,u)\n",
    "#     print('l_a_priori',l_a_priori.shape)\n",
    "    P_a_priori = tf.matmul(tf.matmul(A,P_a_posteriori), A, transpose_b = True) + tf.matmul(g,g, transpose_b=True)\n",
    "#     print('P_a_priori',P_a_priori.shape)\n",
    "    y_pre = z - tf.matmul(C,l_a_priori)\n",
    "#     print('y_pre', y_pre.shape)\n",
    "    S = tf.matmul(sigma, sigma, transpose_b=True) + \\\n",
    "        tf.matmul(tf.matmul(C, P_a_priori), C, transpose_b=True)\n",
    "#     print('S', S.shape)\n",
    "    \n",
    "    S_inv = tf.linalg.inv(S)\n",
    "    K = tf.matmul(tf.matmul(P_a_priori, C, transpose_b=True), S_inv)\n",
    "#     print('K', K.shape)\n",
    "    l_a_posteriori = l_a_priori + tf.matmul(K,y_pre)\n",
    "#     print('l_a_posteriori', l_a_posteriori.shape)\n",
    "    I_KC = _I-tf.matmul(K,C)\n",
    "#     print('I-KC', I_KC.shape)\n",
    "    P_a_posteriori = tf.matmul(tf.matmul(I_KC, P_a_priori), I_KC, transpose_b=True) + \\\n",
    "                        tf.matmul(tf.matmul(K,tf.matmul(sigma, sigma, transpose_b = True)),\n",
    "                                K, transpose_b=True)\n",
    "#     print('P_a_posteriori',P_a_posteriori.shape)\n",
    "    y_post = z-tf.matmul(C,l_a_posteriori)\n",
    "#     print('y_post', y_post.shape)\n",
    "    pred = tf.matmul(C, l_a_posteriori)\n",
    "#     print('pred', pred.shape)\n",
    "        \n",
    "    return A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_all 48 (4, 4)\n",
      "B_all 48 (4, 1)\n",
      "u_all 48 (1, 1)\n",
      "g_all 48 (4, 1)\n",
      "C_all 48 (4, 4)\n",
      "sigma_all 48 (4, 1)\n",
      "l_a_posteriori 49 (4, 1)\n",
      "P_a_posteriori 49 (4, 4)\n",
      "env_states 48 (4, 1)\n",
      "mu 48\n",
      "Sigma 48\n",
      "A_all 48\n",
      "env_states 48\n"
     ]
    }
   ],
   "source": [
    "def build_LSTM(lstm_sizes):\n",
    "    lstms = [tf.contrib.rnn.LSTMCell(size, reuse=tf.get_variable_scope().reuse) for size in lstm_sizes]\n",
    "    dropouts = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = 0.5) for lstm in lstms]\n",
    "\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(dropouts)\n",
    "    return cell\n",
    "\n",
    "def affine_transformation(lstm_output, first=False):\n",
    "    if first:\n",
    "        \n",
    "        mu_0 = tf.reshape(layers.Dense(m, name = 'mu_0dense')(lstm_output), shape=(m,1))\n",
    "        mu_0 = ((mu_0_upper_bound-mu_0_lower_bound)/(1+tf.exp(-mu_0)))+mu_0_lower_bound\n",
    "\n",
    "        Sigma_0 = tf.reshape(layers.Dense(m, name = 'Sigma_0dense')(lstm_output),shape = (m,1))\n",
    "\n",
    "        Sigma_0 = ((Sigma_0_upper_bound-Sigma_0_lower_bound)/(1+tf.exp(-Sigma_0)))+Sigma_0_lower_bound\n",
    "        Sigma_0 = tf.matmul(Sigma_0,Sigma_0,transpose_b=True)+tf.eye(4, dtype=tf.float64)*0.001\n",
    "\n",
    "        l_0_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(mu_0),\n",
    "                                                                covariance_matrix= Sigma_0,\n",
    "                                                                validate_args=True)\n",
    "        l_0 = tf.expand_dims(l_0_distribution.sample(),1)\n",
    "        return mu_0,Sigma_0,l_0\n",
    "\n",
    "#     A = tf.reshape(tf.add(tf.matmul(lstm_output, self.W_A), self.bias_A),shape=(self.m,self.n))\n",
    "    A = tf.reshape(layers.Dense(m*n, name = 'A_dense')(lstm_output),shape=(m,n))\n",
    "#     B = tf.reshape(tf.add(tf.matmul(lstm_output, self.W_B), self.bias_B),shape=(self.m,self.r))\n",
    "    B = tf.reshape(layers.Dense(m*r, name = 'B_dense')(lstm_output),shape=(m,r))\n",
    "\n",
    "#     g = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_g), self.bias_g))\n",
    "    g = tf.reshape(layers.Dense(m, name = 'g_dense')(lstm_output),shape = (m,1))\n",
    "    g = ((g_upper_bound-g_lower_bound)/(1+tf.exp(-g)))+g_lower_bound\n",
    "\n",
    "#     sigma = tf.transpose(tf.add(tf.matmul(lstm_output, self.W_sigma), self.bias_sigma))\n",
    "    sigma = tf.reshape(layers.Dense(dim_z, name = 'sigma_dense')(lstm_output),shape=(dim_z,1))\n",
    "    sigma = ((sigma_upper_bound-sigma_lower_bound)/(1+tf.exp(-sigma)))+sigma_lower_bound\n",
    "\n",
    "    return A,B,g,sigma\n",
    "\n",
    "\n",
    "def likelihood_fn(params, inputs):\n",
    "    A, B, u, g, C, sigma, l_filtered, P_filtered = inputs\n",
    "    mu_1, Sigma_1 = params\n",
    "#     print('A',len(A))\n",
    "#     print('B',len(B))\n",
    "#     print('u',len(u))\n",
    "#     print('C',len(C))\n",
    "#     print('g',len(g))\n",
    "#     print('sigma',len(sigma))\n",
    "#     print('l_filtered',len(l_filtered))\n",
    "#     print('p_filtered',len(P_filtered))\n",
    "#     print('mu_1',mu_1.shape)\n",
    "#     print('Sigma_1',Sigma_1.shape)\n",
    "    mu = [mu_1]\n",
    "    Sigma = [Sigma_1]\n",
    "    assert(len(A)==len(B) and len(B)==len(u) and len(u)==len(C) and len(C)==len(sigma) and \n",
    "           len(sigma)==len(l_filtered) and len(l_filtered)==len(P_filtered)),\"Not all sequences are same length\"\n",
    "    for i in range(len(A)):\n",
    "        mu.append(tf.matmul(C[i], tf.add(tf.matmul(A[i],l_filtered[i]), tf.matmul(B[i],u[i]))))\n",
    "        temp = tf.matmul(tf.matmul(A[i], P_filtered[i]), A[i], transpose_b=True) + \\\n",
    "                    tf.matmul(g[i], g[i], transpose_b=True)\n",
    "        Sigma.append(tf.matmul(tf.matmul(C[i], temp), C[i], transpose_b=True) + \\\n",
    "                     tf.matmul(sigma[i],sigma[i],transpose_b=True))\n",
    "    return mu,Sigma\n",
    "\n",
    "def calculate_loss():\n",
    "    mu_1 = tf.add(tf.matmul(A_all[0], mu_0),tf.matmul(B_all[0],u_all[0]))\n",
    "    Sigma_1 = tf.add(tf.matmul(tf.matmul(C_all[0],Sigma_0),C_all[0], transpose_b=True),tf.matmul(sigma_all[0],sigma_all[0],\n",
    "                                                                            transpose_b=True))\n",
    "#     print(mu_1.shape)\n",
    "#     print(Sigma_1.shape)\n",
    "    likelihoods = []\n",
    "    z_distribution = MVNFull(loc = mu_1, covariance_matrix = Sigma_1)\n",
    "    likelihoods.append(z_distribution.prob(env_states[0]))\n",
    "    if rewards > 1:\n",
    "        mu,Sigma = likelihood_fn((mu_1,Sigma_1),(A_all[1:],B_all[1:],u_all[1:],g_all[1:],\n",
    "                                                 C_all[1:],sigma_all[1:],\n",
    "                                                 l_a_posteriori[2:],P_a_posteriori[2:]))\n",
    "        \n",
    "    print('mu',len(mu))\n",
    "    print('Sigma',len(Sigma))\n",
    "    print('A_all',len(A_all))\n",
    "    print('env_states',len(env_states))\n",
    "    for i in range(len(mu)):\n",
    "        z_distribution = MVNFull(loc = mu[i], covariance_matrix = Sigma[i])\n",
    "        likelihoods.append(z_distribution.prob(env_states[i]))\n",
    "    \n",
    "        \n",
    "    return\n",
    "\n",
    "m = 4\n",
    "dim_z = m\n",
    "n = 4\n",
    "r = 1\n",
    "lstm_input_dim = m+4\n",
    "sigma_upper_bound = 1\n",
    "sigma_lower_bound = 0\n",
    "g_upper_bound = 1\n",
    "g_lower_bound = 0.1\n",
    "mu_0_upper_bound = 1\n",
    "mu_0_lower_bound = 0\n",
    "Sigma_0_upper_bound = 1\n",
    "Sigma_0_lower_bound = 0\n",
    "beta = 0.01\n",
    "b_upper_bound = 0.25\n",
    "b_lower_bound = -0.25\n",
    "thetaacc_error = 0\n",
    "initial_state_variation = 0.1\n",
    "\n",
    "initial_variance = 5\n",
    "\n",
    "count = 0\n",
    "A_all = []\n",
    "B_all = []\n",
    "u_all = []\n",
    "g_all = []\n",
    "C_all = []\n",
    "sigma_all = []\n",
    "l_a_posteriori = []\n",
    "P_a_posteriori = []\n",
    "env_states = []\n",
    "all_KF_params = [A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states]\n",
    "rewards = 0\n",
    "lstm_sizes = [128,64]\n",
    "env = gym.make('Custom_CartPole-v0', thetaacc_error=thetaacc_error, initial_state=initial_state_variation)\n",
    "gravity = env.gravity\n",
    "cart_mass = env.masscart\n",
    "pole_mass = env.masspole\n",
    "pole_length = env.length\n",
    "env_params = tf.expand_dims(np.array([gravity, cart_mass,pole_mass,pole_length],\n",
    "                                     dtype=np.float64),0)\n",
    "\n",
    "\n",
    "\n",
    "cell1 = build_LSTM(lstm_sizes)\n",
    "initial_state = cell1.get_initial_state(batch_size=1,dtype = tf.float64)\n",
    "initial_input = tf.concat((env_params, np.zeros(shape = [1,4])),axis=1)\n",
    "\n",
    "output_single, state_single = cell1(inputs=initial_input, state=initial_state)\n",
    "mu_0, Sigma_0,l_0= affine_transformation(output_single,first=True)\n",
    "\n",
    "# u_all.append(tf.zeros(shape = [1,r], dtype=tf.float64))\n",
    "l_a_posteriori.append(l_0)\n",
    "P_a_posteriori.append(initial_variance*tf.eye(m, dtype = tf.float64))\n",
    "\n",
    "\n",
    "observation=env.reset()\n",
    "# env_states.append(tf.expand_dims(tf.convert_to_tensor(observation,dtype=tf.float64),-1))\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    A, B, g, sigma = affine_transformation(output_single)\n",
    "    no_control = tf.zeros(shape = [1,r], dtype=tf.float64)\n",
    "    C = tf.eye(dim_z, dtype = tf.float64)\n",
    "    \n",
    "    observation, reward, done, info = env.step(tf.squeeze(no_control))\n",
    "    \n",
    "    KF_update = forward_filter_fn(A, B, no_control,g, C, sigma,l_a_posteriori[-1],P_a_posteriori[-1],\n",
    "                                  tf.convert_to_tensor(observation,dtype=tf.float64))\n",
    "    for KF_single,KF_param  in zip(KF_update,all_KF_params):\n",
    "        KF_param.append(KF_single)\n",
    "        \n",
    "    rewards+=1\n",
    "    \n",
    "    next_input = tf.concat((env_params,tf.expand_dims(environment_states[-1],0)),axis=1)\n",
    "    output_single,state_single=cell1(inputs=next_input,state=state_single)\n",
    "env.close()\n",
    "\n",
    "param_names = ['A_all','B_all','u_all','g_all','C_all','sigma_all','l_a_posteriori','P_a_posteriori','env_states']\n",
    "for name,KF_param in zip(param_names,all_KF_params):\n",
    "    print(name,len(KF_param), KF_param[0].shape)\n",
    "calculate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_all 54 (4, 4)\n",
      "B_all 54 (4, 1)\n",
      "u_all 55 (1, 1)\n",
      "g_all 54 (4, 1)\n",
      "C_all 54 (4, 4)\n",
      "sigma_all 54 (4, 1)\n",
      "l_a_posteriori 55 (4, 1)\n",
      "P_a_posteriori 55 (4, 4)\n",
      "env_states 55 (4, 1)\n"
     ]
    }
   ],
   "source": [
    "param_names = ['A_all','B_all','u_all','g_all','C_all','sigma_all','l_a_posteriori','P_a_posteriori','env_states']\n",
    "for name,KF_param in zip(param_names,all_KF_params):\n",
    "    print(name,len(KF_param), KF_param[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
