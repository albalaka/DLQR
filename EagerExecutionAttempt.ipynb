{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import control as ct\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as reg\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVNFull():\n",
    "    def __init__(self, loc,covariance_matrix):\n",
    "        self.loc = loc\n",
    "        self.cov = covariance_matrix\n",
    "        self.shape = tf.cast(self.cov.shape[-1],dtype=tf.float64)\n",
    "#         print(self.loc.shape)\n",
    "#         print(self.cov.shape)\n",
    "        assert(self.loc.shape[-2]==self.cov.shape[-1]), \"mean and covariance must have same n\"\n",
    "        assert(self.cov.shape[-1]==self.cov.shape[-2]),'covariance must have shape [...,n,n]'\n",
    "        \n",
    "    def log_prob(self, value):\n",
    "        value = value\n",
    "#         print('Inside prob function')\n",
    "#         print('value',value.shape)\n",
    "        assert(value.shape[-1]==self.loc.shape[-1] and value.shape[-2]==self.loc.shape[-2]),'value must have same last 2 dimensions as loc'\n",
    "#         print('cov',self.cov.shape)\n",
    "\n",
    "#         print('cov',self.cov)\n",
    "        cov_inv = tf.linalg.inv(self.cov+1e-4*tf.eye(self.shape,dtype=tf.float64))\n",
    "#         cov_inv = None\n",
    "#         multiplier = 1e-8\n",
    "#         while cov_inv == None:\n",
    "#             try:\n",
    "#                 if multiplier != 1e-8:\n",
    "#                     print('MVNFull covariance inverser failed, trying identity multiplier ',multiplier)\n",
    "#                 cov_inv = tf.linalg.inv(self.cov+multiplier*tf.eye(self.shape, dtype = tf.float64))\n",
    "#             except:\n",
    "#                 multiplier *= 10\n",
    "\n",
    "                \n",
    "                \n",
    "#         print('cov_inv',cov_inv)\n",
    "#         print('cov_inv',cov_inv.shape)\n",
    "#         print(cov_inv.numpy())\n",
    "        cov_det = tf.linalg.det(self.cov)\n",
    "#         print('cov_det', cov_det.shape)\n",
    "#         print(cov_det.numpy())\n",
    "        denomenator = tf.math.sqrt(tf.math.pow((tf.cast(2*np.pi,dtype = tf.float64)),self.shape)*cov_det)\n",
    "#         print('denomenator', denomenator.numpy())\n",
    "        diff = value-self.loc\n",
    "#         print('diff', diff.numpy())\n",
    "        numerator = tf.squeeze(tf.math.exp((-0.5)*tf.matmul(tf.matmul(diff,cov_inv, transpose_a=True),diff)))\n",
    "#         print('numerator', numerator.numpy())\n",
    "#         print('final value', tf.math.log(tf.math.divide(numerator,denomenator)).numpy())\n",
    "#         print('leaving prob function')\n",
    "        return tf.math.log(tf.math.divide(numerator,denomenator)+1e-32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_filter_fn(A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,z):\n",
    "    '''Calculates prior distribution based on the previous posterior distribution\n",
    "        and the current residual updates posterior distribution based on the new\n",
    "        prior distribution\n",
    "    '''\n",
    "#     print('z',z)\n",
    "#     print('A', A)\n",
    "#     print('B',B)\n",
    "#     print('u',u)\n",
    "#     print('g',g)\n",
    "#     print('sigma',sigma)\n",
    "#     print('C', C)\n",
    "#     print('l_a_posteriori', l_a_posteriori)\n",
    "#     print('P_a_posteriori', P_a_posteriori)\n",
    "    _I = tf.eye(int(A.shape[0]), dtype = tf.float64)\n",
    "    \n",
    "    z = tf.expand_dims(z,-1)\n",
    "    l_a_priori = tf.matmul(A,l_a_posteriori) + tf.matmul(B,u)\n",
    "#     print('l_a_priori',l_a_priori)\n",
    "    P_a_priori = tf.matmul(tf.matmul(A,P_a_posteriori), A, transpose_b = True) + tf.matmul(g,g, transpose_b=True)\n",
    "#     print('P_a_priori',P_a_priori)\n",
    "    y_pre = z - tf.matmul(C,l_a_priori)\n",
    "#     print('y_pre', y_pre)\n",
    "\n",
    "    S = tf.matmul(sigma, sigma, transpose_b=True) + \\\n",
    "        tf.matmul(tf.matmul(C, P_a_priori), C, transpose_b=True)\n",
    "#     print('S',S)\n",
    "    S_inv = tf.linalg.inv(S+1e-4*tf.eye(int(C.shape[0]), dtype = tf.float64))\n",
    "#     S_inv = None\n",
    "#     try:\n",
    "#         S_inv = tf.linalg.inv(S)\n",
    "#         print('success?')\n",
    "#     except InvalidArgumentError:\n",
    "#         print('Outer except')\n",
    "#         multiplier = 1e-10\n",
    "#         while S_inv == None:\n",
    "#             try:\n",
    "#                 if multiplier != 1e-10:\n",
    "#                     print('KF inv failed, trying identity multiplier ',multiplier)\n",
    "#                 cov_inv = tf.linalg.inv(self.cov+multiplier*tf.eye(S.shape[0], dtype = tf.float64))\n",
    "#             except InvalidArgumentError:\n",
    "#                 multiplier *= 10\n",
    "#         pass\n",
    "\n",
    "\n",
    "#     print('S_inv', S_inv)\n",
    "    K = tf.matmul(tf.matmul(P_a_priori, C, transpose_b=True), S_inv)\n",
    "#     print('K', K)\n",
    "    l_a_posteriori = l_a_priori + tf.matmul(K,y_pre)\n",
    "#     print('l_a_posteriori', l_a_posteriori)\n",
    "    I_KC = _I-tf.matmul(K,C)\n",
    "#     print('I-KC', I_KC)\n",
    "    P_a_posteriori = tf.matmul(tf.matmul(I_KC, P_a_priori), I_KC, transpose_b=True) + \\\n",
    "                        tf.matmul(tf.matmul(K,tf.matmul(sigma, sigma, transpose_b = True)),\n",
    "                                K, transpose_b=True)\n",
    "#     print('P_a_posteriori',P_a_posteriori)\n",
    "    y_post = z-tf.matmul(C,l_a_posteriori)\n",
    "#     print('y_post', y_post)\n",
    "    pred = tf.matmul(C, l_a_posteriori)\n",
    "#     print('pred', pred)\n",
    "        \n",
    "    return A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LSTM(lstm_sizes):\n",
    "    with tf.GradientTape() as tape:\n",
    "        lstms = [tf.contrib.rnn.LSTMCell(size, reuse=tf.get_variable_scope().reuse) for size in lstm_sizes]\n",
    "        dropouts = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = 0.5) for lstm in lstms]\n",
    "\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(dropouts)\n",
    "        return cell\n",
    "\n",
    "class model(object):\n",
    "    def __init__(self):\n",
    "        self.m = 4\n",
    "        self.dim_z = self.m\n",
    "        self.n = 4\n",
    "        self.r = 1\n",
    "        self.lstm_input_dim = self.m+4\n",
    "        self.sigma_upper_bound = 1\n",
    "        self.sigma_lower_bound = 0\n",
    "        self.g_upper_bound = 1\n",
    "        self.g_lower_bound = 0.1\n",
    "        self.mu_0_upper_bound = 1\n",
    "        self.mu_0_lower_bound = 0\n",
    "        self.Sigma_0_upper_bound = 1\n",
    "        self.Sigma_0_lower_bound = 0\n",
    "        self.beta = 0.01\n",
    "        self.b_upper_bound = 0.25\n",
    "        self.b_lower_bound = -0.25\n",
    "        thetaacc_error = 0\n",
    "        initial_state_variation = 0.1\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "        self.initial_variance_estimate = 1\n",
    "\n",
    "        self.lstm_sizes = [128,64]\n",
    "        self.env = gym.make('Custom_CartPole-v0', thetaacc_error=thetaacc_error, initial_state=initial_state_variation)\n",
    "        gravity = self.env.gravity\n",
    "        cart_mass = self.env.masscart\n",
    "        pole_mass = self.env.masspole\n",
    "        pole_length = self.env.length\n",
    "        self.env_params = tf.expand_dims(np.array([gravity, cart_mass,pole_mass,pole_length],\n",
    "                                             dtype=np.float64),0)\n",
    "#     def affine_transformation(self,lstm_output, first=False):\n",
    "#         if first:\n",
    "#             mu_0 = tf.reshape(layers.Dense(m, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                            bias_regularizer = reg.l2(self.beta),\n",
    "#                                            name = 'mu_0dense')(lstm_output), shape=(m,1))\n",
    "#             mu_0 = ((mu_0_upper_bound-mu_0_lower_bound)/(1+tf.exp(-mu_0)))+mu_0_lower_bound\n",
    "#             Sigma_0 = tf.reshape(layers.Dense(m, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                               bias_regularizer = reg.l2(self.beta),\n",
    "#                                               name = 'Sigma_0dense')(lstm_output),shape = (m,1))\n",
    "#             Sigma_0 = ((Sigma_0_upper_bound-Sigma_0_lower_bound)/(1+tf.exp(-Sigma_0)))+Sigma_0_lower_bound\n",
    "#             Sigma_0 = tf.matmul(Sigma_0,Sigma_0,transpose_b=True)+tf.eye(4, dtype=tf.float64)*0.001\n",
    "#             l_0_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(mu_0),\n",
    "#                                                                     covariance_matrix= Sigma_0,\n",
    "#                                                                     validate_args=True)\n",
    "#             l_0 = tf.expand_dims(l_0_distribution.sample(),1)\n",
    "#             return mu_0,Sigma_0,l_0\n",
    "#         A = tf.reshape(layers.Dense(m*n, kernel_regularizer = reg.l2(beta),\n",
    "#                                     bias_regularizer = reg.l2(beta),\n",
    "#                                     name = 'A_dense')(lstm_output),shape=(m,n))\n",
    "#         B = tf.reshape(layers.Dense(m*r, kernel_regularizer = reg.l2(beta),\n",
    "#                                     bias_regularizer = reg.l2(beta),\n",
    "#                                     name = 'B_dense')(lstm_output),shape=(m,r))\n",
    "#         g = tf.reshape(layers.Dense(m, kernel_regularizer = reg.l2(beta),\n",
    "#                                     bias_regularizer = reg.l2(beta),\n",
    "#                                     name = 'g_dense')(lstm_output),shape = (m,1))\n",
    "#         g = ((g_upper_bound-g_lower_bound)/(1+tf.exp(-g)))+g_lower_bound\n",
    "#         sigma = tf.reshape(layers.Dense(dim_z, kernel_regularizer = reg.l2(beta),\n",
    "#                                         bias_regularizer = reg.l2(beta),\n",
    "#                                         name = 'sigma_dense')(lstm_output),shape=(dim_z,1))\n",
    "#         sigma = ((sigma_upper_bound-sigma_lower_bound)/(1+tf.exp(-sigma)))+sigma_lower_bound\n",
    "#         return A,B,g,sigma\n",
    "    def likelihood_fn(self,params, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            A, B, u, g, C, sigma, l_filtered, P_filtered = inputs\n",
    "            mu_1, Sigma_1 = params\n",
    "        #     print('A',len(A))\n",
    "        #     print('B',len(B))\n",
    "        #     print('u',len(u))\n",
    "        #     print('C',len(C))\n",
    "        #     print('g',len(g))\n",
    "        #     print('sigma',len(sigma))\n",
    "        #     print('l_filtered',len(l_filtered))\n",
    "        #     print('p_filtered',len(P_filtered))\n",
    "        #     print('mu_1',mu_1.shape)\n",
    "        #     print('Sigma_1',Sigma_1.shape)\n",
    "            mu = [mu_1]\n",
    "            Sigma = [Sigma_1]\n",
    "            assert(len(A)==len(B) and len(B)==len(u) and len(u)==len(C) and len(C)==len(sigma) and \n",
    "                   len(sigma)==len(l_filtered) and len(l_filtered)==len(P_filtered)),\"Not all sequences are same length\"\n",
    "            for i in range(len(A)):\n",
    "                mu.append(tf.matmul(C[i], tf.add(tf.matmul(A[i],l_filtered[i]), tf.matmul(B[i],u[i]))))\n",
    "                temp = tf.matmul(tf.matmul(A[i], P_filtered[i]), A[i], transpose_b=True) + \\\n",
    "                            tf.matmul(g[i], g[i], transpose_b=True)\n",
    "                Sigma.append(tf.matmul(tf.matmul(C[i], temp), C[i], transpose_b=True) + \\\n",
    "                             tf.matmul(sigma[i],sigma[i],transpose_b=True))\n",
    "            return mu,Sigma\n",
    "    def calculate_loss(self, all_KF_params, mu_0,Sigma_0):\n",
    "        with tf.GradientTape() as tape:\n",
    "            A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states = all_KF_params\n",
    "            mu_1 = tf.add(tf.matmul(A_all[0], mu_0),tf.matmul(B_all[0],u_all[0]))\n",
    "            Sigma_1 = tf.add(tf.matmul(tf.matmul(C_all[0],Sigma_0),C_all[0], transpose_b=True),tf.matmul(sigma_all[0],sigma_all[0],\n",
    "                                                                                    transpose_b=True))\n",
    "        #     print(mu_1.shape)\n",
    "        #     print(Sigma_1.shape)\n",
    "\n",
    "            likelihoods = []\n",
    "            if self.rewards > 1:\n",
    "                mu,Sigma = self.likelihood_fn((mu_1,Sigma_1),(A_all,B_all,u_all,g_all,\n",
    "                                                         C_all,sigma_all,\n",
    "                                                         l_a_posteriori[1:],P_a_posteriori[1:]))\n",
    "        #     print('mu',len(mu),mu[0].shape)\n",
    "        #     print('Sigma',len(Sigma),Sigma[0].shape)\n",
    "    #         print('rewards',self.rewards)\n",
    "    #         print('env_states', len(env_states))\n",
    "            for i in range(self.rewards):\n",
    "                z_distribution = MVNFull(loc = mu[i], covariance_matrix = \\\n",
    "                                         0.0001*tf.eye(self.m, dtype = tf.float64)+Sigma[i])\n",
    "    #             print(id(z_distribution))\n",
    "                likelihoods.append(z_distribution.log_prob(env_states[i]))\n",
    "            loss = tf.Variable([0.0], dtype = tf.float64)\n",
    "    #         print(len(likelihoods),id(likelihoods))\n",
    "            for item in likelihoods:\n",
    "        #         print(item)\n",
    "                loss = tf.add(loss,-item)\n",
    "            return loss\n",
    "    \n",
    "    def train(self,epochs):\n",
    "        losses = []\n",
    "        for _ in range(epochs):\n",
    "            self.rewards = 0\n",
    "            A_all = []\n",
    "            B_all = []\n",
    "            u_all = []\n",
    "            g_all = []\n",
    "            C_all = []\n",
    "            sigma_all = []\n",
    "            l_a_posteriori = []\n",
    "            P_a_posteriori = []\n",
    "            env_states = []\n",
    "            all_KF_params = [A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states]\n",
    "\n",
    "            '''Build LSTM'''\n",
    "            with tf.GradientTape() as tape:\n",
    "                cell = build_LSTM(self.lstm_sizes)\n",
    "                '''Get initial lstm state and input, get first output/state'''\n",
    "                initial_state = cell.get_initial_state(batch_size=1,dtype = tf.float64)\n",
    "                initial_input = tf.concat((self.env_params, np.zeros(shape = [1,4])),axis=1)\n",
    "                output_single, state_single = cell(inputs=initial_input, state=initial_state)\n",
    "    #             mu_0,Sigma_0,l_0 = self.affine_transformation(output_single,first=True)\n",
    "                '''Calculate mu_0,Sigma_0, distribution using initial LSTM output'''\n",
    "                mu_0 = tf.reshape(layers.Dense(self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "                                               bias_regularizer = reg.l2(self.beta),\n",
    "                                               name = 'mu_0dense')(output_single), shape=(self.m,1))\n",
    "                mu_0 = ((self.mu_0_upper_bound-self.mu_0_lower_bound)/(1+tf.exp(-mu_0)))+self.mu_0_lower_bound\n",
    "                Sigma_0 = tf.reshape(layers.Dense(self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "                                                  bias_regularizer = reg.l2(self.beta),\n",
    "                                                  name = 'Sigma_0dense')(output_single),shape = (self.m,1))\n",
    "                Sigma_0 = ((self.Sigma_0_upper_bound-self.Sigma_0_lower_bound)/(1+tf.exp(-Sigma_0)))+self.Sigma_0_lower_bound\n",
    "                Sigma_0 = tf.matmul(Sigma_0,Sigma_0,transpose_b=True)+tf.eye(4, dtype=tf.float64)*0.001\n",
    "                l_0_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(mu_0),\n",
    "                                                                        covariance_matrix= Sigma_0,\n",
    "                                                                        validate_args=True)\n",
    "                l_0 = tf.expand_dims(l_0_distribution.sample(),1)\n",
    "\n",
    "\n",
    "\n",
    "                # u_all.append(tf.zeros(shape = [1,r], dtype=tf.float64))\n",
    "                l_a_posteriori.append(l_0)\n",
    "                P_a_posteriori.append(self.initial_variance_estimate*tf.eye(self.m, dtype = tf.float64))\n",
    "\n",
    "\n",
    "                observation=self.env.reset()\n",
    "                # env_states.append(tf.expand_dims(tf.convert_to_tensor(observation,dtype=tf.float64),-1))\n",
    "                done = False\n",
    "                while not done:\n",
    "                    self.env.render()\n",
    "                    '''Get lstm outputs'''\n",
    "                    A = tf.reshape(layers.Dense(self.m*self.n, kernel_regularizer = reg.l2(self.beta),\n",
    "                                                bias_regularizer = reg.l2(self.beta),\n",
    "                                                name = 'A_dense')(output_single),shape=(self.m,self.n))\n",
    "                    B = tf.reshape(layers.Dense(self.m*self.r, kernel_regularizer = reg.l2(self.beta),\n",
    "                                                bias_regularizer = reg.l2(self.beta),\n",
    "                                                name = 'B_dense')(output_single),shape=(self.m,self.r))\n",
    "                    g = tf.reshape(layers.Dense(self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "                                                bias_regularizer = reg.l2(self.beta),\n",
    "                                                name = 'g_dense')(output_single),shape = (self.m,1))\n",
    "                    g = ((self.g_upper_bound-self.g_lower_bound)/(1+tf.exp(-g)))+self.g_lower_bound\n",
    "                    sigma = tf.reshape(layers.Dense(self.dim_z, kernel_regularizer = reg.l2(self.beta),\n",
    "                                                    bias_regularizer = reg.l2(self.beta),\n",
    "                                                    name = 'sigma_dense')(output_single),shape=(self.dim_z,1))\n",
    "                    sigma = ((self.sigma_upper_bound-self.sigma_lower_bound)/(1+tf.exp(-sigma)))+self.sigma_lower_bound\n",
    "\n",
    "    #                 A, B, g, sigma = self.affine_transformation(output_single)\n",
    "                    no_control = tf.zeros(shape = [1,self.r], dtype=tf.float64)\n",
    "                    C = tf.eye(self.dim_z, dtype = tf.float64)\n",
    "\n",
    "                    observation, reward, done, info = self.env.step(tf.squeeze(no_control))\n",
    "\n",
    "\n",
    "\n",
    "                    '''Calculate:\n",
    "                        A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,env_states'''\n",
    "                    KF_update = forward_filter_fn(A, B, no_control,g, C, sigma,l_a_posteriori[-1],P_a_posteriori[-1],\n",
    "                                                  tf.convert_to_tensor(observation,dtype=tf.float64))\n",
    "                    '''Update lists:\n",
    "                        A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states'''\n",
    "                    for KF_single,KF_param  in zip(KF_update,all_KF_params):\n",
    "                        KF_param.append(KF_single)\n",
    "\n",
    "                    self.rewards+=1\n",
    "\n",
    "                    next_input = tf.concat((self.env_params,tf.transpose(env_states[-1])),axis=1)\n",
    "                    output_single,state_single=cell(inputs=next_input,state=state_single)\n",
    "            self.env.close()\n",
    "\n",
    "            param_names = ['A_all','B_all','u_all','g_all','C_all','sigma_all','l_a_posteriori','P_a_posteriori','env_states']\n",
    "#             for name,KF_param in zip(param_names,all_KF_params):\n",
    "#                 print(name,len(KF_param), KF_param[0].shape)\n",
    "            print('Rewards', self.rewards)\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss = self.calculate_loss(all_KF_params, mu_0,Sigma_0)\n",
    "                print(loss.numpy())\n",
    "#                 print(cell.trainable_variables)\n",
    "                grad = tape.gradient(loss,cell.trainable_variables)\n",
    "                print(grad)\n",
    "#                 self.optimizer.apply_gradients(zip(grad,cell.trainable_variables))\n",
    "            losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Epoch(object):\n",
    "    def __init__(self, view = False):\n",
    "        self.view = view\n",
    "        self.m = 4\n",
    "        self.dim_z = self.m\n",
    "        self.n = 4\n",
    "        self.r = 1\n",
    "        self.lstm_input_dim = self.m+4\n",
    "        self.sigma_upper_bound = 1\n",
    "        self.sigma_lower_bound = 0\n",
    "        self.g_upper_bound = 1\n",
    "        self.g_lower_bound = 0.1\n",
    "        self.mu_0_upper_bound = 1\n",
    "        self.mu_0_lower_bound = 0\n",
    "        self.Sigma_0_upper_bound = 1\n",
    "        self.Sigma_0_lower_bound = 0\n",
    "        self.beta = 0.01\n",
    "        self.b_upper_bound = 0.25\n",
    "        self.b_lower_bound = -0.25\n",
    "        thetaacc_error = 0\n",
    "        initial_state_variation = 0.01\n",
    "\n",
    "        self.initial_variance_estimate = 1\n",
    "\n",
    "        self.lstm_sizes = [128,64]\n",
    "        self.env = gym.make('Custom_CartPole-v0', thetaacc_error=thetaacc_error, initial_state=initial_state_variation)\n",
    "        gravity = self.env.gravity\n",
    "        cart_mass = self.env.masscart\n",
    "        pole_mass = self.env.masspole\n",
    "        pole_length = self.env.length\n",
    "        self.env_params = tf.expand_dims(np.array([gravity, cart_mass,pole_mass,pole_length],\n",
    "                                             dtype=np.float64),0)\n",
    "        \n",
    "        self.variables = []\n",
    "        \n",
    "    def build_LSTM(self):\n",
    "        lstms = [tf.contrib.rnn.LSTMCell(size, reuse=tf.get_variable_scope().reuse) for size in self.lstm_sizes]\n",
    "        dropouts = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = 0.5) for lstm in lstms]\n",
    "\n",
    "        self.cell = tf.contrib.rnn.MultiRNNCell(dropouts)\n",
    "#         print(self.cell.trainable_variables)\n",
    "#         print(self.cell.trainable_weights)\n",
    "#         self.variables.append(self.cell.trainable_variables)\n",
    "        return self\n",
    "    \n",
    "    def get_variables(self):\n",
    "        return self.variables\n",
    "    \n",
    "    def __call__(self):\n",
    "        self.variables = []\n",
    "        self.rewards = 0\n",
    "        A_all = []\n",
    "        B_all = []\n",
    "        u_all = []\n",
    "        g_all = []\n",
    "        C_all = []\n",
    "        sigma_all = []\n",
    "        l_a_posteriori = []\n",
    "        P_a_posteriori = []\n",
    "        env_states = []\n",
    "        all_KF_params = [A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states]\n",
    "\n",
    "        '''Build LSTM'''\n",
    "        self.build_LSTM()\n",
    "        '''Get initial lstm state and input, get first output/state'''\n",
    "        initial_state = self.cell.get_initial_state(batch_size=1,dtype = tf.float64)\n",
    "        initial_input = tf.concat((self.env_params, np.zeros(shape = [1,4])),axis=1)\n",
    "        output_single, state_single = self.cell(inputs=initial_input, state=initial_state)\n",
    "#             mu_0,Sigma_0,l_0 = self.affine_transformation(output_single,first=True)\n",
    "\n",
    "\n",
    "        '''Calculate mu_0,Sigma_0, distribution using initial LSTM output'''\n",
    "        container = tf.contrib.eager.EagerVariableStore()\n",
    "        with container.as_default():\n",
    "            mu_0 = tf.layers.dense(output_single, self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "                                       bias_regularizer = reg.l2(self.beta),\n",
    "                                       name = 'mu_0dense')\n",
    "            Sigma_0 = tf.layers.dense(output_single, self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "                                          bias_regularizer = reg.l2(self.beta),\n",
    "                                          name = 'Sigma_0dense')\n",
    "        mu_0 = tf.reshape(mu_0, shape = (self.m,1))\n",
    "#         mu_0 = tf.reshape(layers.Dense(self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                        bias_regularizer = reg.l2(self.beta),\n",
    "#                                        name = 'mu_0dense')(output_single), shape=(self.m,1))\n",
    "        mu_0 = ((self.mu_0_upper_bound-self.mu_0_lower_bound)/(1+tf.exp(-mu_0)))+self.mu_0_lower_bound\n",
    "        Sigma_0 = tf.reshape(Sigma_0, shape = (self.m,1))\n",
    "#         Sigma_0 = tf.reshape(layers.Dense(self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                           bias_regularizer = reg.l2(self.beta),\n",
    "#                                           name = 'Sigma_0dense')(output_single),shape = (self.m,1))\n",
    "        Sigma_0 = ((self.Sigma_0_upper_bound-self.Sigma_0_lower_bound)/(1+tf.exp(-Sigma_0)))+self.Sigma_0_lower_bound\n",
    "        Sigma_0 = tf.matmul(Sigma_0,Sigma_0,transpose_b=True)+tf.eye(4, dtype=tf.float64)*0.001\n",
    "        l_0_distribution = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(mu_0),\n",
    "                                                                covariance_matrix= Sigma_0,\n",
    "                                                                validate_args=True)\n",
    "        l_0 = tf.expand_dims(l_0_distribution.sample(),1)\n",
    "        l_a_posteriori.append(l_0)\n",
    "        P_a_posteriori.append(self.initial_variance_estimate*tf.eye(self.m, dtype = tf.float64))\n",
    "\n",
    "\n",
    "        observation=self.env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            if self.view:\n",
    "                self.env.render()\n",
    "            '''Get lstm outputs'''\n",
    "#             A = layers.Dense(self.m*self.n, kernel_regularizer = reg.l2(self.beta),\n",
    "#                              bias_regularizer = reg.l2(self.beta),\n",
    "#                              name = 'A_dense')(output_single)\n",
    "#             print(A.__dict__)\n",
    "            with container.as_default():\n",
    "                A = tf.layers.dense(output_single, self.m*self.n, kernel_regularizer = reg.l2(self.beta),\n",
    "                                 bias_regularizer = reg.l2(self.beta),\n",
    "                                 name = 'A_dense', reuse = True)\n",
    "#                 A = tf.reshape(layers.Dense(self.m*self.n, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                             bias_regularizer = reg.l2(self.beta),\n",
    "#                                             name = 'A_dense')(output_single),shape=(self.m,self.n))\n",
    "                B = tf.layers.dense(output_single, self.m*self.r, kernel_regularizer = reg.l2(self.beta),\n",
    "                                    bias_regularizer = reg.l2(self.beta),\n",
    "                                    name = 'B_dense', reuse = True)\n",
    "#                 B = tf.reshape(layers.Dense(self.m*self.r, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                             bias_regularizer = reg.l2(self.beta),\n",
    "#                                             name = 'B_dense')(output_single),shape=(self.m,self.r))\n",
    "                g = tf.layers.dense(output_single, self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "                                    bias_regularizer = reg.l2(self.beta),\n",
    "                                    name = 'g_dense', reuse = True)\n",
    "#                 g = tf.reshape(layers.Dense(self.m, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                             bias_regularizer = reg.l2(self.beta),\n",
    "#                                             name = 'g_dense')(output_single),shape = (self.m,1))\n",
    "#                 g = ((self.g_upper_bound-self.g_lower_bound)/(1+tf.exp(-g)))+self.g_lower_bound\n",
    "                sigma = tf.layers.dense(output_single, self.dim_z, kernel_regularizer = reg.l2(self.beta),\n",
    "                                        bias_regularizer = reg.l2(self.beta),\n",
    "                                        name = 'sigma_dense', reuse = True)\n",
    "#                 sigma = tf.reshape(layers.Dense(self.dim_z, kernel_regularizer = reg.l2(self.beta),\n",
    "#                                                 bias_regularizer = reg.l2(self.beta),\n",
    "#                                                 name = 'sigma_dense')(output_single),shape=(self.dim_z,1))\n",
    "#                 sigma = ((self.sigma_upper_bound-self.sigma_lower_bound)/(1+tf.exp(-sigma)))+self.sigma_lower_bound\n",
    "#                 A, B, g, sigma = self.affine_transformation(output_single)\n",
    "#             print('container total',len(container.variables()))\n",
    "#             print('container trainable',len(container.trainable_variables()))\n",
    "            self.variables.extend(container.trainable_variables())\n",
    "            A = tf.reshape(A, shape = (self.m,self.n))\n",
    "            B = tf.reshape(B, shape = (self.m,self.r))\n",
    "            g = tf.reshape(g, shape = (self.m, 1))\n",
    "            g = ((self.g_upper_bound-self.g_lower_bound)/(1+tf.exp(-g)))+self.g_lower_bound\n",
    "            sigma = tf.reshape(sigma, shape = (self.dim_z,1))\n",
    "            sigma = ((self.sigma_upper_bound-self.sigma_lower_bound)/(1+tf.exp(-sigma)))+self.sigma_lower_bound\n",
    "            no_control = tf.zeros(shape = [1,self.r], dtype=tf.float64)\n",
    "            C = tf.eye(self.dim_z, dtype = tf.float64)\n",
    "            observation, reward, done, info = self.env.step(tf.squeeze(no_control))\n",
    "            '''Calculate:\n",
    "                A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,env_states'''\n",
    "            KF_update = forward_filter_fn(A, B, no_control,g, C, sigma,l_a_posteriori[-1],P_a_posteriori[-1],\n",
    "                                          tf.convert_to_tensor(observation,dtype=tf.float64))\n",
    "            '''Update lists:\n",
    "                A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states'''\n",
    "            for KF_single,KF_param  in zip(KF_update,all_KF_params):\n",
    "                KF_param.append(KF_single)\n",
    "\n",
    "            self.rewards+=1\n",
    "\n",
    "            next_input = tf.concat((self.env_params,tf.transpose(env_states[-1])),axis=1)\n",
    "            output_single,state_single=self.cell(inputs=next_input,state=state_single)\n",
    "        if self.view:\n",
    "            self.env.close()\n",
    "\n",
    "        param_names = ['A_all','B_all','u_all','g_all','C_all','sigma_all','l_a_posteriori','P_a_posteriori','env_states']\n",
    "#             for name,KF_param in zip(param_names,all_KF_params):\n",
    "#                 print(name,len(KF_param), KF_param[0].shape)\n",
    "        self.variables.extend(self.cell.trainable_variables)\n",
    "#         print('LSTM cell trainable',len(self.cell.trainable_variables))\n",
    "#         print('Rewards', self.rewards)\n",
    "#         print('VARIABLES',[x.name for x in self.cell.trainable_variables])\n",
    "#         print('\\n\\n\\nWEIGHTS',[x.name for x in self.cell.trainable_weights])\n",
    "        return all_KF_params, self.rewards, mu_0,Sigma_0\n",
    "\n",
    "def loss(epoch):\n",
    "#     print(epoch.__dict__)\n",
    "    all_KF_params, rewards, mu_0, Sigma_0 = epoch()\n",
    "    def likelihood_fn(params, inputs):\n",
    "        A, B, u, g, C, sigma, l_filtered, P_filtered = inputs\n",
    "        mu_1, Sigma_1 = params\n",
    "#         print('A',len(A))\n",
    "#         print('B',len(B))\n",
    "#         print('u',len(u))\n",
    "#         print('C',len(C))\n",
    "#         print('g',len(g))\n",
    "#         print('sigma',len(sigma))\n",
    "#         print('l_filtered',len(l_filtered))\n",
    "#         print('p_filtered',len(P_filtered))\n",
    "#         print('mu_1',mu_1.shape)\n",
    "#         print('Sigma_1',Sigma_1.shape)\n",
    "        mu = [mu_1]\n",
    "        Sigma = [Sigma_1]\n",
    "        assert(len(A)==len(B) and len(B)==len(u) and len(u)==len(C) and len(C)==len(sigma) and \n",
    "               len(sigma)==len(l_filtered) and len(l_filtered)==len(P_filtered)),\"Not all sequences are same length\"\n",
    "        for i in range(len(A)):\n",
    "            mu.append(tf.matmul(C[i], tf.add(tf.matmul(A[i],l_filtered[i]), tf.matmul(B[i],u[i]))))\n",
    "            temp = tf.matmul(tf.matmul(A[i], P_filtered[i]), A[i], transpose_b=True) + \\\n",
    "                        tf.matmul(g[i], g[i], transpose_b=True)\n",
    "            Sigma.append(tf.matmul(tf.matmul(C[i], temp), C[i], transpose_b=True) + \\\n",
    "                        tf.matmul(sigma[i],sigma[i],transpose_b=True))\n",
    "        return mu,Sigma\n",
    "    \n",
    "    \n",
    "    A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states = all_KF_params\n",
    "    mu_1 = tf.add(tf.matmul(A_all[0], mu_0),tf.matmul(B_all[0],u_all[0]))\n",
    "    Sigma_1 = tf.add(tf.matmul(tf.matmul(C_all[0],Sigma_0),C_all[0], transpose_b=True),\n",
    "                     tf.matmul(sigma_all[0],sigma_all[0],transpose_b=True))\n",
    "        #     print(mu_1.shape)\n",
    "        #     print(Sigma_1.shape)\n",
    "\n",
    "    likelihoods = []\n",
    "    if rewards > 1:\n",
    "        mu,Sigma = likelihood_fn((mu_1,Sigma_1),(A_all,B_all,u_all,g_all,\n",
    "                                                 C_all,sigma_all,\n",
    "                                                 l_a_posteriori[1:],\n",
    "                                                 P_a_posteriori[1:]))\n",
    "#     print('mu',len(mu),mu[0].shape)\n",
    "#     print('Sigma',len(Sigma),Sigma[0].shape)\n",
    "#         print('rewards',self.rewards)\n",
    "#         print('env_states', len(env_states))\n",
    "    for i in range(rewards):\n",
    "        z_distribution = MVNFull(loc = mu[i], covariance_matrix = Sigma[i])\n",
    "#                                  0.0001*tf.eye(epoch.m, dtype = tf.float64)+Sigma[i])\n",
    "#             print(id(z_distribution))\n",
    "        likelihoods.append(z_distribution.log_prob(env_states[i]))\n",
    "    loss = tf.Variable([0.0], dtype = tf.float64)\n",
    "#         print(len(likelihoods),id(likelihoods))\n",
    "    for item in likelihoods:\n",
    "#         print(item)\n",
    "        loss = tf.add(loss,-item)\n",
    "    return loss, rewards\n",
    "    \n",
    "\n",
    "def grad(epoch):\n",
    "    with tf.GradientTape(persistent = True) as tape:\n",
    "        loss_value, rewards = loss(epoch)\n",
    "#         print(tape.gradient(loss_value,epoch.get_variables()))\n",
    "    return tape.gradient(loss_value, epoch.get_variables()), loss_value.numpy(), rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = Epoch()\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "losses = []\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Minutes elapsed: 0.05990602572758993\n",
      "last loss: [3830.17360431], reward: 85, loss/reward: [45.06086593]\n",
      "Epoch 2\n",
      "Minutes elapsed: 0.1196645458539327\n",
      "last loss: [3271.8397981], reward: 89, loss/reward: [36.76224492]\n",
      "Epoch 3\n",
      "Minutes elapsed: 0.17910154660542807\n",
      "last loss: [3195.28381602], reward: 78, loss/reward: [40.96517713]\n",
      "Epoch 4\n",
      "Minutes elapsed: 0.24593288103739422\n",
      "last loss: [3235.4205326], reward: 99, loss/reward: [32.68101548]\n",
      "Epoch 5\n",
      "Minutes elapsed: 0.3125503142674764\n",
      "last loss: [3874.49203446], reward: 97, loss/reward: [39.94321685]\n",
      "Epoch 6\n",
      "Minutes elapsed: 0.35908164183298746\n",
      "last loss: [3561.29241386], reward: 69, loss/reward: [51.61293353]\n",
      "Epoch 7\n",
      "Minutes elapsed: 0.4131742278734843\n",
      "last loss: [3571.76700372], reward: 79, loss/reward: [45.21224055]\n",
      "Epoch 8\n",
      "Minutes elapsed: 0.4658164660135905\n",
      "last loss: [3875.09987653], reward: 74, loss/reward: [52.36621455]\n",
      "Epoch 9\n",
      "Minutes elapsed: 0.5205916245778401\n",
      "last loss: [3506.8480347], reward: 81, loss/reward: [43.29442018]\n",
      "Epoch 10\n",
      "Minutes elapsed: 0.5637468218803405\n",
      "last loss: [3416.24087699], reward: 65, loss/reward: [52.55755195]\n",
      "Epoch 11\n",
      "Minutes elapsed: 0.6314404686292012\n",
      "last loss: [4831.88332405], reward: 96, loss/reward: [50.33211796]\n",
      "Epoch 12\n",
      "Minutes elapsed: 0.6898751139640809\n",
      "last loss: [3997.21092163], reward: 86, loss/reward: [46.47919676]\n",
      "Epoch 13\n",
      "Minutes elapsed: 0.7427938024202982\n",
      "last loss: [4450.14805182], reward: 76, loss/reward: [58.55457963]\n",
      "Epoch 14\n",
      "Minutes elapsed: 0.8027568062146505\n",
      "last loss: [3492.99313996], reward: 87, loss/reward: [40.14934644]\n",
      "Epoch 15\n",
      "Minutes elapsed: 0.8595420956611634\n",
      "last loss: [3276.25027958], reward: 77, loss/reward: [42.54870493]\n",
      "Epoch 16\n",
      "Minutes elapsed: 0.9379086494445801\n",
      "last loss: [4175.74079492], reward: 119, loss/reward: [35.09025878]\n",
      "Epoch 17\n",
      "Minutes elapsed: 1.00146640141805\n",
      "last loss: [4124.82524514], reward: 89, loss/reward: [46.34635107]\n",
      "Epoch 18\n",
      "Minutes elapsed: 1.050429896513621\n",
      "last loss: [3468.91599172], reward: 72, loss/reward: [48.17938877]\n",
      "Epoch 19\n",
      "Minutes elapsed: 1.1169594486554464\n",
      "last loss: [3383.86162009], reward: 90, loss/reward: [37.59846245]\n",
      "Epoch 20\n",
      "Minutes elapsed: 1.1662648598353067\n",
      "last loss: [3892.8719287], reward: 78, loss/reward: [49.90861447]\n",
      "Epoch 21\n",
      "Minutes elapsed: 1.2187341332435608\n",
      "last loss: [4366.9173678], reward: 76, loss/reward: [57.45943905]\n",
      "Epoch 22\n",
      "Minutes elapsed: 1.2663844188054403\n",
      "last loss: [3581.11628908], reward: 69, loss/reward: [51.90023607]\n",
      "Epoch 23\n",
      "Minutes elapsed: 1.3114734212557475\n",
      "last loss: [3669.39169641], reward: 70, loss/reward: [52.41988138]\n",
      "Epoch 24\n",
      "Minutes elapsed: 1.3606868386268616\n",
      "last loss: [3338.10700795], reward: 71, loss/reward: [47.01559166]\n",
      "Epoch 25\n",
      "Minutes elapsed: 1.423553748925527\n",
      "last loss: [3569.14586176], reward: 92, loss/reward: [38.79506371]\n",
      "Epoch 26\n",
      "Minutes elapsed: 1.4932206312815348\n",
      "last loss: [3471.629518], reward: 106, loss/reward: [32.75122187]\n",
      "Epoch 27\n",
      "Minutes elapsed: 1.559703516960144\n",
      "last loss: [4001.4068477], reward: 83, loss/reward: [48.20972106]\n",
      "Epoch 28\n",
      "Minutes elapsed: 1.6124444524447124\n",
      "last loss: [4022.62886916], reward: 68, loss/reward: [59.1563069]\n",
      "Epoch 29\n",
      "Minutes elapsed: 1.6988930265108744\n",
      "last loss: [3056.38421008], reward: 117, loss/reward: [26.12294197]\n",
      "Epoch 30\n",
      "Minutes elapsed: 1.768999461332957\n",
      "last loss: [3288.47647845], reward: 99, loss/reward: [33.21693413]\n",
      "Epoch 31\n",
      "Minutes elapsed: 1.8257404923439027\n",
      "last loss: [4159.32999679], reward: 84, loss/reward: [49.5158333]\n",
      "Epoch 32\n",
      "Minutes elapsed: 1.899021077156067\n",
      "last loss: [3618.68071629], reward: 96, loss/reward: [37.69459079]\n",
      "Epoch 33\n",
      "Minutes elapsed: 1.9535090645154318\n",
      "last loss: [3943.97342095], reward: 71, loss/reward: [55.54892142]\n",
      "Epoch 34\n",
      "Minutes elapsed: 2.0211596965789793\n",
      "last loss: [3681.09209779], reward: 73, loss/reward: [50.42591915]\n",
      "Epoch 35\n",
      "Minutes elapsed: 2.068939467271169\n",
      "last loss: [4080.18834688], reward: 70, loss/reward: [58.28840496]\n",
      "Epoch 36\n",
      "Minutes elapsed: 2.1164186596870422\n",
      "last loss: [3938.44219738], reward: 66, loss/reward: [59.67336663]\n",
      "Epoch 37\n",
      "Minutes elapsed: 2.179011829694112\n",
      "last loss: [3763.25209154], reward: 91, loss/reward: [41.35441859]\n",
      "Epoch 38\n",
      "Minutes elapsed: 2.233338248729706\n",
      "last loss: [3692.35252831], reward: 73, loss/reward: [50.58017162]\n",
      "Epoch 39\n",
      "Minutes elapsed: 2.28910851875941\n",
      "last loss: [3510.93133706], reward: 78, loss/reward: [45.01194022]\n",
      "Epoch 40\n",
      "Minutes elapsed: 2.338140018781026\n",
      "last loss: [3135.1659409], reward: 72, loss/reward: [43.5439714]\n",
      "Epoch 41\n",
      "Minutes elapsed: 2.3898310899734496\n",
      "last loss: [3260.37901212], reward: 80, loss/reward: [40.75473765]\n",
      "Epoch 42\n",
      "Minutes elapsed: 2.453775711854299\n",
      "last loss: [3793.89595387], reward: 94, loss/reward: [40.36059525]\n",
      "Epoch 43\n",
      "Minutes elapsed: 2.5188900272051495\n",
      "last loss: [3466.57815996], reward: 71, loss/reward: [48.82504451]\n",
      "Epoch 44\n",
      "Minutes elapsed: 2.5870278596878054\n",
      "last loss: [3748.97887843], reward: 73, loss/reward: [51.35587505]\n",
      "Epoch 45\n",
      "Minutes elapsed: 2.6602439085642495\n",
      "last loss: [3605.77715369], reward: 98, loss/reward: [36.79364443]\n",
      "Epoch 46\n",
      "Minutes elapsed: 2.7034862200419107\n",
      "last loss: [3780.62394332], reward: 69, loss/reward: [54.79165135]\n",
      "Epoch 47\n",
      "Minutes elapsed: 2.7528474887212115\n",
      "last loss: [4013.92493496], reward: 82, loss/reward: [48.95030408]\n",
      "Epoch 48\n",
      "Minutes elapsed: 2.8020625352859496\n",
      "last loss: [4084.5113418], reward: 88, loss/reward: [46.41490161]\n",
      "Epoch 49\n",
      "Minutes elapsed: 2.8456575234731036\n",
      "last loss: [2890.16027316], reward: 77, loss/reward: [37.534549]\n",
      "Epoch 50\n",
      "Minutes elapsed: 2.8957337141036987\n",
      "last loss: [3536.67606926], reward: 78, loss/reward: [45.34200089]\n",
      "Epoch 51\n",
      "Minutes elapsed: 2.957442045211792\n",
      "last loss: [3339.5480362], reward: 99, loss/reward: [33.73280845]\n",
      "Epoch 52\n",
      "Minutes elapsed: 3.021373283863068\n",
      "last loss: [3607.7819212], reward: 75, loss/reward: [48.10375895]\n",
      "Epoch 53\n",
      "Minutes elapsed: 3.064867603778839\n",
      "last loss: [3819.73788201], reward: 70, loss/reward: [54.56768403]\n",
      "Epoch 54\n",
      "Minutes elapsed: 3.115121022860209\n",
      "last loss: [3686.36841201], reward: 83, loss/reward: [44.41407725]\n",
      "Epoch 55\n",
      "Minutes elapsed: 3.165046528975169\n",
      "last loss: [3447.074353], reward: 82, loss/reward: [42.03749211]\n",
      "Epoch 56\n",
      "Minutes elapsed: 3.2077994346618652\n",
      "last loss: [3953.16379586], reward: 71, loss/reward: [55.67836332]\n",
      "Epoch 57\n",
      "Minutes elapsed: 3.2533185442288715\n",
      "last loss: [4205.52286231], reward: 76, loss/reward: [55.33582714]\n",
      "Epoch 58\n",
      "Minutes elapsed: 3.2966408491134644\n",
      "last loss: [3817.9120403], reward: 72, loss/reward: [53.02655612]\n",
      "Epoch 59\n",
      "Minutes elapsed: 3.345994015534719\n",
      "last loss: [3667.97564519], reward: 82, loss/reward: [44.73141031]\n",
      "Epoch 60\n",
      "Minutes elapsed: 3.3972939531008404\n",
      "last loss: [3878.74533218], reward: 76, loss/reward: [51.03612279]\n",
      "Epoch 61\n",
      "Minutes elapsed: 3.443673761685689\n",
      "last loss: [3911.96506206], reward: 72, loss/reward: [54.33284808]\n",
      "Epoch 62\n",
      "Minutes elapsed: 3.50494038661321\n",
      "last loss: [2864.3041601], reward: 97, loss/reward: [29.52890887]\n",
      "Epoch 63\n",
      "Minutes elapsed: 3.5526195883750917\n",
      "last loss: [3319.02978635], reward: 79, loss/reward: [42.01303527]\n",
      "Epoch 64\n",
      "Minutes elapsed: 3.600390839576721\n",
      "last loss: [3919.06654295], reward: 80, loss/reward: [48.98833179]\n",
      "Epoch 65\n",
      "Minutes elapsed: 3.6533054669698077\n",
      "last loss: [3494.86194292], reward: 88, loss/reward: [39.71434026]\n",
      "Epoch 66\n",
      "Minutes elapsed: 3.69808779557546\n",
      "last loss: [3648.75044529], reward: 74, loss/reward: [49.30743845]\n",
      "Epoch 67\n",
      "Minutes elapsed: 3.7434903621673583\n",
      "last loss: [3948.39759775], reward: 75, loss/reward: [52.6453013]\n",
      "Epoch 68\n",
      "Minutes elapsed: 3.786885742346446\n",
      "last loss: [4070.45633941], reward: 72, loss/reward: [56.53411583]\n",
      "Epoch 69\n",
      "Minutes elapsed: 3.8394213279088336\n",
      "last loss: [3377.17896063], reward: 75, loss/reward: [45.02905281]\n",
      "Epoch 70\n",
      "Minutes elapsed: 3.8849244832992555\n",
      "last loss: [3377.77195145], reward: 72, loss/reward: [46.91349933]\n",
      "Epoch 71\n",
      "Minutes elapsed: 3.9280088822046917\n",
      "last loss: [3722.46305623], reward: 71, loss/reward: [52.42905713]\n",
      "Epoch 72\n",
      "Minutes elapsed: 3.9706557552019754\n",
      "last loss: [3425.69408208], reward: 70, loss/reward: [48.93848689]\n",
      "Epoch 73\n",
      "Minutes elapsed: 4.015152887503306\n",
      "last loss: [3639.65875769], reward: 73, loss/reward: [49.85833915]\n",
      "Epoch 74\n",
      "Minutes elapsed: 4.062780944506327\n",
      "last loss: [3514.90285135], reward: 77, loss/reward: [45.64808898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75\n",
      "Minutes elapsed: 4.118473879496256\n",
      "last loss: [3306.00741695], reward: 92, loss/reward: [35.93486323]\n",
      "Epoch 76\n",
      "Minutes elapsed: 4.168224334716797\n",
      "last loss: [3552.16291369], reward: 83, loss/reward: [42.79714354]\n",
      "Epoch 77\n",
      "Minutes elapsed: 4.222195800145467\n",
      "last loss: [3927.71868076], reward: 81, loss/reward: [48.49035408]\n",
      "Epoch 78\n",
      "Minutes elapsed: 4.268730048338572\n",
      "last loss: [4054.09114814], reward: 72, loss/reward: [56.3068215]\n",
      "Epoch 79\n",
      "Minutes elapsed: 4.310725967089335\n",
      "last loss: [3433.55799094], reward: 65, loss/reward: [52.82396909]\n",
      "Epoch 80\n",
      "Minutes elapsed: 4.3590717792510985\n",
      "last loss: [3530.71724991], reward: 80, loss/reward: [44.13396562]\n",
      "Epoch 81\n",
      "Minutes elapsed: 4.4056814312934875\n",
      "last loss: [3469.16760847], reward: 77, loss/reward: [45.05412479]\n",
      "Epoch 82\n",
      "Minutes elapsed: 4.453040297826131\n",
      "last loss: [3348.93649425], reward: 75, loss/reward: [44.65248659]\n",
      "Epoch 83\n",
      "Minutes elapsed: 4.49835901260376\n",
      "last loss: [2991.18385445], reward: 69, loss/reward: [43.35049064]\n",
      "Epoch 84\n",
      "Minutes elapsed: 4.543038463592529\n",
      "last loss: [3811.30736575], reward: 72, loss/reward: [52.93482452]\n",
      "Epoch 85\n",
      "Minutes elapsed: 4.600025081634522\n",
      "last loss: [3680.79079228], reward: 77, loss/reward: [47.80247782]\n",
      "Epoch 86\n",
      "Minutes elapsed: 4.64580397605896\n",
      "last loss: [4012.1001778], reward: 70, loss/reward: [57.31571683]\n",
      "Epoch 87\n",
      "Minutes elapsed: 4.704179100195566\n",
      "last loss: [4024.19172227], reward: 80, loss/reward: [50.30239653]\n",
      "Epoch 88\n",
      "Minutes elapsed: 4.792588806152343\n",
      "last loss: [3882.68525823], reward: 133, loss/reward: [29.19312224]\n",
      "Epoch 89\n",
      "Minutes elapsed: 4.871187233924866\n",
      "last loss: [3208.355871], reward: 118, loss/reward: [27.18945653]\n",
      "Epoch 90\n",
      "Minutes elapsed: 4.9214932481447855\n",
      "last loss: [4226.59233897], reward: 78, loss/reward: [54.18708127]\n",
      "Epoch 91\n",
      "Minutes elapsed: 4.973985497156779\n",
      "last loss: [4125.15029718], reward: 87, loss/reward: [47.41552066]\n",
      "Epoch 92\n",
      "Minutes elapsed: 5.018409184614817\n",
      "last loss: [3675.69222387], reward: 67, loss/reward: [54.86107797]\n",
      "Epoch 93\n",
      "Minutes elapsed: 5.059579249223074\n",
      "last loss: [3311.81106893], reward: 71, loss/reward: [46.64522632]\n",
      "Epoch 94\n",
      "Minutes elapsed: 5.098699406782786\n",
      "last loss: [3930.13311635], reward: 67, loss/reward: [58.65870323]\n",
      "Epoch 95\n",
      "Minutes elapsed: 5.151998515923818\n",
      "last loss: [3901.7052651], reward: 77, loss/reward: [50.67149695]\n",
      "Epoch 96\n",
      "Minutes elapsed: 5.203629374504089\n",
      "last loss: [3980.35794649], reward: 88, loss/reward: [45.2313403]\n",
      "Epoch 97\n",
      "Minutes elapsed: 5.249426829814911\n",
      "last loss: [3784.01151975], reward: 76, loss/reward: [49.78962526]\n",
      "Epoch 98\n",
      "Minutes elapsed: 5.288114229838054\n",
      "last loss: [3320.23888677], reward: 66, loss/reward: [50.3066498]\n",
      "Epoch 99\n",
      "Minutes elapsed: 5.339007786909739\n",
      "last loss: [3165.54746107], reward: 81, loss/reward: [39.08083285]\n",
      "Epoch 100\n",
      "Minutes elapsed: 5.387789531548818\n",
      "last loss: [3633.00013085], reward: 84, loss/reward: [43.25000156]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(100):\n",
    "    grads, loss_, reward_ = grad(epoch)\n",
    "    losses.append(loss_)\n",
    "    rewards.append(reward_)\n",
    "    optimizer.apply_gradients(zip(grads,epoch.get_variables()))\n",
    "#     if (i+1)%50 == 0:\n",
    "#         print('Epoch {}'.format(i+1))\n",
    "#         print('Minutes elapsed: {}'.format((time.time()-start)/60))\n",
    "#         print('last 50 average loss: {}'.format(np.mean(losses[-50:])))\n",
    "    print('Epoch {}'.format(i+1))\n",
    "    print('Minutes elapsed: {}'.format((time.time()-start)/60))\n",
    "    print('last loss: {}, reward: {}, loss/reward: {}'.format(loss_, reward_, loss_/reward_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2573.6466149]),\n",
       " array([3880.24722777]),\n",
       " array([2579.90640346]),\n",
       " array([2974.63688902]),\n",
       " array([3190.76265005]),\n",
       " array([2445.39038853]),\n",
       " array([4431.8222477]),\n",
       " array([3147.09144731]),\n",
       " array([3112.22784904]),\n",
       " array([3225.71902632]),\n",
       " array([2550.08122345]),\n",
       " array([3752.72610826]),\n",
       " array([2618.31997066]),\n",
       " array([4216.51816037]),\n",
       " array([4450.41260883]),\n",
       " array([3452.04615388]),\n",
       " array([2419.4378341]),\n",
       " array([2567.96629039]),\n",
       " array([5006.39892912]),\n",
       " array([4863.0796107]),\n",
       " array([2555.99314415]),\n",
       " array([2720.05399418]),\n",
       " array([2825.88328444]),\n",
       " array([3181.32689749]),\n",
       " array([2798.76050276]),\n",
       " array([3020.76610973]),\n",
       " array([2849.71233759]),\n",
       " array([2833.40990067]),\n",
       " array([3939.02185164]),\n",
       " array([2907.63701388]),\n",
       " array([2641.33001783]),\n",
       " array([2922.48055657]),\n",
       " array([2512.91967302]),\n",
       " array([2529.58060065]),\n",
       " array([5482.43263332]),\n",
       " array([3474.96899211]),\n",
       " array([2702.55840236]),\n",
       " array([2846.30224148]),\n",
       " array([2922.78109612]),\n",
       " array([2871.35641773]),\n",
       " array([2870.9623694]),\n",
       " array([3031.31851071]),\n",
       " array([3466.94607431]),\n",
       " array([3674.97963309]),\n",
       " array([2769.35389424]),\n",
       " array([2995.03858137]),\n",
       " array([3315.31083753]),\n",
       " array([2717.54758396]),\n",
       " array([5506.99914767]),\n",
       " array([3830.13602205]),\n",
       " array([3028.24673694]),\n",
       " array([3985.64885096]),\n",
       " array([6104.57095523]),\n",
       " array([2708.40514686]),\n",
       " array([2795.89683118]),\n",
       " array([2820.06835649]),\n",
       " array([3823.18135817]),\n",
       " array([3601.83571734]),\n",
       " array([4776.00324926]),\n",
       " array([2826.74809144]),\n",
       " array([2856.41520331]),\n",
       " array([3232.33971111]),\n",
       " array([4580.67444022]),\n",
       " array([2526.8742522]),\n",
       " array([2662.86739545]),\n",
       " array([2767.06251288]),\n",
       " array([3257.31651249]),\n",
       " array([3297.34135769]),\n",
       " array([2653.71806012]),\n",
       " array([4595.50759214]),\n",
       " array([2673.48160621]),\n",
       " array([4197.48237676]),\n",
       " array([4592.18011274]),\n",
       " array([2602.76733189]),\n",
       " array([4066.49897139]),\n",
       " array([3688.57707208]),\n",
       " array([3742.52295301]),\n",
       " array([4188.24326144]),\n",
       " array([2830.94966684]),\n",
       " array([2742.73848261]),\n",
       " array([3576.97722535]),\n",
       " array([3046.78592195]),\n",
       " array([2895.07894987]),\n",
       " array([2717.09378286]),\n",
       " array([3374.91193589]),\n",
       " array([2994.33813717]),\n",
       " array([4612.61083663]),\n",
       " array([2811.76387411]),\n",
       " array([3632.52971571]),\n",
       " array([2636.32312045]),\n",
       " array([3397.58888768]),\n",
       " array([2800.71027336]),\n",
       " array([5980.56185322]),\n",
       " array([2566.26746811]),\n",
       " array([2657.35988086]),\n",
       " array([3941.69331652]),\n",
       " array([3751.64158909]),\n",
       " array([2469.3894246]),\n",
       " array([2506.96106774]),\n",
       " array([2910.82924397]),\n",
       " array([2621.37050003]),\n",
       " array([3981.77389999]),\n",
       " array([3834.42126068]),\n",
       " array([5204.43793268]),\n",
       " array([2664.05052693]),\n",
       " array([4417.87533444]),\n",
       " array([2350.69412109]),\n",
       " array([4054.11778057]),\n",
       " array([3075.06494145]),\n",
       " array([2434.39575733]),\n",
       " array([2720.74097258]),\n",
       " array([3261.29697305]),\n",
       " array([4781.69969213]),\n",
       " array([3979.72542399]),\n",
       " array([3017.36482203]),\n",
       " array([2602.02035067]),\n",
       " array([3500.51144181]),\n",
       " array([3059.05473402]),\n",
       " array([4799.39014673]),\n",
       " array([3183.06313815]),\n",
       " array([3162.09188125]),\n",
       " array([3429.0943166]),\n",
       " array([2889.87813824]),\n",
       " array([4890.8100743]),\n",
       " array([3138.58485218]),\n",
       " array([2560.99956378]),\n",
       " array([3460.80274906]),\n",
       " array([2912.9571182]),\n",
       " array([2406.81258556]),\n",
       " array([2781.29853696]),\n",
       " array([2960.94164763]),\n",
       " array([3833.83832586]),\n",
       " array([2870.38113008]),\n",
       " array([4862.05778371]),\n",
       " array([4439.36376434]),\n",
       " array([2935.71475898]),\n",
       " array([3738.32644145]),\n",
       " array([2733.91854279]),\n",
       " array([3025.8535322]),\n",
       " array([3127.85794284]),\n",
       " array([3617.86758192]),\n",
       " array([2583.35403208]),\n",
       " array([3906.21984312]),\n",
       " array([4591.65538392]),\n",
       " array([2556.94295084]),\n",
       " array([2696.24962363]),\n",
       " array([3050.06029628]),\n",
       " array([2966.13397552]),\n",
       " array([2419.46007667]),\n",
       " array([2619.02141034]),\n",
       " array([2783.69260278]),\n",
       " array([2519.50198064]),\n",
       " array([3807.5842287]),\n",
       " array([3530.18929834]),\n",
       " array([3104.16245095]),\n",
       " array([2755.2875131]),\n",
       " array([2492.97639957]),\n",
       " array([3427.47883588]),\n",
       " array([2953.35650688]),\n",
       " array([3906.08956352]),\n",
       " array([2821.45270289]),\n",
       " array([2551.16965188]),\n",
       " array([2748.84403336]),\n",
       " array([3575.78245463]),\n",
       " array([6002.50683466]),\n",
       " array([3383.94057924]),\n",
       " array([2495.19416229]),\n",
       " array([2645.62773422]),\n",
       " array([2763.08409228]),\n",
       " array([4266.70714742]),\n",
       " array([2901.47382656]),\n",
       " array([3820.45399284]),\n",
       " array([2470.49011407]),\n",
       " array([3096.92578462]),\n",
       " array([2699.24764977]),\n",
       " array([2626.41965963]),\n",
       " array([3849.84818412]),\n",
       " array([4117.55240585]),\n",
       " array([3426.9471346]),\n",
       " array([4214.44219697]),\n",
       " array([3458.07685782]),\n",
       " array([4271.81834239]),\n",
       " array([3190.81203061]),\n",
       " array([2771.26365824]),\n",
       " array([2983.2415342]),\n",
       " array([2596.47719769]),\n",
       " array([2575.20951733]),\n",
       " array([2364.86015278]),\n",
       " array([3168.8491859]),\n",
       " array([4250.32055591]),\n",
       " array([2759.40257373]),\n",
       " array([3395.3212466]),\n",
       " array([2609.30714254]),\n",
       " array([3172.13029009]),\n",
       " array([3647.97093331]),\n",
       " array([2614.1260184]),\n",
       " array([4298.84375685]),\n",
       " array([4190.39154992]),\n",
       " array([2598.76572696]),\n",
       " array([2616.89928106]),\n",
       " array([2546.20406441]),\n",
       " array([3169.76867966]),\n",
       " array([2881.60920718]),\n",
       " array([2857.2634963]),\n",
       " array([2724.82195889]),\n",
       " array([2820.5380121]),\n",
       " array([4023.41123757]),\n",
       " array([4157.81657955]),\n",
       " array([3518.6262645]),\n",
       " array([2600.52830785]),\n",
       " array([4037.78466114]),\n",
       " array([2826.8104234]),\n",
       " array([3724.36605042]),\n",
       " array([2395.33794023]),\n",
       " array([3872.00068735]),\n",
       " array([2911.17584755]),\n",
       " array([3772.09322869]),\n",
       " array([3405.62703064]),\n",
       " array([2708.57831354]),\n",
       " array([3028.36623426]),\n",
       " array([3207.82015211]),\n",
       " array([3012.04619195]),\n",
       " array([2947.25838601]),\n",
       " array([2773.07018478]),\n",
       " array([4810.23186311]),\n",
       " array([2760.39891718]),\n",
       " array([3295.98358442]),\n",
       " array([3415.1441871]),\n",
       " array([3079.99416816]),\n",
       " array([3559.29834851]),\n",
       " array([2751.81037279]),\n",
       " array([3440.68266018]),\n",
       " array([3319.2179144]),\n",
       " array([2580.48680037]),\n",
       " array([3532.76713183]),\n",
       " array([3902.52262223]),\n",
       " array([3750.13989292]),\n",
       " array([2314.8444074]),\n",
       " array([3745.65817186]),\n",
       " array([3492.4117418]),\n",
       " array([4292.47917985]),\n",
       " array([2797.88477682]),\n",
       " array([3357.32403417]),\n",
       " array([2610.9058716]),\n",
       " array([2541.74885184]),\n",
       " array([3529.57157025]),\n",
       " array([2882.49098726]),\n",
       " array([2839.16511972]),\n",
       " array([3263.34395715]),\n",
       " array([2560.76020192]),\n",
       " array([2647.86958521]),\n",
       " array([2795.39979173]),\n",
       " array([3249.90910794]),\n",
       " array([2964.38518919]),\n",
       " array([2988.00289608]),\n",
       " array([3475.76167175]),\n",
       " array([3063.10209583]),\n",
       " array([2738.23667374]),\n",
       " array([2747.39598355]),\n",
       " array([2933.40063221]),\n",
       " array([2849.87782101]),\n",
       " array([3291.03967353]),\n",
       " array([3829.91635642]),\n",
       " array([2606.27789663]),\n",
       " array([3764.62586166]),\n",
       " array([4133.6750447]),\n",
       " array([2872.55551788]),\n",
       " array([3450.38592055]),\n",
       " array([2677.5653364]),\n",
       " array([3151.5926601]),\n",
       " array([4471.47347889]),\n",
       " array([5303.19443458]),\n",
       " array([2761.1283634]),\n",
       " array([3452.65534749]),\n",
       " array([3658.58328095]),\n",
       " array([2842.73356159]),\n",
       " array([4930.72059642]),\n",
       " array([3616.14548629]),\n",
       " array([3221.34514571]),\n",
       " array([3186.15901695]),\n",
       " array([4062.2624336]),\n",
       " array([3630.17664127]),\n",
       " array([3445.95760657]),\n",
       " array([4689.97849058]),\n",
       " array([2607.70544594]),\n",
       " array([2692.37421615]),\n",
       " array([3242.34478821]),\n",
       " array([2993.63104568]),\n",
       " array([3060.92263535]),\n",
       " array([2784.99938136]),\n",
       " array([2753.88485115]),\n",
       " array([2579.84836141]),\n",
       " array([5497.62351077]),\n",
       " array([2778.9653305]),\n",
       " array([4509.75448868]),\n",
       " array([3644.08657142]),\n",
       " array([3093.79165023]),\n",
       " array([2539.45159287]),\n",
       " array([2885.93135607]),\n",
       " array([2861.49077491]),\n",
       " array([3036.18171741]),\n",
       " array([3548.44996469]),\n",
       " array([2583.10951893]),\n",
       " array([3049.19966858]),\n",
       " array([2983.55811015]),\n",
       " array([2784.51525133]),\n",
       " array([2809.74707916]),\n",
       " array([2786.14731347]),\n",
       " array([3086.73947398]),\n",
       " array([2527.05905931]),\n",
       " array([2686.80458299]),\n",
       " array([2584.48312136]),\n",
       " array([2871.17109483]),\n",
       " array([2831.11320024]),\n",
       " array([2859.01817883]),\n",
       " array([4086.29048516]),\n",
       " array([3296.9594633]),\n",
       " array([5035.93174851]),\n",
       " array([3060.68106327]),\n",
       " array([2828.0653367]),\n",
       " array([3773.47164029]),\n",
       " array([2822.08233315]),\n",
       " array([2994.7337198]),\n",
       " array([5740.11122751]),\n",
       " array([3037.42258424]),\n",
       " array([3510.88061416]),\n",
       " array([2633.61925662]),\n",
       " array([3348.92600042]),\n",
       " array([3019.742746]),\n",
       " array([2390.9186604]),\n",
       " array([2961.07638525]),\n",
       " array([3494.69295685]),\n",
       " array([3024.77606701]),\n",
       " array([2653.48791299]),\n",
       " array([3576.68183077]),\n",
       " array([3190.2539853]),\n",
       " array([2928.79193553]),\n",
       " array([3665.24848122]),\n",
       " array([3211.40136602]),\n",
       " array([3220.87128836]),\n",
       " array([4128.68437678]),\n",
       " array([3206.09648553]),\n",
       " array([7633.91771079]),\n",
       " array([2843.97829851]),\n",
       " array([3402.65608602]),\n",
       " array([3091.94012453]),\n",
       " array([3937.2148175]),\n",
       " array([3445.24630011]),\n",
       " array([3315.81626275]),\n",
       " array([3007.35518859]),\n",
       " array([2493.10010011]),\n",
       " array([2830.81111001]),\n",
       " array([3006.88710738]),\n",
       " array([3006.23228707]),\n",
       " array([3288.09514502]),\n",
       " array([3218.86995816]),\n",
       " array([5620.54982235]),\n",
       " array([3114.35165855]),\n",
       " array([2854.21553736]),\n",
       " array([2888.39373748]),\n",
       " array([3703.12836053]),\n",
       " array([2597.57514203]),\n",
       " array([2556.85299759]),\n",
       " array([4432.22077774]),\n",
       " array([3349.36320005]),\n",
       " array([2901.91123257]),\n",
       " array([2496.82571827]),\n",
       " array([2770.22759497]),\n",
       " array([3212.18163422]),\n",
       " array([2691.30707935]),\n",
       " array([3289.42073141]),\n",
       " array([2535.51021909]),\n",
       " array([3339.19968112]),\n",
       " array([3182.73324131]),\n",
       " array([3123.20402391]),\n",
       " array([3399.86410184]),\n",
       " array([2444.84143657]),\n",
       " array([3018.80619369]),\n",
       " array([3419.27734142]),\n",
       " array([3662.63797229]),\n",
       " array([3250.61200756]),\n",
       " array([3475.35652684]),\n",
       " array([3366.36401811]),\n",
       " array([4819.69208169]),\n",
       " array([2814.98718017]),\n",
       " array([6916.65619707]),\n",
       " array([3653.44821027]),\n",
       " array([4525.98044991]),\n",
       " array([2696.56454165]),\n",
       " array([5571.14597704]),\n",
       " array([3526.22814023]),\n",
       " array([3171.2292444]),\n",
       " array([2830.86063323]),\n",
       " array([3032.56979135]),\n",
       " array([3315.08637365]),\n",
       " array([3231.39954703]),\n",
       " array([2557.60541634]),\n",
       " array([2990.55944718]),\n",
       " array([2683.42060976]),\n",
       " array([3006.80148226]),\n",
       " array([4101.734774]),\n",
       " array([3158.81580537]),\n",
       " array([2667.76590894]),\n",
       " array([2713.21971616]),\n",
       " array([3220.14758544]),\n",
       " array([4944.05660042]),\n",
       " array([2634.45210275]),\n",
       " array([3587.1811285]),\n",
       " array([4952.01633648]),\n",
       " array([3030.8520655]),\n",
       " array([2926.78141867]),\n",
       " array([4126.26408537]),\n",
       " array([2834.30875077]),\n",
       " array([3367.38934076]),\n",
       " array([3838.58578614]),\n",
       " array([2971.70860301]),\n",
       " array([4656.52128927]),\n",
       " array([3115.30079645]),\n",
       " array([4031.21429158]),\n",
       " array([2512.65709348]),\n",
       " array([3096.8058139]),\n",
       " array([2871.06770328]),\n",
       " array([2751.72035224]),\n",
       " array([2611.17215306]),\n",
       " array([3253.87505269]),\n",
       " array([3062.27890982]),\n",
       " array([3152.42985466]),\n",
       " array([3763.0303905]),\n",
       " array([2491.71455002]),\n",
       " array([3257.46691791]),\n",
       " array([2824.48274987]),\n",
       " array([3951.74027837]),\n",
       " array([3010.89404028]),\n",
       " array([2831.70331172]),\n",
       " array([4087.89584958]),\n",
       " array([3874.58210113]),\n",
       " array([2692.5638838]),\n",
       " array([2697.5889313]),\n",
       " array([2716.38370251]),\n",
       " array([3298.64306988]),\n",
       " array([3270.06827087]),\n",
       " array([3556.24641142]),\n",
       " array([2571.69261001]),\n",
       " array([2695.97565303]),\n",
       " array([2161.57673797]),\n",
       " array([2986.39399421]),\n",
       " array([3532.2659835]),\n",
       " array([2789.28555179]),\n",
       " array([3618.90839211]),\n",
       " array([3082.56194662]),\n",
       " array([4498.74965948]),\n",
       " array([3070.44604767]),\n",
       " array([4375.53622873]),\n",
       " array([3033.98257218]),\n",
       " array([3251.66261686]),\n",
       " array([2727.23868078]),\n",
       " array([5611.2351719]),\n",
       " array([3614.29258681]),\n",
       " array([2684.28579932]),\n",
       " array([2754.72411959]),\n",
       " array([3292.53556179]),\n",
       " array([2957.79590899]),\n",
       " array([3920.75843855]),\n",
       " array([2630.43217368]),\n",
       " array([2928.08461792]),\n",
       " array([2572.95914305]),\n",
       " array([2656.82044084]),\n",
       " array([2339.60267085]),\n",
       " array([3247.60976459]),\n",
       " array([2705.36247189]),\n",
       " array([2843.07208554]),\n",
       " array([3472.80913788]),\n",
       " array([3030.24492545]),\n",
       " array([2561.25432899]),\n",
       " array([2495.3899348]),\n",
       " array([2793.51845229]),\n",
       " array([3798.92777062]),\n",
       " array([3276.79520273]),\n",
       " array([3818.83354851]),\n",
       " array([4381.62273405]),\n",
       " array([2951.12770102]),\n",
       " array([4148.5676582]),\n",
       " array([3563.06391068]),\n",
       " array([4161.12112043]),\n",
       " array([3151.34451287]),\n",
       " array([2951.86813472]),\n",
       " array([3834.54269906]),\n",
       " array([2455.79439516]),\n",
       " array([2849.64476434]),\n",
       " array([3111.15861946]),\n",
       " array([4307.98641072]),\n",
       " array([3343.55407085]),\n",
       " array([3583.28447282]),\n",
       " array([2711.94428265]),\n",
       " array([3415.23511636]),\n",
       " array([2887.59120698]),\n",
       " array([3400.51082973]),\n",
       " array([3078.05708303]),\n",
       " array([2554.34756177]),\n",
       " array([2805.13366242]),\n",
       " array([2483.27584791]),\n",
       " array([2976.16667003]),\n",
       " array([2856.19570443]),\n",
       " array([3756.84551345]),\n",
       " array([4163.03962507]),\n",
       " array([4068.32195778]),\n",
       " array([3281.42069375]),\n",
       " array([3412.21328517]),\n",
       " array([3360.20582949]),\n",
       " array([4431.55811745]),\n",
       " array([3083.98073078]),\n",
       " array([3054.56926395]),\n",
       " array([3931.35601557]),\n",
       " array([2723.56682169]),\n",
       " array([2606.03029643]),\n",
       " array([2772.43559289]),\n",
       " array([3466.8528009]),\n",
       " array([4453.93698833]),\n",
       " array([2547.46701288]),\n",
       " array([2917.87688485]),\n",
       " array([3178.15925799]),\n",
       " array([2744.13705388]),\n",
       " array([2659.11419612]),\n",
       " array([3331.48348131]),\n",
       " array([3857.2896322]),\n",
       " array([4729.50979872]),\n",
       " array([3196.89961895]),\n",
       " array([7399.45989797]),\n",
       " array([2522.79916409]),\n",
       " array([5922.35789551]),\n",
       " array([2410.79781766]),\n",
       " array([3342.0711786]),\n",
       " array([3215.45435559]),\n",
       " array([3893.71794699]),\n",
       " array([2963.25469442]),\n",
       " array([2715.73959596]),\n",
       " array([3951.4482263]),\n",
       " array([2778.09596989]),\n",
       " array([3608.24685561]),\n",
       " array([4168.20107141]),\n",
       " array([2698.36742594]),\n",
       " array([3519.3008957]),\n",
       " array([2770.86629373]),\n",
       " array([2789.41132324]),\n",
       " array([2556.92826103]),\n",
       " array([2554.52490533]),\n",
       " array([3261.31615989]),\n",
       " array([2925.848486]),\n",
       " array([2797.8668401]),\n",
       " array([3630.23801412]),\n",
       " array([2706.68588162]),\n",
       " array([3103.83361192]),\n",
       " array([5686.07818646]),\n",
       " array([2664.67496094]),\n",
       " array([4652.00850511]),\n",
       " array([2522.41671044]),\n",
       " array([3915.35127828]),\n",
       " array([2964.36459331]),\n",
       " array([2611.19356072]),\n",
       " array([2706.52289251]),\n",
       " array([3484.03830013]),\n",
       " array([3044.76184372]),\n",
       " array([3178.4162369]),\n",
       " array([2667.38076392]),\n",
       " array([3069.22128137]),\n",
       " array([2537.11129127]),\n",
       " array([2744.11894482]),\n",
       " array([3003.1286562]),\n",
       " array([2664.83723746]),\n",
       " array([3414.29922218]),\n",
       " array([2567.42539411]),\n",
       " array([3059.83291451]),\n",
       " array([3221.30906631]),\n",
       " array([2834.23391746]),\n",
       " array([3139.16160288]),\n",
       " array([2879.34579168]),\n",
       " array([3075.199587]),\n",
       " array([3078.44294433]),\n",
       " array([3737.0291364]),\n",
       " array([2489.22192836]),\n",
       " array([3199.24688586]),\n",
       " array([2756.29480819]),\n",
       " array([3051.45429978]),\n",
       " array([2919.11914077]),\n",
       " array([2665.28167022]),\n",
       " array([5137.96663538]),\n",
       " array([2840.14820509]),\n",
       " array([3003.51969484]),\n",
       " array([3243.63734422]),\n",
       " array([2720.19592169]),\n",
       " array([3183.33513158]),\n",
       " array([2732.08969266]),\n",
       " array([5219.48086805]),\n",
       " array([2830.02105395]),\n",
       " array([4118.43782148]),\n",
       " array([4154.82138467]),\n",
       " array([3996.34992691]),\n",
       " array([2944.98642308]),\n",
       " array([3036.84454105]),\n",
       " array([3049.60878201]),\n",
       " array([2563.80653664]),\n",
       " array([3331.38411216]),\n",
       " array([4625.39502671]),\n",
       " array([3549.96599011]),\n",
       " array([4216.98711938]),\n",
       " array([2402.48972229]),\n",
       " array([2486.55787002]),\n",
       " array([3730.36768936]),\n",
       " array([4525.81809221]),\n",
       " array([3717.17512656]),\n",
       " array([2753.06931307]),\n",
       " array([3749.81740662]),\n",
       " array([2784.18379951]),\n",
       " array([3306.93823779]),\n",
       " array([2516.69876868]),\n",
       " array([3235.3857901]),\n",
       " array([3389.51420986]),\n",
       " array([3089.43289012]),\n",
       " array([2889.01010211]),\n",
       " array([3321.08292277]),\n",
       " array([2896.70066382]),\n",
       " array([2824.87419983]),\n",
       " array([2525.96201777]),\n",
       " array([3509.00359322]),\n",
       " array([3145.14705692]),\n",
       " array([3777.68470959]),\n",
       " array([2523.69680443]),\n",
       " array([3060.7726272]),\n",
       " array([3133.18346646]),\n",
       " array([3859.90131732]),\n",
       " array([2645.42374188]),\n",
       " array([2687.53293215]),\n",
       " array([2730.03364173]),\n",
       " array([2921.52871695]),\n",
       " array([2810.46327973]),\n",
       " array([3507.33020244]),\n",
       " array([3842.26203371]),\n",
       " array([2483.74174264]),\n",
       " array([2796.96520836]),\n",
       " array([2743.31688129]),\n",
       " array([3129.10760603]),\n",
       " array([2536.47491131]),\n",
       " array([5364.65997438]),\n",
       " array([3403.22497223]),\n",
       " array([2777.78745716]),\n",
       " array([2646.40409664]),\n",
       " array([3749.45977548]),\n",
       " array([3132.82261268]),\n",
       " array([2824.14512145]),\n",
       " array([2744.33156492]),\n",
       " array([3672.73670005]),\n",
       " array([3029.52330466]),\n",
       " array([3934.91227353]),\n",
       " array([2424.93318715]),\n",
       " array([2513.56687178]),\n",
       " array([3202.09832717]),\n",
       " array([3270.32744506]),\n",
       " array([3654.39389937]),\n",
       " array([3211.89328119]),\n",
       " array([3062.1335512]),\n",
       " array([2574.65702757]),\n",
       " array([3999.42827358]),\n",
       " array([6329.77693139]),\n",
       " array([2529.6488826]),\n",
       " array([3014.69086637]),\n",
       " array([2967.7049423]),\n",
       " array([3421.67723752]),\n",
       " array([2570.43002843]),\n",
       " array([3455.93351939]),\n",
       " array([3301.87859131]),\n",
       " array([3256.46888476]),\n",
       " array([2997.13377684]),\n",
       " array([3811.58100187]),\n",
       " array([4731.94573316]),\n",
       " array([3746.46656551]),\n",
       " array([4033.34361291]),\n",
       " array([3094.2741691]),\n",
       " array([3625.34527465]),\n",
       " array([3105.28090552]),\n",
       " array([3518.80078101]),\n",
       " array([2847.8407052]),\n",
       " array([4760.06829733]),\n",
       " array([2925.49766098]),\n",
       " array([3908.19853247]),\n",
       " array([2575.34833713]),\n",
       " array([3648.96216983]),\n",
       " array([3674.83786]),\n",
       " array([4513.37389407]),\n",
       " array([3027.16911193]),\n",
       " array([2707.04550946]),\n",
       " array([2866.08986949]),\n",
       " array([3504.4036752]),\n",
       " array([4016.5782636]),\n",
       " array([3817.28017926]),\n",
       " array([2529.02412665]),\n",
       " array([3478.26579149]),\n",
       " array([3711.97314959]),\n",
       " array([3135.96754801]),\n",
       " array([2733.58602052]),\n",
       " array([3948.69018784]),\n",
       " array([3229.15557792]),\n",
       " array([2859.65781406]),\n",
       " array([3456.04342998]),\n",
       " array([3856.80443221]),\n",
       " array([2732.19686311]),\n",
       " array([2513.43608489]),\n",
       " array([2829.98383355]),\n",
       " array([2884.08174515]),\n",
       " array([2656.48063336]),\n",
       " array([3263.6823013]),\n",
       " array([2704.25043874]),\n",
       " array([3017.19225905]),\n",
       " array([2446.39432099]),\n",
       " array([3087.07908773]),\n",
       " array([3086.48552688]),\n",
       " array([3027.10259037]),\n",
       " array([3988.76096837]),\n",
       " array([2869.85862036]),\n",
       " array([5003.81742961]),\n",
       " array([3530.98529758]),\n",
       " array([2938.66433515]),\n",
       " array([4987.85220398]),\n",
       " array([3613.85015674]),\n",
       " array([2752.9725787]),\n",
       " array([3238.91290479]),\n",
       " array([2879.00322736]),\n",
       " array([2966.56601063]),\n",
       " array([4767.26929557]),\n",
       " array([2661.08883905]),\n",
       " array([3240.79199039]),\n",
       " array([3322.79851647]),\n",
       " array([3803.98644404]),\n",
       " array([4725.83778205]),\n",
       " array([3647.80526077]),\n",
       " array([2945.19288877]),\n",
       " array([2553.26273753]),\n",
       " array([3923.90581118]),\n",
       " array([2977.08447124]),\n",
       " array([2894.85496904]),\n",
       " array([2645.36127762]),\n",
       " array([5028.8027007]),\n",
       " array([2780.67079397]),\n",
       " array([2735.99872264]),\n",
       " array([3003.02198309]),\n",
       " array([2568.08908358]),\n",
       " array([2935.93188312]),\n",
       " array([2630.031334]),\n",
       " array([2523.2281357]),\n",
       " array([3574.68744564]),\n",
       " array([2752.40520666]),\n",
       " array([3475.70852179]),\n",
       " array([2435.50182644]),\n",
       " array([3995.22752681]),\n",
       " array([3432.20603554]),\n",
       " array([3492.47945273]),\n",
       " array([5083.95376142]),\n",
       " array([2560.13635106]),\n",
       " array([3709.40326031]),\n",
       " array([2742.98400323]),\n",
       " array([3673.0056424]),\n",
       " array([3803.54883268]),\n",
       " array([2725.21901867]),\n",
       " array([3144.14298296]),\n",
       " array([3165.46065821]),\n",
       " array([3983.12429339]),\n",
       " array([3097.02893002]),\n",
       " array([3263.87045202]),\n",
       " array([3824.17016154]),\n",
       " array([2917.80681175]),\n",
       " array([2819.61256926]),\n",
       " array([3582.23363084]),\n",
       " array([2591.34684339]),\n",
       " array([2854.0892087]),\n",
       " array([3055.21963763]),\n",
       " array([3424.8685961]),\n",
       " array([3354.81686782]),\n",
       " array([2898.47293667]),\n",
       " array([2822.13840158]),\n",
       " array([3757.68104709]),\n",
       " array([2797.43483864]),\n",
       " array([2910.91179301]),\n",
       " array([2943.78362142]),\n",
       " array([2818.1249102]),\n",
       " array([3951.80569199]),\n",
       " array([2805.55250492]),\n",
       " array([3167.84358769]),\n",
       " array([3407.7455371]),\n",
       " array([2370.1614971]),\n",
       " array([3133.68147507]),\n",
       " array([3824.9228337]),\n",
       " array([2142.97492569]),\n",
       " array([2676.21311176]),\n",
       " array([2566.10162222]),\n",
       " array([2988.51261363]),\n",
       " array([4915.34998856]),\n",
       " array([3951.28463297]),\n",
       " array([2470.96756077]),\n",
       " array([2800.96814099]),\n",
       " array([3768.90722652]),\n",
       " array([3899.86800138]),\n",
       " array([2832.38151737]),\n",
       " array([2738.41829061]),\n",
       " array([3097.8240338]),\n",
       " array([3098.13539771]),\n",
       " array([3393.8071321]),\n",
       " array([4188.13993487]),\n",
       " array([3462.55855037]),\n",
       " array([4213.39255956]),\n",
       " array([4891.43385827]),\n",
       " array([2733.78834502]),\n",
       " array([2801.68936807]),\n",
       " array([3245.5202763]),\n",
       " array([3529.68098512]),\n",
       " array([3143.3641309]),\n",
       " array([3840.6371855]),\n",
       " array([4064.61895794]),\n",
       " array([4114.44040828]),\n",
       " array([2760.43993519]),\n",
       " array([2510.5473107]),\n",
       " array([3387.71164906]),\n",
       " array([2788.11743725]),\n",
       " array([4607.28908072]),\n",
       " array([3983.90410287]),\n",
       " array([2635.44600682]),\n",
       " array([2897.38581393]),\n",
       " array([3853.80961094]),\n",
       " array([3970.93858063]),\n",
       " array([3639.49840842]),\n",
       " array([2668.7587317]),\n",
       " array([2960.54294646]),\n",
       " array([3457.34619119]),\n",
       " array([2947.79153347]),\n",
       " array([2658.64502238]),\n",
       " array([4040.3334239]),\n",
       " array([5036.81048085]),\n",
       " array([3099.05726137]),\n",
       " array([2874.80225684]),\n",
       " array([2890.88629825]),\n",
       " array([3079.54028899]),\n",
       " array([3191.08332778]),\n",
       " array([4659.85473628]),\n",
       " array([4161.99841918]),\n",
       " array([3387.45742711]),\n",
       " array([3060.94423739]),\n",
       " array([3547.82597482]),\n",
       " array([3811.66087621]),\n",
       " array([2594.45398889]),\n",
       " array([2625.42977354]),\n",
       " array([3822.39951779]),\n",
       " array([3084.35007133]),\n",
       " array([3481.0505872]),\n",
       " array([3329.42154685]),\n",
       " array([2777.43056377]),\n",
       " array([2625.3343754]),\n",
       " array([2743.37093907]),\n",
       " array([3203.31188868]),\n",
       " array([2599.89032976]),\n",
       " array([2668.70690761]),\n",
       " array([2832.15712937]),\n",
       " array([2962.38314231]),\n",
       " array([3453.41869862]),\n",
       " array([3209.10801195]),\n",
       " array([5248.59307032]),\n",
       " array([2900.13022187]),\n",
       " array([3034.14739329]),\n",
       " array([3060.29209715]),\n",
       " array([3143.74723663]),\n",
       " array([3267.39153325]),\n",
       " array([3293.47411807]),\n",
       " array([2748.26723923]),\n",
       " array([2761.63436643]),\n",
       " array([3357.13396516]),\n",
       " array([4161.66742366]),\n",
       " array([3109.41771388]),\n",
       " array([3813.55638146]),\n",
       " array([4352.57163231]),\n",
       " array([2962.34568213]),\n",
       " array([2564.64671576]),\n",
       " array([4457.01553337]),\n",
       " array([2800.95004529]),\n",
       " array([2906.85617632]),\n",
       " array([2798.85151178]),\n",
       " array([2597.18925708]),\n",
       " array([3385.31433966]),\n",
       " array([2696.92673716]),\n",
       " array([2529.82147993]),\n",
       " array([3241.02879897]),\n",
       " array([2921.52871153]),\n",
       " array([3151.60244152]),\n",
       " array([2874.52212375]),\n",
       " array([2329.39245084]),\n",
       " array([3014.96690004]),\n",
       " array([3215.716509]),\n",
       " array([4252.66680802]),\n",
       " array([4902.76102014]),\n",
       " array([2780.10028424]),\n",
       " array([2709.49381671]),\n",
       " array([3451.43594244]),\n",
       " array([2650.43283299]),\n",
       " array([2462.78565373]),\n",
       " array([3857.38449295]),\n",
       " array([3028.58159549]),\n",
       " array([2637.92232235]),\n",
       " array([3332.52489602]),\n",
       " array([4395.03542333]),\n",
       " array([3279.5336648]),\n",
       " array([2646.50079102]),\n",
       " array([3154.36012921]),\n",
       " array([3195.98607467]),\n",
       " array([3415.4323513]),\n",
       " array([3036.48354935]),\n",
       " array([2678.01643261]),\n",
       " array([3411.64564575]),\n",
       " array([3214.12731069]),\n",
       " array([2879.28231234]),\n",
       " array([3268.19815111]),\n",
       " array([2545.04129563]),\n",
       " array([2609.28572712]),\n",
       " array([4523.46701829]),\n",
       " array([2801.10288893]),\n",
       " array([2626.24807765]),\n",
       " array([3435.23664227]),\n",
       " array([2614.903239]),\n",
       " array([4129.33226354]),\n",
       " array([2829.59631629]),\n",
       " array([3159.11990966]),\n",
       " array([3361.40956985]),\n",
       " array([3398.81358974]),\n",
       " array([2880.51993926]),\n",
       " array([2816.68385964]),\n",
       " array([4105.6642301]),\n",
       " array([3796.32859919]),\n",
       " array([3563.04806025]),\n",
       " array([3081.3379975]),\n",
       " array([2786.58226023]),\n",
       " array([2825.33920354]),\n",
       " array([3270.43668244]),\n",
       " array([2775.72171797]),\n",
       " array([3029.62908265]),\n",
       " array([2907.7936808]),\n",
       " array([3091.61662035]),\n",
       " array([3072.02778359]),\n",
       " array([3670.11298944]),\n",
       " array([2922.21401801]),\n",
       " array([3027.90868822]),\n",
       " array([2756.4143488]),\n",
       " array([2391.90556572]),\n",
       " array([4100.24062921]),\n",
       " array([3537.45931535]),\n",
       " array([2904.5741206]),\n",
       " array([3168.8667993]),\n",
       " array([2956.75579506]),\n",
       " array([2810.53743882]),\n",
       " array([2894.20116936]),\n",
       " array([2671.56435405]),\n",
       " array([3247.77530115]),\n",
       " array([3266.01180982]),\n",
       " array([3216.55733699]),\n",
       " array([2985.17670489]),\n",
       " array([3229.64563385]),\n",
       " array([2749.94038465]),\n",
       " array([3065.79044837]),\n",
       " array([3516.40302703]),\n",
       " array([2938.09633552]),\n",
       " array([3137.03484893]),\n",
       " array([2899.73029135]),\n",
       " array([2957.68206902]),\n",
       " array([2953.56531065]),\n",
       " array([3876.45526798]),\n",
       " array([3199.09428935]),\n",
       " array([3672.40523906]),\n",
       " array([3111.41913038]),\n",
       " array([3407.00174103]),\n",
       " array([3161.61877665]),\n",
       " array([3394.7148847]),\n",
       " array([2589.80622009]),\n",
       " array([2312.04724779]),\n",
       " array([3146.09301875]),\n",
       " array([2371.67495301]),\n",
       " array([2272.33178939]),\n",
       " array([5552.73102583]),\n",
       " array([3130.34519027]),\n",
       " array([2804.78262191]),\n",
       " array([2408.96863679]),\n",
       " array([3215.7482821]),\n",
       " array([2526.69807667]),\n",
       " array([3640.57207324]),\n",
       " array([3065.51530301]),\n",
       " array([2560.39337614]),\n",
       " array([3014.56984237]),\n",
       " array([3039.21871295]),\n",
       " array([3180.91977936]),\n",
       " array([2853.96409753]),\n",
       " array([2716.18320969]),\n",
       " array([4826.96397152]),\n",
       " array([3314.45777499]),\n",
       " array([4905.09320303]),\n",
       " array([3062.03663044]),\n",
       " array([3981.81187163]),\n",
       " array([3033.799655])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(self, rho, z, z_pred):\n",
    "    if z > z_pred:\n",
    "        return rho*(z-z_pred)\n",
    "    else:\n",
    "        return (1-rho)*(z_pred-z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
