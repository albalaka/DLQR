\documentclass[twoside]{article}
\usepackage{amsmath,amsfonts,listings}
\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\begin{document}
\section{Ideas/Issues}
Even if I train the obseravtion model and the controls at the same time succesfully, how do I motivate the controls to do what I want?
Use the built in reward (+1 for every time frame where the pole is "up")?
\subsection{Training}
The considerations for training are:
\begin{itemize}
\item What/when I'm training (observation model, control, 
\item what the goal of that training is(learn to control the system, or just explore, i.e. learn to predict the next state)
\item How to get training samples(online/offline)
\item LSTM fixed/variable length
\item Inputs to LSTM(physical specifications, previous outputs, etc.)
\end{itemize}
\subsection{Thoughts}
\begin{itemize}
\item Train transition model with LQR, hope that the model learns how to linearize given any particular observation. Then separately train the learned transition/control models to put the pole into any place of our choosing. 
Loss function: euclidean distance from our desired state? Only works if we have knowledge of what the states mean
\item Suppose that I include the previous state as input to the LSTM, the system becomes auto-regressive, do the assumptions leading to the kalman filter, and the log-likelihood function still hold?
\end{itemize}

\section{Assumptions}
We have the linear dynamical system:\[\begin{array}{lclr}l_{t+1} & = & A_{t}l_{t}+B_{t}u_{t}+g_{t}\epsilon_{t}&\epsilon_{t}\sim\mathcal{N}(0,1) \\ Z_{t} & = & C_{t}l_{t} + D_{t}u_{t} + \sigma_{t}\varepsilon_{t} & \varepsilon_{t}\sim\mathcal{N}(0,1)\end{array}\]
where $A\in\mathbb{R}^{m\times n}, B\in\mathbb{R}^{m\times r}, C\in\mathbb{R}^{z\times m}, D\in\mathbb{R}^{z\times r}, l\in\mathbb{R}^{m}, u\in\mathbb{R}^{r}, Z\in\mathbb{R}^{z}, \epsilon\in\mathbb{R}^{m}, \varepsilon\in\mathbb{R}^{z}$
However, it simplifies if, as in our situation, C = I, and D = 0.

\section{Potential mistakes}
In computing the likelihood: $\mathcal{N}(z_{t}|\mu_{t},\Sigma_{t})$
Compare the paper's calculation:\[\begin{array}{lcl} \mu_{1} & = & a_{1}^{T}\mu_{0} \\ \Sigma_{1} & = & a_{1}^{T}\Sigma_{0}a_{1} + \sigma_{1}^{2} \\ \mu_{t} & = & a_{t}F_{t}f_{t-1} \\ \Sigma_{t} & = & a_{t}^{T}(F_{t}S_{t}F_{t}^{T}+g_{t}g_{t}^{T})a_{t}+\sigma_{t}^{2}\end{array}\]
with my control version:
\begin{lstlisting}
mu_1 = tf.matmul(trans(self.C)[0], self.mu_0)
mu = tf.matmul(C, tf.add(tf.matmul(A,l_filtered), tf.matmul(B,u)))

Sigma_1 = tf.matmul(tf.matmul(trans(self.C)[0], tf.linalg.diag(tf.squeeze(self.Sigma_0))),trans(self.C)[0], transpose_b=True)+tf.square(trans(self.sigma)[0])

temp = tf.matmul(tf.matmul(A, P_filtered), A, transpose_b=True) + tf.matmul(g, g, transpose_b=True)
Sigma = tf.matmul(tf.matmul(C, temp), C, transpose_b=True) + tf.square(sigma)
\end{lstlisting}
\end{document}