{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import control as ct\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as reg\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle as pkl\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_forward_filter_fn(A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,z):\n",
    "    '''Calculates prior distribution based on the previous posterior distribution\n",
    "        and the current residual updates posterior distribution based on the new\n",
    "        prior distribution\n",
    "    '''\n",
    "#     print('z',z)\n",
    "#     print('A', A)\n",
    "#     print('B',B)\n",
    "#     print('u',u)\n",
    "#     print('g',g)\n",
    "#     print('sigma',sigma)\n",
    "#     print('C', C)\n",
    "#     print('l_a_posteriori', l_a_posteriori)\n",
    "#     print('P_a_posteriori', P_a_posteriori)\n",
    "    _I = tf.eye(int(A.shape[0]), dtype = tf.float64)\n",
    "    \n",
    "    z = tf.reshape(z,[1,1])\n",
    "    l_a_priori = tf.matmul(A,l_a_posteriori) + tf.matmul(B,u)\n",
    "#     print('l_a_priori',l_a_priori)\n",
    "    P_a_priori = tf.matmul(tf.matmul(A,P_a_posteriori), A, transpose_b = True) + tf.matmul(g,g, transpose_b=True)\n",
    "#     print('P_a_priori',P_a_priori)\n",
    "    y_pre = z - tf.matmul(C,l_a_priori)\n",
    "#     print('y_pre', y_pre)\n",
    "    S = tf.square(sigma) + tf.matmul(tf.matmul(C, P_a_priori), C, transpose_b=True)\n",
    "#     print('S',S)\n",
    "    S_inv = tf.math.reciprocal(S)\n",
    "#     print('S_inv', S_inv)\n",
    "    K = tf.matmul(tf.matmul(P_a_priori, C, transpose_b=True), S_inv)\n",
    "#     print('K', K)\n",
    "    l_a_posteriori = l_a_priori + tf.matmul(K,y_pre)\n",
    "#     print('l_a_posteriori', l_a_posteriori)\n",
    "    I_KC = _I-tf.matmul(K,C)\n",
    "#     print('I-KC', I_KC)\n",
    "    P_a_posteriori = tf.matmul(tf.matmul(I_KC, P_a_priori), I_KC, transpose_b=True) + \\\n",
    "                        tf.matmul(tf.matmul(K,tf.matmul(sigma, sigma, transpose_b = True)),\n",
    "                                K, transpose_b=True)\n",
    "#     print('P_a_posteriori',P_a_posteriori)\n",
    "    y_post = z-tf.matmul(C,l_a_posteriori)\n",
    "    squared_error = tf.squeeze(tf.matmul(y_post,y_post, transpose_a=True))\n",
    "#     print(squared_error)\n",
    "#     print('y_post', y_post)\n",
    "    pred = tf.matmul(C, l_a_posteriori)\n",
    "#     print('pred', pred)\n",
    "\n",
    "    return l_a_posteriori,P_a_posteriori,z, pred, squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class split_KF_Model(object):\n",
    "    def __init__(self, model_name, thetaacc_error = 0, env_params_variation = [0,0,0,0], initial_state_variation = [0,0,0,0], control = False):\n",
    "        self.m = 4\n",
    "        self.dim_z = self.m\n",
    "        self.n = 4\n",
    "        self.r = 1\n",
    "        self.sigma_upper_bound = 1\n",
    "        self.sigma_lower_bound = 0\n",
    "        self.g_upper_bound = 1\n",
    "        self.g_lower_bound = 0.1\n",
    "        self.mu_0_upper_bound = 1\n",
    "        self.mu_0_lower_bound = 0\n",
    "        self.Sigma_0_upper_bound = 1\n",
    "        self.Sigma_0_lower_bound = 0\n",
    "        self.weight_beta = .1\n",
    "        self.bias_beta = .1\n",
    "        self.thetaacc_error = thetaacc_error\n",
    "        self.global_epoch = 0\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.mu_0_NN = tf.keras.Sequential(name = 'mu_0_NN', layers = [layers.Dense(self.m*8, activation = tf.sigmoid, kernel_regularizer = reg.l2(self.weight_beta),\n",
    "                                                            bias_regularizer = reg.l2(self.bias_beta),name = 'mu_0_dense1'),\n",
    "                                               layers.Dense(self.m, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l2(self.weight_beta),\n",
    "                                                            bias_regularizer = reg.l2(self.bias_beta),name = 'mu_0_dense2')])\n",
    "        self.Sigma_0_NN = tf.keras.Sequential(name='Sigma_0_NN',layers=[layers.Dense(self.m*8, activation = tf.sigmoid, kernel_regularizer = reg.l2(self.weight_beta),\n",
    "                                                               bias_regularizer = reg.l2(self.bias_beta),name = 'Sigma_0dense1'),\n",
    "                                                  layers.Dense(self.m, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l2(self.weight_beta),\n",
    "                                                               bias_regularizer = reg.l2(self.bias_beta),name = 'Sigma_0dense2')])\n",
    "        \n",
    "        self.A_NN = tf.keras.Sequential(name='A_dense_NN',layers=[layers.Dense(self.m*self.n*8, activation = tf.sigmoid, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                         bias_regularizer = reg.l2(self.bias_beta),name = 'A_dense1'),\n",
    "                                            layers.Dense(self.m*self.n, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                         bias_regularizer = reg.l2(self.bias_beta),name = 'A_dense2')])\n",
    "        self.g_NN = tf.keras.Sequential(name='g_dense_NN',layers=[layers.Dense(self.m*8, activation = tf.sigmoid, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                         bias_regularizer = reg.l2(self.bias_beta),name = 'g_dense1'),\n",
    "                                            layers.Dense(self.m, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                         bias_regularizer = reg.l2(self.bias_beta),name = 'g_dense2')])\n",
    "        self.sigma1_NN = tf.keras.Sequential(name='sigma1_dense_NN',layers=[layers.Dense(1*8, activation = tf.sigmoid, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma1_dense1'),\n",
    "                                                 layers.Dense(1, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma1_dense2')])\n",
    "        self.sigma2_NN = tf.keras.Sequential(name='sigma2_dense_NN',layers=[layers.Dense(1*8, activation = tf.sigmoid, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma2_dense1'),\n",
    "                                                 layers.Dense(1, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma2_dense2')])\n",
    "        self.sigma3_NN = tf.keras.Sequential(name='sigma3_dense_NN',layers=[layers.Dense(1*8, activation = tf.sigmoid, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma3_dense1'),\n",
    "                                                 layers.Dense(1, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma3_dense2')])\n",
    "        self.sigma4_NN = tf.keras.Sequential(name='sigma4_dense_NN',layers=[layers.Dense(1*8, activation = tf.sigmoid, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma4_dense1'),\n",
    "                                                 layers.Dense(1, activation = tf.nn.leaky_relu, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                                              bias_regularizer = reg.l2(self.bias_beta),name = 'sigma4_dense2')])\n",
    "        self.NNs = [self.mu_0_NN,self.Sigma_0_NN,self.A_NN,self.g_NN,\n",
    "                    self.sigma1_NN,self.sigma2_NN,self.sigma3_NN,self.sigma4_NN]\n",
    "        \n",
    "        self.lstm_sizes = [256,128]        \n",
    "        lstms = [tf.contrib.rnn.LSTMCell(size, reuse=tf.get_variable_scope().reuse) for size in self.lstm_sizes]\n",
    "        dropouts = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = 0.5) for lstm in lstms]\n",
    "\n",
    "        self.cell = tf.contrib.rnn.MultiRNNCell(dropouts)\n",
    "        dummy_state = self.cell.get_initial_state(batch_size=1,dtype = tf.float64)\n",
    "        dummy_input = tf.zeros([1,8],dtype = tf.float64)\n",
    "        dummy_output,dummy_state=self.cell(inputs=dummy_input,state=dummy_state)\n",
    "        \n",
    "        self.C_1 = tf.Variable(np.array([[1,0,0,0]]), dtype = tf.float64, trainable=False)\n",
    "        self.C_2 = tf.Variable(np.array([[0,1,0,0]]), dtype = tf.float64, trainable=False)\n",
    "        self.C_3 = tf.Variable(np.array([[0,0,1,0]]), dtype = tf.float64, trainable=False)\n",
    "        self.C_4 = tf.Variable(np.array([[0,0,0,1]]), dtype = tf.float64, trainable=False)\n",
    "        \n",
    "        '''Temporary LQR variables'''\n",
    "        self.Q = np.eye(4)*[1,1,100,1]\n",
    "        self.R = 100\n",
    "        self.u_clip_value = tf.Variable(10, dtype = tf.float64, trainable = False)\n",
    "\n",
    "        self.initial_variance_estimate = tf.Variable(np.array([[1]]), dtype = tf.float64, trainable=False) \n",
    "\n",
    "        self.env = gym.make('Custom_CartPole-v0', thetaacc_error=self.thetaacc_error, env_params_var=env_params_variation, initial_state_var=initial_state_variation)\n",
    "        gravity = self.env.gravity\n",
    "        cart_mass = self.env.masscart\n",
    "        pole_mass = self.env.masspole\n",
    "        pole_length = self.env.length\n",
    "        self.env_params = tf.expand_dims(np.array([gravity, cart_mass,pole_mass,pole_length],\n",
    "                                             dtype=np.float64),0)\n",
    "        self.control = control\n",
    "#         self.variables = []\n",
    "        \n",
    "    def build_LSTM(self):\n",
    "        lstms = [tf.contrib.rnn.LSTMCell(size, reuse=tf.get_variable_scope().reuse) for size in self.lstm_sizes]\n",
    "        dropouts = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = 0.5) for lstm in lstms]\n",
    "\n",
    "        self.cell = tf.contrib.rnn.MultiRNNCell(dropouts)\n",
    "        return self\n",
    "    \n",
    "#     def get_variables(self):\n",
    "#         return self.variables\n",
    "#     def reset_variables(self):\n",
    "#         self.variables = []\n",
    "#         return self\n",
    "    def set_control(self, control, control_type):\n",
    "        self.control = control\n",
    "        self.control_type = control_type\n",
    "        return self\n",
    "    def set_env(self,env_params_variation,initial_state_variation):\n",
    "        self.env = gym.make('Custom_CartPole-v0', thetaacc_error=self.thetaacc_error, env_params_var=env_params_variation, initial_state_var=initial_state_variation)\n",
    "        return self\n",
    "    def set_u_clip(self,u_clip_value):\n",
    "        self.u_clip_value = tf.Variable(u_clip_value, dtype = tf.float64, trainable = False)\n",
    "        return self\n",
    "    def set_LQR_params(self,Q, R):\n",
    "        self.Q = np.eye(4)*Q\n",
    "        self.R = R\n",
    "        return self\n",
    "    \n",
    "    def likelihood_fn(self, params, inputs):\n",
    "        A, B, u, g, C, sigma, l_filtered, P_filtered = inputs\n",
    "        mu_1, Sigma_1 = params\n",
    "#         print('A',len(A))\n",
    "#         print('B',len(B))\n",
    "#         print('u',len(u))\n",
    "#         print('C',len(C))\n",
    "#         print('g',len(g))\n",
    "#         print('sigma',len(sigma))\n",
    "#         print('l_filtered',len(l_filtered))\n",
    "#         print('p_filtered',len(P_filtered))\n",
    "#         print('mu_1',mu_1.shape)\n",
    "#         print('Sigma_1',Sigma_1.shape)\n",
    "        mu = [mu_1]\n",
    "        Sigma = [Sigma_1]\n",
    "        assert(len(A)==len(B) and len(B)==len(u) and len(u)==len(sigma) and \n",
    "               len(sigma)==len(l_filtered) and len(l_filtered)==len(P_filtered)),\"Not all sequences are same length\"\n",
    "        for i in range(len(A)):\n",
    "            mu.append(tf.matmul(C, tf.add(tf.matmul(A[i],l_filtered[i]), tf.matmul(B[i],u[i]))))\n",
    "            temp = tf.matmul(tf.matmul(A[i], P_filtered[i]), A[i], transpose_b=True) + \\\n",
    "                        tf.matmul(g[i], g[i], transpose_b=True)\n",
    "            Sigma.append(tf.matmul(tf.matmul(C, temp), C, transpose_b=True) + \\\n",
    "                        tf.matmul(sigma[i],sigma[i],transpose_b=True))\n",
    "        return mu,Sigma\n",
    "    \n",
    "    def step(self, output_single):\n",
    "        '''Calculate SSM parameters from LSTM output'''\n",
    "#         A = layers.Dense(output_single, self.m*self.n, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "#                             bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                             name = 'A_dense', reuse = True)\n",
    "#         g = layers.Dense(output_single, self.m, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "#                                 bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                                 name = 'g_dense', reuse = True)\n",
    "#         sigma1 = layers.Dense(output_single, 1, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "#                                  bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                                  name = 'sigma1_dense', reuse = True)\n",
    "#         sigma2 = layers.Dense(output_single, 1, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "#                                  bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                                  name = 'sigma2_dense', reuse = True)\n",
    "#         sigma3 = layers.Dense(output_single, 1, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "#                                  bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                                  name = 'sigma3_dense', reuse = True)\n",
    "#         sigma4 = layers.Dense(output_single, 1, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "#                                  bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                                  name = 'sigma4_dense', reuse = True)\n",
    "        A = self.A_NN(output_single)\n",
    "        g = self.g_NN(output_single)\n",
    "        sigma1 = self.sigma1_NN(output_single)\n",
    "        sigma2 = self.sigma2_NN(output_single)\n",
    "        sigma3 = self.sigma3_NN(output_single)\n",
    "        sigma4 = self.sigma4_NN(output_single)\n",
    "        A = tf.reshape(A, shape = (self.m,self.n))\n",
    "        g = tf.reshape(g, shape = (self.m, 1))\n",
    "        g = ((self.g_upper_bound-self.g_lower_bound)/(1+tf.exp(-g)))+self.g_lower_bound\n",
    "        sigma1 = ((self.sigma_upper_bound-self.sigma_lower_bound)/(1+tf.exp(-sigma1)))+self.sigma_lower_bound\n",
    "        sigma2 = ((self.sigma_upper_bound-self.sigma_lower_bound)/(1+tf.exp(-sigma2)))+self.sigma_lower_bound\n",
    "        sigma3 = ((self.sigma_upper_bound-self.sigma_lower_bound)/(1+tf.exp(-sigma3)))+self.sigma_lower_bound\n",
    "        sigma4 = ((self.sigma_upper_bound-self.sigma_lower_bound)/(1+tf.exp(-sigma4)))+self.sigma_lower_bound\n",
    "        return A, g, sigma1, sigma2, sigma3, sigma4\n",
    "    \n",
    "    def control_step(self, output_single, u, A, observation):\n",
    "        '''Calculate SSM parameter B from LSTM output, and\n",
    "            calculate u'''\n",
    "        B = tf.layers.Dense(output_single, self.m*self.r, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                            bias_regularizer = reg.l2(self.bias_beta),\n",
    "                            name = 'B_dense', reuse = True)\n",
    "        B = tf.reshape(B, shape = (self.m,self.r))\n",
    "        '''Use one of the below options for directly predicting u from LSTM'''\n",
    "        if self.control_type == 'NN regularized':\n",
    "            u = tf.layers.Dense(output_single, 1, kernel_regularizer = reg.l1(self.weight_beta),\n",
    "                                bias_regularizer = reg.l2(self.bias_beta),\n",
    "                                name = 'u_dense', reuse = True)\n",
    "        elif self.control_type == 'NN':\n",
    "            u = tf.layers.Dense(output_single, 1, name = 'u_dense', reuse = True)\n",
    "            '''LQR'''\n",
    "        elif self.control_type == 'LQR':\n",
    "            K,S,E = ct.lqr(A.numpy(),B.numpy(),self.Q,self.R)\n",
    "            u = -tf.matmul(K.astype(np.float64),\n",
    "                           tf.expand_dims(tf.convert_to_tensor(observation,dtype=tf.float64),-1))\n",
    "            u = tf.clip_by_value(u, -self.u_clip_value, self.u_clip_value)\n",
    "            '''Random action sampling'''\n",
    "        elif self.control_type == 'uniform random':\n",
    "            u = u + tf.random.uniform(shape = [1,self.r], minval=-3.5, maxval=3.5, dtype = tf.float64)\n",
    "        else:\n",
    "            pass\n",
    "        return B, u\n",
    "    \n",
    "    def look_ahead_prediction(self, prediction_horizon, observation, output_single, state_single,\n",
    "                              l_a_post1,l_a_post2,l_a_post3,l_a_post4,\n",
    "                              P_a_post1,P_a_post2,P_a_post3,P_a_post4):\n",
    "        LA_output_single = output_single\n",
    "        LA_state_single = state_single\n",
    "        \n",
    "        '''Set initial prediction states to current observation'''\n",
    "        LA_pred1 = tf.convert_to_tensor(observation[0], dtype = tf.float64)\n",
    "        LA_pred2 = tf.convert_to_tensor(observation[1], dtype = tf.float64)\n",
    "        LA_pred3 = tf.convert_to_tensor(observation[2], dtype = tf.float64)\n",
    "        LA_pred4 = tf.convert_to_tensor(observation[3], dtype = tf.float64)\n",
    "        LA_preds = []\n",
    "        LA_l_a_post1 = []\n",
    "        LA_l_a_post2 = []\n",
    "        LA_l_a_post3 = []\n",
    "        LA_l_a_post4 = []\n",
    "        LA_P_a_post1 = []\n",
    "        LA_P_a_post2 = []\n",
    "        LA_P_a_post3 = []\n",
    "        LA_P_a_post4 = []\n",
    "        LA_A = []\n",
    "        LA_B = []\n",
    "        LA_u = []\n",
    "        LA_g = []\n",
    "        LA_sigma1 = []\n",
    "        LA_sigma2 = []\n",
    "        LA_sigma3 = []\n",
    "        LA_sigma4 = []\n",
    "        \n",
    "        for i in range(prediction_horizon):\n",
    "            '''Get SSM parameters from LSTM'''\n",
    "            A_pred,g_pred,sigma1_pred,sigma2_pred,sigma3_pred,sigma4_pred = self.step(LA_output_single)\n",
    "            if self.control:\n",
    "                B_pred, u_pred = self.control_step(LA_output_single, u, A, observation)\n",
    "            else:\n",
    "                B_pred = tf.zeros(shape = (self.m,self.r), dtype = tf.float64)\n",
    "                u_pred = tf.zeros(shape = [1,self.r], dtype=tf.float64)\n",
    "                \n",
    "            LA_A.append(A_pred)\n",
    "            LA_B.append(B_pred)\n",
    "            LA_u.append(u_pred)\n",
    "            LA_g.append(g_pred)\n",
    "            LA_sigma1.append(sigma1_pred)\n",
    "            LA_sigma2.append(sigma2_pred)\n",
    "            LA_sigma3.append(sigma3_pred)\n",
    "            LA_sigma4.append(sigma4_pred)\n",
    "            '''Predict next states from Kalman Filter'''\n",
    "            l_a_post1,P_a_post1,env_state1,LA_pred1,_ = split_forward_filter_fn(A_pred,B_pred,u_pred,g_pred,self.C_1,sigma1_pred,l_a_post1,P_a_post1,LA_pred1)\n",
    "            l_a_post2,P_a_post2,env_state2,LA_pred2,_ = split_forward_filter_fn(A_pred,B_pred,u_pred,g_pred,self.C_2,sigma2_pred,l_a_post2,P_a_post2,LA_pred2)\n",
    "            l_a_post3,P_a_post3,env_state3,LA_pred3,_ = split_forward_filter_fn(A_pred,B_pred,u_pred,g_pred,self.C_3,sigma3_pred,l_a_post3,P_a_post3,LA_pred3)\n",
    "            l_a_post4,P_a_post4,env_state4,LA_pred4,_ = split_forward_filter_fn(A_pred,B_pred,u_pred,g_pred,self.C_4,sigma4_pred,l_a_post4,P_a_post4,LA_pred4)\n",
    "            LA_l_a_post1.append(l_a_post1)\n",
    "            LA_l_a_post2.append(l_a_post2)\n",
    "            LA_l_a_post3.append(l_a_post3)\n",
    "            LA_l_a_post4.append(l_a_post4)\n",
    "            LA_P_a_post1.append(P_a_post1)\n",
    "            LA_P_a_post2.append(P_a_post2)\n",
    "            LA_P_a_post3.append(P_a_post3)\n",
    "            LA_P_a_post4.append(P_a_post4)\n",
    "            LA_preds.append(tf.squeeze(tf.concat((LA_pred1,LA_pred2,LA_pred3,LA_pred4),axis=-1)))\n",
    "            LA_next_input = tf.concat((self.env_params,LA_pred1,LA_pred2,LA_pred3,LA_pred4),axis=1)\n",
    "            LA_output_single,LA_state_single=self.cell(inputs=LA_next_input,state=LA_state_single)\n",
    "#         print('LA_A',len(LA_A))\n",
    "#         print('LA_g',len(LA_g))\n",
    "#         print('LA_sigma1',len(LA_sigma1))\n",
    "#         print('LA_lpost',len(LA_l_a_post1))\n",
    "#         print('LA_Ppost',len(LA_P_a_post1))\n",
    "        return (LA_preds,LA_A,LA_B,LA_u,LA_g,LA_sigma1,LA_sigma2,LA_sigma3,LA_sigma4,LA_l_a_post1,LA_l_a_post2,LA_l_a_post3,LA_l_a_post4,LA_P_a_post1,LA_P_a_post2,LA_P_a_post3,LA_P_a_post4)\n",
    "    \n",
    "    def __call__(self, prediction_horizon, view = False):\n",
    "#         self.reset_variables()\n",
    "        rewards = 0\n",
    "        A_all = []\n",
    "        B_all = []\n",
    "        u_all = []\n",
    "        g_all = []\n",
    "        sigma1_all = []\n",
    "        sigma2_all = []\n",
    "        sigma3_all = []\n",
    "        sigma4_all = []\n",
    "        l_a_posteriori1 = []\n",
    "        l_a_posteriori2 = []\n",
    "        l_a_posteriori3 = []\n",
    "        l_a_posteriori4 = []\n",
    "        P_a_posteriori1 = []\n",
    "        P_a_posteriori2 = []\n",
    "        P_a_posteriori3 = []\n",
    "        P_a_posteriori4 = []\n",
    "        env_states1 = []\n",
    "        env_states2 = []\n",
    "        env_states3 = []\n",
    "        env_states4 = []\n",
    "        KF_preds1 = []\n",
    "        KF_preds2 = []\n",
    "        KF_preds3 = []\n",
    "        KF_preds4 = []\n",
    "        squared_error1 = []\n",
    "        squared_error2 = []\n",
    "        squared_error3 = []\n",
    "        squared_error4 = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        KF1_params = [l_a_posteriori1,P_a_posteriori1,env_states1, KF_preds1, squared_error1]\n",
    "        KF2_params = [l_a_posteriori2,P_a_posteriori2,env_states2, KF_preds2, squared_error2]\n",
    "        KF3_params = [l_a_posteriori3,P_a_posteriori3,env_states3, KF_preds3, squared_error3]\n",
    "        KF4_params = [l_a_posteriori4,P_a_posteriori4,env_states4, KF_preds4, squared_error4]\n",
    "        \n",
    "        '''Prediction function variables'''\n",
    "        look_ahead_preds = []\n",
    "        LA_A_all = []\n",
    "        LA_B_all = []\n",
    "        LA_u_all = []\n",
    "        LA_g_all = []\n",
    "        LA_sigma1_all = []\n",
    "        LA_sigma2_all = []\n",
    "        LA_sigma3_all = []\n",
    "        LA_sigma4_all = []\n",
    "        LA_l_a_posteriori1 = []\n",
    "        LA_l_a_posteriori2 = []\n",
    "        LA_l_a_posteriori3 = []\n",
    "        LA_l_a_posteriori4 = []\n",
    "        LA_P_a_posteriori1 = []\n",
    "        LA_P_a_posteriori2 = []\n",
    "        LA_P_a_posteriori3 = []\n",
    "        LA_P_a_posteriori4 = []\n",
    "        look_ahead_vars = [look_ahead_preds,LA_A_all,LA_B_all,LA_u_all,LA_g_all,LA_sigma1_all,LA_sigma2_all,LA_sigma3_all,LA_sigma4_all,\n",
    "                           LA_l_a_posteriori1,LA_l_a_posteriori2,LA_l_a_posteriori3,LA_l_a_posteriori4,\n",
    "                           LA_P_a_posteriori1,LA_P_a_posteriori2,LA_P_a_posteriori3,LA_P_a_posteriori4]\n",
    "        \n",
    "        '''p-quantile loss'''\n",
    "        Q50_numerator = np.zeros(4)\n",
    "        Q90_numerator = np.zeros(4)\n",
    "        \n",
    "        '''Build LSTM'''\n",
    "#         self.build_LSTM()\n",
    "        \n",
    "        '''Start gym environment'''\n",
    "        observation=self.env.reset()\n",
    "\n",
    "        '''Get initial lstm state and input, get first output/state'''\n",
    "        initial_state = self.cell.get_initial_state(batch_size=1,dtype = tf.float64)\n",
    "        initial_input = tf.concat((self.env_params,tf.expand_dims(tf.convert_to_tensor(observation,dtype=tf.float64),0)),\n",
    "                                  axis=1)\n",
    "        output_single, state_single = self.cell(inputs=initial_input, state=initial_state)\n",
    "#         if not self.control or self.control_type =='uniform random':\n",
    "#             self.variables.extend(self.cell.trainable_variables)\n",
    "\n",
    "#         print('LSTM cell trainable',len(self.cell.trainable_variables))\n",
    "#         print('Rewards', self.rewards)\n",
    "#         print('VARIABLES',[x.name for x in self.cell.trainable_variables])\n",
    "#         print('\\n\\n\\nWEIGHTS',[x.name for x in self.cell.trainable_weights])\n",
    "\n",
    "        '''Calculate mu_0,Sigma_0, distribution using initial LSTM output'''\n",
    "        container = tf.contrib.eager.EagerVariableStore()\n",
    "#         control_container = tf.contrib.eager.EagerVariableStore()\n",
    "#         with container.as_default():\n",
    "#             mu_0 = tf.layers.Dense(output_single, self.m, kernel_regularizer = reg.l2(self.weight_beta),\n",
    "#                                        bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                                        name = 'mu_0dense', reuse = True)\n",
    "#             Sigma_0 = tf.layers.Dense(output_single, self.m, kernel_regularizer = reg.l2(self.weight_beta),\n",
    "#                                           bias_regularizer = reg.l2(self.bias_beta),\n",
    "#                                           name = 'Sigma_0dense', reuse = True)\n",
    "        mu_0 = self.mu_0_NN(output_single)\n",
    "        Sigma_0 = self.Sigma_0_NN(output_single)\n",
    "        mu_0 = tf.reshape(mu_0, shape = (self.m,1))\n",
    "        mu_0 = ((self.mu_0_upper_bound-self.mu_0_lower_bound)/(1+tf.exp(-mu_0)))+self.mu_0_lower_bound\n",
    "\n",
    "        Sigma_0 = tf.reshape(Sigma_0, shape = (self.m,1))\n",
    "        Sigma_0 = tf.matmul(Sigma_0,Sigma_0,transpose_b=True)+tf.eye(4, dtype=tf.float64)*1e-8\n",
    "        '''Calculate predicted initial distribution'''\n",
    "        l_0_dist = tfd.MultivariateNormalFullCovariance(loc = tf.squeeze(mu_0),\n",
    "                                                                covariance_matrix= Sigma_0,\n",
    "                                                                validate_args=True)\n",
    "        l_0 = tf.expand_dims(l_0_dist.sample(),1)\n",
    "        l_a_posteriori1.append(l_0)\n",
    "        l_a_posteriori2.append(l_0)\n",
    "        l_a_posteriori3.append(l_0)\n",
    "        l_a_posteriori4.append(l_0)\n",
    "        P_a_posteriori1.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "        P_a_posteriori2.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "        P_a_posteriori3.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "        P_a_posteriori4.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "        LA_l_a_posteriori1.append(l_0)\n",
    "        LA_l_a_posteriori2.append(l_0)\n",
    "        LA_l_a_posteriori3.append(l_0)\n",
    "        LA_l_a_posteriori4.append(l_0)\n",
    "        LA_P_a_posteriori1.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "        LA_P_a_posteriori2.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "        LA_P_a_posteriori3.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "        LA_P_a_posteriori4.append(tf.eye(4, dtype = tf.float64)*self.initial_variance_estimate)\n",
    "\n",
    "\n",
    "        '''set initial u for random uniform control'''\n",
    "        u = tf.Variable([0.0], dtype = tf.float64, trainable = False)\n",
    "        \n",
    "        first_pass = True\n",
    "        done = False\n",
    "        while not done:\n",
    "            if view and self.control:\n",
    "                self.env.render()\n",
    "                \n",
    "#             with container.as_default():\n",
    "            A, g, sigma1, sigma2, sigma3, sigma4 = self.step(output_single)\n",
    "            if self.control:\n",
    "                B, u = self.control_step(output_single, u, A, observation)\n",
    "            else:\n",
    "                B = tf.zeros(shape = (self.m,self.r), dtype = tf.float64)\n",
    "                u = tf.zeros(shape = [1,self.r], dtype=tf.float64)\n",
    "            '''If this is first pass in loop, add variables to graph'''\n",
    "#             if first_pass:\n",
    "#                 self.variables.extend(container.trainable_variables())\n",
    "#                 first_pass = False\n",
    "            observation, reward, done, info = self.env.step(tf.squeeze(u))\n",
    "            '''Calculate:\n",
    "                A,B,u,g,C,sigma,l_a_posteriori,P_a_posteriori,env_states'''\n",
    "            KF1_update = split_forward_filter_fn(A,B,u,g,self.C_1,sigma1,l_a_posteriori1[-1],P_a_posteriori1[-1],\n",
    "                                                tf.convert_to_tensor(observation[0],dtype=tf.float64))\n",
    "            KF2_update = split_forward_filter_fn(A,B,u,g,self.C_2,sigma2,l_a_posteriori2[-1],P_a_posteriori2[-1],\n",
    "                                                tf.convert_to_tensor(observation[1],dtype=tf.float64))\n",
    "            KF3_update = split_forward_filter_fn(A,B,u,g,self.C_3,sigma3,l_a_posteriori3[-1],P_a_posteriori3[-1],\n",
    "                                                tf.convert_to_tensor(observation[2],dtype=tf.float64))\n",
    "            KF4_update = split_forward_filter_fn(A,B,u,g,self.C_4,sigma4,l_a_posteriori4[-1],P_a_posteriori4[-1],\n",
    "                                                tf.convert_to_tensor(observation[3],dtype=tf.float64))\n",
    "            '''Update lists:\n",
    "                A_all,B_all,u_all,g_all,C_all,sigma_all,l_a_posteriori,P_a_posteriori,env_states'''\n",
    "            A_all.append(A)\n",
    "            B_all.append(B)\n",
    "            u_all.append(u)\n",
    "            g_all.append(g)\n",
    "            sigma1_all.append(sigma1)\n",
    "            sigma2_all.append(sigma2)\n",
    "            sigma3_all.append(sigma3)\n",
    "            sigma4_all.append(sigma4)\n",
    "            for KF_single,KF_param in zip(KF1_update,KF1_params):\n",
    "                KF_param.append(KF_single)\n",
    "            for KF_single,KF_param in zip(KF2_update,KF2_params):\n",
    "                KF_param.append(KF_single)\n",
    "            for KF_single,KF_param in zip(KF3_update,KF3_params):\n",
    "                KF_param.append(KF_single)\n",
    "            for KF_single,KF_param in zip(KF4_update,KF4_params):\n",
    "                KF_param.append(KF_single)\n",
    "                \n",
    "            next_input = tf.concat((self.env_params,env_states1[-1],env_states2[-1],\n",
    "                                    env_states3[-1],env_states4[-1]),axis=1)\n",
    "            output_single,state_single=self.cell(inputs=next_input,state=state_single)\n",
    "            if rewards%prediction_horizon==0:\n",
    "#                 LA_preds,LA_A,LA_B,LA_u,LA_g,LA_sigma1,LA_sigma2,LA_sigma3,LA_sigma4,LA_l_a_posteriori, LA_P_a_posteriori\n",
    "                LA_update = self.look_ahead_prediction(prediction_horizon, observation, output_single, state_single,\n",
    "                                                       l_a_posteriori1[-1],l_a_posteriori2[-1],l_a_posteriori3[-1],l_a_posteriori4[-1],\n",
    "                                                       P_a_posteriori1[-1],P_a_posteriori2[-1],P_a_posteriori3[-1],P_a_posteriori4[-1])\n",
    "                for var,param in zip(look_ahead_vars,LA_update):\n",
    "                    var.extend(param)\n",
    "#                 look_ahead_preds.extend(LA_preds)\n",
    "#                 LA_A_all.extend(LA_A)\n",
    "#                 LA_B_all.extend(LA_B)\n",
    "#                 LA_u_all.extend(LA_u)\n",
    "#                 LA_g_all.extend(LA_g)\n",
    "#                 LA_sigma1_all.extend(LA_sigma1)\n",
    "#                 LA_sigma2_all.extend(LA_sigma2)\n",
    "#                 LA_sigma3_all.extend(LA_sigma3)\n",
    "#                 LA_sigma4_all.extend(LA_sigma4)\n",
    "#                 LA_l_a_posteriori1.extend(LA_l_a_posteriori[0])\n",
    "#                 LA_l_a_posteriori2.extend(LA_l_a_posteriori[1])\n",
    "#                 LA_l_a_posteriori3.extend(LA_l_a_posteriori[2])\n",
    "#                 LA_l_a_posteriori4.extend(LA_l_a_posteriori[3])\n",
    "#                 LA_P_a_posteriori1.extend(LA_P_a_posteriori[0])\n",
    "#                 LA_P_a_posteriori2.extend(LA_P_a_posteriori[1])\n",
    "#                 LA_P_a_posteriori3.extend(LA_P_a_posteriori[2])\n",
    "#                 LA_P_a_posteriori4.extend(LA_P_a_posteriori[3])\n",
    "            rewards+=1\n",
    "\n",
    "        LA_A_all = LA_A_all[:rewards]\n",
    "        LA_B_all = LA_B_all[:rewards]\n",
    "        LA_u_all = LA_u_all[:rewards]\n",
    "        LA_g_all = LA_g_all[:rewards]\n",
    "        LA_sigma1_all = LA_sigma1_all[:rewards]\n",
    "        LA_sigma2_all = LA_sigma2_all[:rewards]\n",
    "        LA_sigma3_all = LA_sigma3_all[:rewards]\n",
    "        LA_sigma4_all = LA_sigma4_all[:rewards]\n",
    "        LA_l_a_posteriori1 = LA_l_a_posteriori1[:rewards+1]\n",
    "        LA_l_a_posteriori2 = LA_l_a_posteriori2[:rewards+1]\n",
    "        LA_l_a_posteriori3 = LA_l_a_posteriori3[:rewards+1]\n",
    "        LA_l_a_posteriori4 = LA_l_a_posteriori4[:rewards+1]\n",
    "        LA_P_a_posteriori1 = LA_P_a_posteriori1[:rewards+1]\n",
    "        LA_P_a_posteriori2 = LA_P_a_posteriori2[:rewards+1]\n",
    "        LA_P_a_posteriori3 = LA_P_a_posteriori3[:rewards+1]\n",
    "        LA_P_a_posteriori4 = LA_P_a_posteriori4[:rewards+1]\n",
    "        if view and self.control:\n",
    "            self.env.close()\n",
    "\n",
    "#         param_names = ['A_all','B_all','u_all','g_all','C_all','sigma_all',\n",
    "#                        'l_a_posteriori','P_a_posteriori','env_states','preds']\n",
    "#             for name,KF_param in zip(param_names,all_KF_params):\n",
    "#                 print(name,len(KF_param), KF_param[0].shape)\n",
    "\n",
    "#         print('mu_0',mu_0)\n",
    "#         print('Sigma_0',Sigma_0)\n",
    "#         print('A_all',A_all[0])\n",
    "#         print('B_all',B_all[0])\n",
    "#         print('u_all',u_all[0])\n",
    "#         print('C_1',C_1)\n",
    "#         print('sigma1_all',sigma1_all[0])\n",
    "        '''Start Maximum a posteriori section'''\n",
    "        mu_11 = tf.add(tf.matmul(tf.slice(A_all[0],(0,0),(1,4)), mu_0),tf.matmul(tf.slice(B_all[0],(0,0),(1,1)),u_all[0]))\n",
    "        Sigma_11 = tf.add(tf.matmul(tf.matmul(self.C_1,Sigma_0),self.C_1, transpose_b=True),\n",
    "                     tf.matmul(sigma1_all[0],sigma1_all[0],transpose_b=True))\n",
    "        mu_12 = tf.add(tf.matmul(tf.slice(A_all[0],(1,0),(1,4)), mu_0),tf.matmul(tf.slice(B_all[0],(1,0),(1,1)),u_all[0]))\n",
    "        Sigma_12 = tf.add(tf.matmul(tf.matmul(self.C_2,Sigma_0),self.C_2, transpose_b=True),\n",
    "                     tf.matmul(sigma2_all[0],sigma2_all[0],transpose_b=True))\n",
    "        mu_13 = tf.add(tf.matmul(tf.slice(A_all[0],(2,0),(1,4)), mu_0),tf.matmul(tf.slice(B_all[0],(2,0),(1,1)),u_all[0]))\n",
    "        Sigma_13 = tf.add(tf.matmul(tf.matmul(self.C_3,Sigma_0),self.C_3, transpose_b=True),\n",
    "                     tf.matmul(sigma3_all[0],sigma3_all[0],transpose_b=True))\n",
    "        mu_14 = tf.add(tf.matmul(tf.slice(A_all[0],(3,0),(1,4)), mu_0),tf.matmul(tf.slice(B_all[0],(3,0),(1,1)),u_all[0]))\n",
    "        Sigma_14 = tf.add(tf.matmul(tf.matmul(self.C_4,Sigma_0),self.C_4, transpose_b=True),\n",
    "                     tf.matmul(sigma4_all[0],sigma4_all[0],transpose_b=True))\n",
    "        \n",
    "        LA_mu_11 = tf.add(tf.matmul(tf.slice(LA_A_all[0],(0,0),(1,4)), mu_0),tf.matmul(tf.slice(LA_B_all[0],(0,0),(1,1)),LA_u_all[0]))\n",
    "        LA_Sigma_11 = tf.add(tf.matmul(tf.matmul(self.C_1,Sigma_0),self.C_1, transpose_b=True),\n",
    "                     tf.matmul(LA_sigma1_all[0],LA_sigma1_all[0],transpose_b=True))\n",
    "        LA_mu_12 = tf.add(tf.matmul(tf.slice(LA_A_all[0],(1,0),(1,4)), mu_0),tf.matmul(tf.slice(LA_B_all[0],(1,0),(1,1)),LA_u_all[0]))\n",
    "        LA_Sigma_12 = tf.add(tf.matmul(tf.matmul(self.C_2,Sigma_0),self.C_2, transpose_b=True),\n",
    "                     tf.matmul(LA_sigma2_all[0],LA_sigma2_all[0],transpose_b=True))\n",
    "        LA_mu_13 = tf.add(tf.matmul(tf.slice(LA_A_all[0],(2,0),(1,4)), mu_0),tf.matmul(tf.slice(LA_B_all[0],(2,0),(1,1)),LA_u_all[0]))\n",
    "        LA_Sigma_13 = tf.add(tf.matmul(tf.matmul(self.C_3,Sigma_0),self.C_3, transpose_b=True),\n",
    "                     tf.matmul(LA_sigma3_all[0],LA_sigma3_all[0],transpose_b=True))\n",
    "        LA_mu_14 = tf.add(tf.matmul(tf.slice(LA_A_all[0],(3,0),(1,4)), mu_0),tf.matmul(tf.slice(LA_B_all[0],(3,0),(1,1)),LA_u_all[0]))\n",
    "        LA_Sigma_14 = tf.add(tf.matmul(tf.matmul(self.C_4,Sigma_0),self.C_4, transpose_b=True),\n",
    "                     tf.matmul(LA_sigma4_all[0],LA_sigma4_all[0],transpose_b=True))\n",
    "\n",
    "        if rewards > 1:\n",
    "            mu1,Sigma1 = self.likelihood_fn((mu_11,Sigma_11),(A_all[1:],B_all[1:],u_all[1:],g_all[1:],\n",
    "                                                     self.C_1,sigma1_all[1:],\n",
    "                                                     l_a_posteriori1[1:-1],\n",
    "                                                     P_a_posteriori1[1:-1]))\n",
    "            mu2,Sigma2 = self.likelihood_fn((mu_12,Sigma_12),(A_all[1:],B_all[1:],u_all[1:],g_all[1:],\n",
    "                                                     self.C_2,sigma2_all[1:],\n",
    "                                                     l_a_posteriori2[1:-1],\n",
    "                                                     P_a_posteriori2[1:-1]))\n",
    "            mu3,Sigma3 = self.likelihood_fn((mu_13,Sigma_13),(A_all[1:],B_all[1:],u_all[1:],g_all[1:],\n",
    "                                                     self.C_3,sigma3_all[1:],\n",
    "                                                     l_a_posteriori3[1:-1],\n",
    "                                                     P_a_posteriori3[1:-1]))\n",
    "            mu4,Sigma4 = self.likelihood_fn((mu_14,Sigma_14),(A_all[1:],B_all[1:],u_all[1:],g_all[1:],\n",
    "                                                     self.C_4,sigma4_all[1:],\n",
    "                                                     l_a_posteriori4[1:-1],\n",
    "                                                     P_a_posteriori4[1:-1]))\n",
    "\n",
    "            LA_mu1,LA_Sigma1 = self.likelihood_fn((LA_mu_11,LA_Sigma_11),(LA_A_all[1:],LA_B_all[1:],LA_u_all[1:],LA_g_all[1:],\n",
    "                                                     self.C_1,LA_sigma1_all[1:],\n",
    "                                                     LA_l_a_posteriori1[1:-1],\n",
    "                                                     LA_P_a_posteriori1[1:-1]))\n",
    "            LA_mu2,LA_Sigma2 = self.likelihood_fn((LA_mu_12,LA_Sigma_12),(LA_A_all[1:],LA_B_all[1:],LA_u_all[1:],LA_g_all[1:],\n",
    "                                                     self.C_2,LA_sigma2_all[1:],\n",
    "                                                     LA_l_a_posteriori2[1:-1],\n",
    "                                                     LA_P_a_posteriori2[1:-1]))\n",
    "            LA_mu3,LA_Sigma3 = self.likelihood_fn((LA_mu_13,LA_Sigma_13),(LA_A_all[1:],LA_B_all[1:],LA_u_all[1:],LA_g_all[1:],\n",
    "                                                     self.C_3,LA_sigma3_all[1:],\n",
    "                                                     LA_l_a_posteriori3[1:-1],\n",
    "                                                     LA_P_a_posteriori3[1:-1]))\n",
    "            LA_mu4,LA_Sigma4 = self.likelihood_fn((LA_mu_14,LA_Sigma_14),(LA_A_all[1:],LA_B_all[1:],LA_u_all[1:],LA_g_all[1:],\n",
    "                                                     self.C_4,LA_sigma4_all[1:],\n",
    "                                                     LA_l_a_posteriori4[1:-1],\n",
    "                                                     LA_P_a_posteriori4[1:-1]))            \n",
    "        else:\n",
    "            mu1,Sigma1 = LA_mu1,LA_Sigma1 = mu_11,Sigma_11\n",
    "            mu2,Sigma2 = LA_mu2,LA_Sigma2 = mu_12,Sigma_12\n",
    "            mu3,Sigma3 = LA_mu3,LA_Sigma3 = mu_13,Sigma_13\n",
    "            mu4,Sigma4 = LA_mu4,LA_Sigma4 = mu_14,Sigma_14\n",
    "        '''End Maximum A posteriori section'''\n",
    "    \n",
    "        '''p-quantile loss'''\n",
    "        for j in range(rewards):\n",
    "#             Q50_numerator[0] += QL(0.5,look_ahead_preds[j][0],env_states1[j])\n",
    "#             Q90_numerator[0] += QL(0.9,look_ahead_preds[j][0],env_states1[j])\n",
    "            Q50_numerator[0] += QL(0.5, KF_preds1[j], env_states1[j])\n",
    "            Q90_numerator[0] += QL(0.9, KF_preds1[j], env_states1[j])\n",
    "        for j in range(rewards):\n",
    "#             Q50_numerator[1] += QL(0.5,look_ahead_preds[j][1],env_states2[j])\n",
    "#             Q90_numerator[1] += QL(0.9,look_ahead_preds[j][1],env_states2[j])\n",
    "            Q50_numerator[1] += QL(0.5, KF_preds2[j], env_states2[j])\n",
    "            Q90_numerator[1] += QL(0.9, KF_preds2[j], env_states2[j])\n",
    "        for j in range(rewards):\n",
    "#             Q50_numerator[2] += QL(0.5,look_ahead_preds[j][2],env_states3[j])\n",
    "#             Q90_numerator[2] += QL(0.9,look_ahead_preds[j][2],env_states3[j])\n",
    "            Q50_numerator[2] += QL(0.5, KF_preds3[j], env_states3[j])\n",
    "            Q90_numerator[2] += QL(0.9, KF_preds3[j], env_states3[j])\n",
    "        for j in range(rewards):\n",
    "#             Q50_numerator[3] += QL(0.5,look_ahead_preds[j][3],env_states4[j])\n",
    "#             Q90_numerator[3] += QL(0.9,look_ahead_preds[j][3],env_states4[j])\n",
    "            Q50_numerator[3] += QL(0.5, KF_preds4[j], env_states4[j])\n",
    "            Q90_numerator[3] += QL(0.9, KF_preds4[j], env_states4[j])\n",
    "\n",
    "        Q_denomenator1 = np.sum(np.abs(np.squeeze(np.array(env_states1))), axis = 0)\n",
    "        Q_denomenator2 = np.sum(np.abs(np.squeeze(np.array(env_states2))), axis = 0)\n",
    "        Q_denomenator3 = np.sum(np.abs(np.squeeze(np.array(env_states3))), axis = 0)\n",
    "        Q_denomenator4 = np.sum(np.abs(np.squeeze(np.array(env_states4))), axis = 0)\n",
    "\n",
    "        pq50_loss1 = 2*np.divide(Q50_numerator[0],Q_denomenator1)\n",
    "        pq90_loss1 = 2*np.divide(Q90_numerator[0],Q_denomenator1)\n",
    "        pq50_loss2 = 2*np.divide(Q50_numerator[1],Q_denomenator2)\n",
    "        pq90_loss2 = 2*np.divide(Q90_numerator[1],Q_denomenator2)\n",
    "        pq50_loss3 = 2*np.divide(Q50_numerator[2],Q_denomenator3)\n",
    "        pq90_loss3 = 2*np.divide(Q90_numerator[2],Q_denomenator3)\n",
    "        pq50_loss4 = 2*np.divide(Q50_numerator[3],Q_denomenator4)\n",
    "        pq90_loss4 = 2*np.divide(Q90_numerator[3],Q_denomenator4)\n",
    "\n",
    "\n",
    "        '''Compute Likelihood of observations given KF evaluation'''\n",
    "        z1_distribution = tfd.Normal(loc = mu1, scale = Sigma1)\n",
    "        z1_likelihood = z1_distribution.log_prob(env_states1)\n",
    "        z2_distribution = tfd.Normal(loc = mu2, scale = Sigma2)\n",
    "        z2_likelihood = z2_distribution.log_prob(env_states2)\n",
    "        z3_distribution = tfd.Normal(loc = mu3, scale = Sigma3)\n",
    "        z3_likelihood = z3_distribution.log_prob(env_states3)\n",
    "        z4_distribution = tfd.Normal(loc = mu4, scale = Sigma4)\n",
    "        z4_likelihood = z4_distribution.log_prob(env_states4)\n",
    "        LA_z1_distribution = tfd.Normal(loc = LA_mu1, scale = LA_Sigma1)\n",
    "        LA_z1_likelihood = LA_z1_distribution.log_prob(env_states1)\n",
    "        LA_z2_distribution = tfd.Normal(loc = LA_mu2, scale = LA_Sigma2)\n",
    "        LA_z2_likelihood = LA_z2_distribution.log_prob(env_states2)\n",
    "        LA_z3_distribution = tfd.Normal(loc = LA_mu3, scale = LA_Sigma3)\n",
    "        LA_z3_likelihood = LA_z3_distribution.log_prob(env_states3)\n",
    "        LA_z4_distribution = tfd.Normal(loc = LA_mu4, scale = LA_Sigma4)\n",
    "        LA_z4_likelihood = LA_z4_distribution.log_prob(env_states4)\n",
    "        self.global_epoch += 1\n",
    "\n",
    "#         print('container len', len(container.variables()))\n",
    "#         for var in container.variables():\n",
    "#             print(var.name)\n",
    "        return((z1_likelihood,z2_likelihood,z3_likelihood,z4_likelihood),(LA_z1_likelihood,LA_z2_likelihood,LA_z3_likelihood,LA_z4_likelihood),\n",
    "               rewards,tf.squeeze(tf.convert_to_tensor((KF_preds1,KF_preds2,KF_preds3,KF_preds4))),\n",
    "               (env_states1,env_states2,env_states3,env_states4),(squared_error1,squared_error2,squared_error3,squared_error4),\n",
    "               (pq50_loss1,pq90_loss1,pq50_loss2,pq90_loss2,pq50_loss3,pq90_loss3,pq50_loss4,pq90_loss4), look_ahead_preds)\n",
    "\n",
    "def QL(rho, z, z_pred):\n",
    "    if z > z_pred:\n",
    "        return rho*(z-z_pred)\n",
    "    else:\n",
    "        return (1-rho)*(z_pred-z)\n",
    "    \n",
    "def look_ahead_loss(model,view,prediction_horizon):\n",
    "    likelihoods, LA_likelihoods, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds = model(prediction_horizon,view)\n",
    "    loss = tf.Variable([0.0], trainable=False, dtype = tf.float64)\n",
    "    for i in range(rewards):\n",
    "        loss = tf.add(loss,tf.square(trajectory[0][i])-look_ahead_preds[i][0])\n",
    "        loss = tf.add(loss,tf.square(trajectory[1][i])-look_ahead_preds[i][1])\n",
    "        loss = tf.add(loss,tf.square(trajectory[2][i])-look_ahead_preds[i][2])\n",
    "        loss = tf.add(loss,tf.square(trajectory[3][i])-look_ahead_preds[i][3])\n",
    "#         loss = tf.add(loss,((i%prediction_horizon)+1)*tf.square(trajectory[0][i])-look_ahead_preds[i][0])\n",
    "#         loss = tf.add(loss,((i%prediction_horizon)+1)*tf.square(trajectory[1][i])-look_ahead_preds[i][1])\n",
    "#         loss = tf.add(loss,((i%prediction_horizon)+1)*tf.square(trajectory[2][i])-look_ahead_preds[i][2])\n",
    "#         loss = tf.add(loss,((i%prediction_horizon)+1)*tf.square(trajectory[3][i])-look_ahead_preds[i][3])\n",
    "    for likelihood in LA_likelihoods:\n",
    "        for loss_term in likelihood:\n",
    "            loss = tf.add(loss,-loss_term)\n",
    "    \n",
    "    return loss, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds\n",
    "    \n",
    "def standard_loss(model,view,prediction_horizon):\n",
    "    likelihoods, LA_likelihoods, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds = model(prediction_horizon,view)\n",
    "    loss = tf.Variable([0.0], trainable = False, dtype = tf.float64)\n",
    "    for likelihood in LA_likelihoods:\n",
    "        for loss_term in likelihood:\n",
    "            loss = tf.add(loss,-loss_term)\n",
    "    return loss, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds\n",
    "\n",
    "def inverse_multiplicative_loss(model,view,prediction_horizon):\n",
    "    '''This gives loss terms which are a multiple of their time step'''\n",
    "    likelihoods, LA_likelihoods, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds = model(prediction_horizon,view)\n",
    "    loss = tf.Variable([0.0], trainable = False, dtype = tf.float64)\n",
    "    for likelihood in likelihoods:\n",
    "        for t,loss_term in enumerate(likelihood):\n",
    "            loss = tf.add(loss,-(loss_term*(1/(t+1))))\n",
    "    return loss, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds\n",
    "\n",
    "def multiplicative_loss(model,view,prediction_horizon):\n",
    "    '''This gives loss terms which are a multiple of their time step'''\n",
    "    likelihoods, LA_likelihoods, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds = model(prediction_horizon,view)\n",
    "    loss = tf.Variable([0.0], trainable = False, dtype = tf.float64)\n",
    "    for likelihood in likelihoods:\n",
    "        for t,loss_term in enumerate(likelihood):\n",
    "            loss = tf.add(loss,-(loss_term*t))\n",
    "    return loss, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds\n",
    "\n",
    "def exponential_loss(model, alpha,view,prediction_horizon):\n",
    "    '''For alpha > 1 this gives exponentially increasing loss\n",
    "        For 0<alpha<1 this gives discounted loss'''\n",
    "    likelihoods, LA_likelihoods, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds = model(prediction_horizon,view)\n",
    "    loss = tf.Variable([0.0], trainable = False, dtype = tf.float64)\n",
    "    for likelihood in likelihoods:\n",
    "        for t,loss_term in enumerate(likelihood):\n",
    "            loss = tf.add(loss,-(tf.math.pow(alpha,t)*loss_term))\n",
    "    return loss, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds\n",
    "\n",
    "def control_loss(model, alpha, view,prediction_horizon):\n",
    "    likelihoods, LA_likelihoods, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds = model(prediction_horizon,view)\n",
    "    loss = tf.Variable([0.0], trainable=False, dtype = tf.float64)\n",
    "    max_seq_len = tf.Variable([200.0], trainable=False, dtype = tf.float64)\n",
    "    for likelihood in likelihoods:\n",
    "        for t,loss_term in enumerate(likelihood):\n",
    "            loss = tf.add(loss,tf.math.pow(alpha,t)*loss_term)\n",
    "    return loss, rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds\n",
    "\n",
    "def compute_gradient(model, loss_type, alpha,prediction_horizon,view = False):\n",
    "    with tf.GradientTape() as tape:\n",
    "        if loss_type == 'standard':\n",
    "            loss_value, rewards, preds,trajectory, squared_error, pq_loss, look_ahead_preds = standard_loss(model,view,prediction_horizon)\n",
    "        elif loss_type == 'inverse_multiplicative':\n",
    "            loss_value, rewards, preds,trajectory, squared_error, pq_loss, look_ahead_preds = inverse_multiplicative_loss(model,view,prediction_horizon)\n",
    "        elif loss_type == 'multiplicative':\n",
    "            loss_value, rewards, preds,trajectory, squared_error, pq_loss, look_ahead_preds = multiplicative_loss(model,view,prediction_horizon)\n",
    "        elif loss_type == 'exponential':\n",
    "            loss_value, rewards, preds,trajectory, squared_error, pq_loss, look_ahead_preds = exponential_loss(model, tf.convert_to_tensor(alpha, dtype = tf.float64),view,prediction_horizon)\n",
    "        elif loss_type == 'control':\n",
    "            loss_value, rewards, preds,trajectory, squared_error, pq_loss, look_ahead_preds = control_loss(model,tf.convert_to_tensor(alpha, dtype = tf.float64),view,prediction_horizon)\n",
    "        elif loss_type == 'look ahead':\n",
    "            loss_value, rewards, preds,trajectory, squared_error, pq_loss, look_ahead_preds = look_ahead_loss(model,view,prediction_horizon)\n",
    "#         for var in tape.watched_variables():\n",
    "#               print(var.name)\n",
    "#         print(tape.watched_variables())\n",
    "#         print('tape len',len(tape.watched_variables()))\n",
    "#         if view:\n",
    "#             for var in tape.watched_variables():\n",
    "#                 print(var.name)\n",
    "#         print('model variables',len(model.get_variables()))\n",
    "    return (tape.watched_variables(), tape.gradient(loss_value, tape.watched_variables()), loss_value.numpy(),rewards, preds, trajectory, squared_error, pq_loss, look_ahead_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, optimizer, loss_type='standard', alpha = None, view_rate = False, clip_gradients = False, prediction_horizon=5):\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    rewards = []\n",
    "    pq_losses = []\n",
    "    grad_norms = []\n",
    "    predicted_trajectories = []\n",
    "    actual_trajectories = []\n",
    "#     squared_errors = []\n",
    "    look_ahead_predictions = []\n",
    "    for i in range(num_epochs):\n",
    "        '''Try to load model along with previous metrics'''        \n",
    "        if i==0:\n",
    "            try:\n",
    "                (losses,rewards,pq_losses,grad_norms,predicted_trajectories,actual_trajectories,look_ahead_predictions) =\\\n",
    "                        load_model(model,model.model_name)\n",
    "                print('Model loaded from /{}/'.format(model.model_name))\n",
    "            except tf.errors.NotFoundError:\n",
    "                print('Model not found, continuing to train new model')\n",
    "                pass\n",
    "            except FileNotFoundError:\n",
    "                print('Model not found, continuing to train new model')\n",
    "                pass\n",
    "            except:\n",
    "                print(\"other error\")\n",
    "        '''Run model with or without viewing'''\n",
    "\n",
    "        if view_rate:\n",
    "            if (model.global_epoch)%view_rate==0:\n",
    "                watched_vars, grads, loss_, reward_, pred, trajectory,squared_error, pq_loss, look_ahead_preds = compute_gradient(model, loss_type, alpha, view=True,prediction_horizon=prediction_horizon)\n",
    "            else:\n",
    "                watched_vars, grads, loss_, reward_, pred, trajectory,squared_error, pq_loss, look_ahead_preds = compute_gradient(model, loss_type, alpha,prediction_horizon=prediction_horizon)\n",
    "        else:\n",
    "            watched_vars, grads, loss_, reward_, pred, trajectory,squared_error, pq_loss, look_ahead_preds = compute_gradient(model, loss_type, alpha,prediction_horizon=prediction_horizon)\n",
    "        \n",
    "        '''Keep track of loss, rewards, etc.'''\n",
    "        if model.global_epoch==1:\n",
    "            for var in watched_vars:\n",
    "                grad_norms.append([var.name])\n",
    "        losses.extend(loss_)\n",
    "        rewards.append(reward_)\n",
    "        predicted_trajectories.append(pred)\n",
    "        actual_trajectories.append(trajectory)\n",
    "#         squared_errors.append(squared_error)\n",
    "        pq_losses.append(pq_loss)\n",
    "        look_ahead_predictions.append(look_ahead_preds)\n",
    "        for idx, grad in enumerate(grads):\n",
    "            grad_norms[idx].append(np.linalg.norm(grad))\n",
    "\n",
    "        '''clip gradients if called for and apply gradients'''\n",
    "#         clipped_grads = [tf.clip_by_value(grad_, -1.,1.) for grad_ in grads]\n",
    "        if clip_gradients:\n",
    "            clipped_grads = [tf.clip_by_norm(grad, 1.) for grad in grads]\n",
    "            optimizer.apply_gradients(zip(clipped_grads,model.get_variables()))\n",
    "        else:\n",
    "            optimizer.apply_gradients(zip(grads,watched_vars), tf.Variable(model.global_epoch))\n",
    "        if (i+1)%view_rate == 0:\n",
    "            print('Epoch {}'.format(model.global_epoch))\n",
    "            print('Minutes elapsed: {}'.format((time.time()-start)/60))\n",
    "            print('Last {} averages: Loss: {}, reward: {}, loss/reward: {}'.format(view_rate,np.mean(losses[-view_rate:]), np.mean(rewards[-view_rate:]),\n",
    "                                                                                   (np.mean(losses[-view_rate:])/np.mean(rewards[-view_rate:]))))\n",
    "            save_model(model,model.model_name,(losses,rewards,pq_losses,\n",
    "                                               grad_norms,predicted_trajectories,\n",
    "                                               actual_trajectories,look_ahead_predictions))\n",
    "#             print('Model variables:')\n",
    "#             for var in watched_vars:\n",
    "#                 print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,savepath,metrics):\n",
    "    if not os.path.exists(savepath):\n",
    "        os.mkdir(savepath)\n",
    "        print(\"Directory \" , savepath ,  \" Created \")\n",
    "    pkl.dump(metrics, open(savepath+'/metrics.pkl','wb'))\n",
    "    for NN in model.NNs:\n",
    "        NN.save_weights('{}/{}.tf'.format(savepath,NN.name))\n",
    "    pkl.dump(model.cell.get_weights(), open(savepath+'/lstmweights.pkl', 'wb'))\n",
    "    pkl.dump(model.global_epoch, open(savepath+'/globalepoch.pkl', 'wb'))\n",
    "\n",
    "    \n",
    "def load_model(model,loadpath):\n",
    "    metrics = pkl.load(open(loadpath+'/metrics.pkl','rb'))\n",
    "    for NN in model.NNs:\n",
    "        NN.load_weights('{}/{}.tf'.format(loadpath,NN.name))\n",
    "    lstm_weights = pkl.load(open(loadpath+'/lstmweights.pkl','rb'))\n",
    "    model.global_epoch = pkl.load(open(loadpath+'/globalepoch.pkl','rb'))\n",
    "    model.cell.set_weights(lstm_weights)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create empty model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_model = split_KF_Model(model_name = 'pred_horizon_10_standard_loss', env_params_variation=[0,0,0,0],initial_state_variation=[1,0.1,0.1,0.1])\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, continuing to train new model\n",
      "Epoch 100\n",
      "Minutes elapsed: 4.673808677991231\n",
      "Last 100 averages: Loss: 78.89570552499288, reward: 49.84, loss/reward: 1.5829796453650256\n",
      "very end 100\n",
      "Directory  pred_horizon_10_standard_loss  Created \n",
      "WARNING:tensorflow:From /home/alon/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 200\n",
      "Minutes elapsed: 4.556159440676371\n",
      "Last 100 averages: Loss: 15.549078984780431, reward: 49.41, loss/reward: 0.3146949804650968\n",
      "very end 200\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 300\n",
      "Minutes elapsed: 4.848460161685944\n",
      "Last 100 averages: Loss: -20.435055195637585, reward: 50.24, loss/reward: -0.4067487101042513\n",
      "very end 300\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 400\n",
      "Minutes elapsed: 4.730239379405975\n",
      "Last 100 averages: Loss: -61.91733163164053, reward: 50.78, loss/reward: -1.219325160134709\n",
      "very end 400\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 500\n",
      "Minutes elapsed: 4.622382251421611\n",
      "Last 100 averages: Loss: -77.1189405986165, reward: 49.09, loss/reward: -1.5709704746102362\n",
      "very end 500\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 600\n",
      "Minutes elapsed: 4.873360912005107\n",
      "Last 100 averages: Loss: -95.85793410128586, reward: 50.94, loss/reward: -1.8817811955493888\n",
      "very end 600\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 700\n",
      "Minutes elapsed: 5.058583982785543\n",
      "Last 100 averages: Loss: -133.91413941900717, reward: 50.27, loss/reward: -2.663897740581006\n",
      "very end 700\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 800\n",
      "Minutes elapsed: 4.642351933320364\n",
      "Last 100 averages: Loss: -140.4825085840651, reward: 49.07, loss/reward: -2.8629001137979437\n",
      "very end 800\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 900\n",
      "Minutes elapsed: 4.77336684068044\n",
      "Last 100 averages: Loss: -159.22299873160335, reward: 48.72, loss/reward: -3.268123947693008\n",
      "very end 900\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1000\n",
      "Minutes elapsed: 4.8309323708216345\n",
      "Last 100 averages: Loss: -182.06827691086065, reward: 51.0, loss/reward: -3.5699662139384443\n",
      "very end 1000\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1100\n",
      "Minutes elapsed: 5.649702902634939\n",
      "Last 100 averages: Loss: -191.3687868983353, reward: 50.32, loss/reward: -3.8030363056107968\n",
      "very end 1100\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1200\n",
      "Minutes elapsed: 5.395758652687073\n",
      "Last 100 averages: Loss: -182.53861416922675, reward: 48.67, loss/reward: -3.7505365557679626\n",
      "very end 1200\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1300\n",
      "Minutes elapsed: 4.910791659355164\n",
      "Last 100 averages: Loss: -212.21217536661337, reward: 51.23, loss/reward: -4.142341896674085\n",
      "very end 1300\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1400\n",
      "Minutes elapsed: 4.948182622591655\n",
      "Last 100 averages: Loss: -213.8630191310253, reward: 49.74, loss/reward: -4.2996183982916225\n",
      "very end 1400\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1500\n",
      "Minutes elapsed: 4.984216407934825\n",
      "Last 100 averages: Loss: -232.3335884125106, reward: 50.89, loss/reward: -4.56540751449225\n",
      "very end 1500\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1600\n",
      "Minutes elapsed: 4.900186200936635\n",
      "Last 100 averages: Loss: -244.20432132981855, reward: 50.07, loss/reward: -4.877258265025335\n",
      "very end 1600\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1700\n",
      "Minutes elapsed: 4.897917886575063\n",
      "Last 100 averages: Loss: -252.97348645659815, reward: 50.13, loss/reward: -5.046349221156954\n",
      "very end 1700\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1800\n",
      "Minutes elapsed: 4.607515807946523\n",
      "Last 100 averages: Loss: -241.3015574308438, reward: 47.46, loss/reward: -5.0843143158627\n",
      "very end 1800\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 1900\n",
      "Minutes elapsed: 4.962275048096974\n",
      "Last 100 averages: Loss: -257.8505669998658, reward: 50.7, loss/reward: -5.085809999997353\n",
      "very end 1900\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2000\n",
      "Minutes elapsed: 5.100894598166148\n",
      "Last 100 averages: Loss: -281.6516223641851, reward: 50.76, loss/reward: -5.548692323959517\n",
      "very end 2000\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2100\n",
      "Minutes elapsed: 4.860365136464437\n",
      "Last 100 averages: Loss: -265.1872259856134, reward: 48.55, loss/reward: -5.462146776222728\n",
      "very end 2100\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2200\n",
      "Minutes elapsed: 4.8165978272755945\n",
      "Last 100 averages: Loss: -303.4160517438805, reward: 49.25, loss/reward: -6.1607320151041725\n",
      "very end 2200\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2300\n",
      "Minutes elapsed: 4.968280959129333\n",
      "Last 100 averages: Loss: -310.6659037956125, reward: 51.12, loss/reward: -6.077189041385221\n",
      "very end 2300\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2400\n",
      "Minutes elapsed: 5.286346364021301\n",
      "Last 100 averages: Loss: -327.70320061296917, reward: 51.8, loss/reward: -6.3263166141499845\n",
      "very end 2400\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2500\n",
      "Minutes elapsed: 5.116259471575419\n",
      "Last 100 averages: Loss: -342.1662570513816, reward: 52.19, loss/reward: -6.556165109242798\n",
      "very end 2500\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2600\n",
      "Minutes elapsed: 5.0915959278742475\n",
      "Last 100 averages: Loss: -336.3894392234552, reward: 51.61, loss/reward: -6.51791201750543\n",
      "very end 2600\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2700\n",
      "Minutes elapsed: 4.97660356760025\n",
      "Last 100 averages: Loss: -325.413698434885, reward: 49.23, loss/reward: -6.610069031787224\n",
      "very end 2700\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2800\n",
      "Minutes elapsed: 5.013362014293671\n",
      "Last 100 averages: Loss: -340.2462334999974, reward: 49.92, loss/reward: -6.815829997996743\n",
      "very end 2800\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 2900\n",
      "Minutes elapsed: 5.211128171284994\n",
      "Last 100 averages: Loss: -347.7050593780199, reward: 49.81, loss/reward: -6.980627572335272\n",
      "very end 2900\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3000\n",
      "Minutes elapsed: 5.238371296723684\n",
      "Last 100 averages: Loss: -364.74526896534314, reward: 51.66, loss/reward: -7.06049688279797\n",
      "very end 3000\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3100\n",
      "Minutes elapsed: 5.302256345748901\n",
      "Last 100 averages: Loss: -382.55164218896044, reward: 52.61, loss/reward: -7.271462501215747\n",
      "very end 3100\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3200\n",
      "Minutes elapsed: 4.682094661394755\n",
      "Last 100 averages: Loss: -346.47262554274465, reward: 47.11, loss/reward: -7.354545224851298\n",
      "very end 3200\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3300\n",
      "Minutes elapsed: 5.280143157641093\n",
      "Last 100 averages: Loss: -355.9342909707495, reward: 49.01, loss/reward: -7.262482982467853\n",
      "very end 3300\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3400\n",
      "Minutes elapsed: 4.9858837445576984\n",
      "Last 100 averages: Loss: -352.5620404078082, reward: 48.95, loss/reward: -7.2024931646130375\n",
      "very end 3400\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3500\n",
      "Minutes elapsed: 5.096263082822164\n",
      "Last 100 averages: Loss: -371.33790704780256, reward: 51.53, loss/reward: -7.2062469832680485\n",
      "very end 3500\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3600\n",
      "Minutes elapsed: 5.032610873381297\n",
      "Last 100 averages: Loss: -379.7091124115287, reward: 51.15, loss/reward: -7.423443057898899\n",
      "very end 3600\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3700\n",
      "Minutes elapsed: 5.13079682191213\n",
      "Last 100 averages: Loss: -380.7261838131089, reward: 51.02, loss/reward: -7.462292901080143\n",
      "very end 3700\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3800\n",
      "Minutes elapsed: 5.2437486012776695\n",
      "Last 100 averages: Loss: -374.890937228149, reward: 51.85, loss/reward: -7.23029772860461\n",
      "very end 3800\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 3900\n",
      "Minutes elapsed: 5.146041369438171\n",
      "Last 100 averages: Loss: -370.93479637559926, reward: 50.53, loss/reward: -7.3408825722461755\n",
      "very end 3900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4000\n",
      "Minutes elapsed: 5.165192031860352\n",
      "Last 100 averages: Loss: -364.02017277480024, reward: 50.62, loss/reward: -7.191232176507315\n",
      "very end 4000\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4100\n",
      "Minutes elapsed: 5.215252220630646\n",
      "Last 100 averages: Loss: -412.1041969378062, reward: 52.22, loss/reward: -7.891692779352857\n",
      "very end 4100\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4200\n",
      "Minutes elapsed: 5.309831488132477\n",
      "Last 100 averages: Loss: -406.14656174816497, reward: 52.64, loss/reward: -7.715550185185505\n",
      "very end 4200\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4300\n",
      "Minutes elapsed: 4.785808245340983\n",
      "Last 100 averages: Loss: -386.2154253070128, reward: 48.84, loss/reward: -7.907768740929828\n",
      "very end 4300\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4400\n",
      "Minutes elapsed: 5.00760311683019\n",
      "Last 100 averages: Loss: -398.64019755637906, reward: 49.61, loss/reward: -8.0354807005922\n",
      "very end 4400\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4500\n",
      "Minutes elapsed: 5.224714159965515\n",
      "Last 100 averages: Loss: -397.7189588760497, reward: 51.52, loss/reward: -7.7197002887432005\n",
      "very end 4500\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4600\n",
      "Minutes elapsed: 5.18033074537913\n",
      "Last 100 averages: Loss: -398.83086039439246, reward: 51.06, loss/reward: -7.81102350948673\n",
      "very end 4600\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4700\n",
      "Minutes elapsed: 5.251767392953237\n",
      "Last 100 averages: Loss: -433.1397620061366, reward: 52.3, loss/reward: -8.281831013501657\n",
      "very end 4700\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4800\n",
      "Minutes elapsed: 5.705041861534118\n",
      "Last 100 averages: Loss: -436.85219515887184, reward: 52.15, loss/reward: -8.37683979211643\n",
      "very end 4800\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 4900\n",
      "Minutes elapsed: 6.470398465792338\n",
      "Last 100 averages: Loss: -429.8568521965097, reward: 52.74, loss/reward: -8.15049018195885\n",
      "very end 4900\n",
      "Model loaded from /pred_horizon_10_standard_loss/\n",
      "Epoch 5000\n",
      "Minutes elapsed: 6.0643693963686625\n",
      "Last 100 averages: Loss: -438.8771201658468, reward: 51.83, loss/reward: -8.467627246109334\n",
      "very end 5000\n"
     ]
    }
   ],
   "source": [
    "# split_model.set_control(True, 'uniform random')\n",
    "# split_model.set_env(env_params_variation=[0,0,0,0],initial_state_variation=[1,0.1,0.1,0.1])\n",
    "for i in range(50):\n",
    "    train(split_model,100,optimizer, view_rate=100, loss_type='standard',prediction_horizon=10)\n",
    "    tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "# split_model.set_env(env_params_variation=[0,0,0,0],initial_state_variation=[1,0.1,0.1,0.1])\n",
    "# split_model.set_control(True,'NN regularized')\n",
    "# split_model.set_u_clip(15)\n",
    "# split_model.set_LQR_params([1,1,100,1],10)\n",
    "# train(split_model,100,tf.train.AdamOptimizer(), view_rate=5, loss_type = 'exponential',alpha = 0.95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
